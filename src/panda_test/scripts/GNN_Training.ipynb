{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "c0fe9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, DataLoader, Data\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GCNConv\n",
    "from define_path import Def_Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import splitfolders\n",
    "import shutil\n",
    "import albumentations as A # Library for augmentations\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt \n",
    "from torchvision import transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "9fa9d205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jc-merlab/Pictures/Data/2023-06-27/\n"
     ]
    }
   ],
   "source": [
    "# to generalize home directory. User can change their parent path without entering their home directory\n",
    "path = Def_Path()\n",
    "\n",
    "parent_path =  path.home + \"/Pictures/\" + \"Data/\"\n",
    "\n",
    "root_dir = parent_path + path.year + \"-\" + path.month + \"-\" + path.day + \"/\"\n",
    "\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "7b3ea856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotArmDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, pre_transform=None):\n",
    "        super(RobotArmDataset, self).__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.imgs_files = sorted(os.listdir(os.path.join(root_dir, \"images\")))\n",
    "        self.annotations_files = sorted(os.listdir(os.path.join(root_dir, \"annotations\")))\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.imgs_files)\n",
    "\n",
    "    def get(self, idx):\n",
    "        image_file = os.path.join(self.root_dir, \"images\", self.imgs_files[idx])\n",
    "        json_file = os.path.join(self.root_dir, \"annotations\", self.annotations_files[idx])\n",
    "\n",
    "        with open(json_file, 'r') as f:\n",
    "            data_json = json.load(f)\n",
    "        \n",
    "        keypoints = data_json['keypoints']\n",
    "        keypoints = [kp[0] for kp in keypoints]  # Extract keypoints from each list\n",
    "\n",
    "        keypoints = np.array(keypoints).reshape(-1, 3)  # Convert to numpy array and reshape\n",
    "\n",
    "        image = cv2.imread(image_file)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "\n",
    "#         data = {\"image\": image, \"keypoints\": keypoints.tolist()}\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(data)\n",
    "\n",
    "        keypoints = torch.tensor(keypoints, dtype=torch.float).view(-1, 3)  # Convert back to tensor and reshape\n",
    "        edge_index = torch.tensor([[i, i+1] for i in range(len(keypoints)-1)], dtype=torch.long).t().contiguous()\n",
    "        data = Data(x=keypoints, edge_index=edge_index, y=keypoints.clone())\n",
    "    \n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float()  # Convert to PyTorch tensor and rearrange dimensions to (C, H, W)\n",
    "        return image, data\n",
    "#         return transformed\n",
    "        \n",
    "#     def __getitem__(self, idx):\n",
    "#         image_file = os.path.join(self.root, \"images\", self.imgs_files[idx])\n",
    "#         json_file = os.path.join(self.root, \"annotations\", self.annotations_files[idx])\n",
    "    \n",
    "#         with open(json_file, 'r') as f:\n",
    "#             data_json = json.load(f)\n",
    "#         keypoints = data_json['keypoints']\n",
    "#         keypoints = np.array(keypoints).reshape(-1, 3)  # Convert to numpy array and reshape\n",
    "\n",
    "#         image = cv2.imread(image_file)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "\n",
    "#         if self.transform:\n",
    "#             # Transform expects keypoints in format [x, y, visibility]\n",
    "#             transformed = self.transform(image=image, keypoints=keypoints)\n",
    "#             image = transformed[\"image\"]\n",
    "#             keypoints = transformed[\"keypoints\"]\n",
    "\n",
    "#         keypoints = torch.tensor(keypoints, dtype=torch.float).view(-1, 3)  # Convert back to tensor and reshape\n",
    "#         edge_index = torch.tensor([[i, i+1] for i in range(len(keypoints)-1)], dtype=torch.long).t().contiguous()\n",
    "#         data = Data(x=keypoints, edge_index=edge_index)\n",
    "\n",
    "#         image = torch.from_numpy(image).permute(2, 0, 1).float()  # Convert to PyTorch tensor and rearrange dimensions to (C, H, W)\n",
    "#         return image, data\n",
    "    \n",
    "#     def len(self):\n",
    "#         return len(self.imgs_files)  # Return the number of data points\n",
    "\n",
    "#     def get(self, idx):\n",
    "#         return self.__getitem__(idx)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ed7c89c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotateKeyPoints(object):\n",
    "    def __init__(self, angle):\n",
    "        self.angle = angle\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, keypoints = sample['image'], sample['keypoints']\n",
    "\n",
    "        # rotation of image\n",
    "        image = image.rotate(self.angle)\n",
    "\n",
    "        # rotation of keypoints\n",
    "        rotation_matrix = torch.tensor([\n",
    "            [torch.cos(self.angle), -torch.sin(self.angle)],\n",
    "            [torch.sin(self.angle),  torch.cos(self.angle)]\n",
    "        ])\n",
    "\n",
    "        keypoints[:, :2] = torch.mm(keypoints[:, :2], rotation_matrix)\n",
    "\n",
    "        return {'image': image, 'keypoints': keypoints}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "937a236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transform():\n",
    "    return transforms.Compose([\n",
    "    transforms.Lambda(lambda x: Image.fromarray(x)),\n",
    "    transforms.Resize((640, 480)), \n",
    "    transforms.ToTensor(),\n",
    "    RotateKeyPoints(90),  # Rotate image and keypoints by 90 degrees\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "f8e725dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(src_dir):\n",
    "    dst_dir_img = src_dir + \"images\"\n",
    "    dst_dir_anno = src_dir + \"annotations\"\n",
    "    \n",
    "    if os.path.exists(dst_dir_img) and os.path.exists(dst_dir_anno):\n",
    "        print(\"folders exist\")\n",
    "    else:\n",
    "        os.mkdir(dst_dir_img)\n",
    "        os.mkdir(dst_dir_anno)\n",
    "        \n",
    "    for jpgfile in glob.iglob(os.path.join(src_dir, \"*.jpg\")):\n",
    "        shutil.copy(jpgfile, dst_dir_img)\n",
    "\n",
    "    for jsonfile in glob.iglob(os.path.join(src_dir, \"*.json\")):\n",
    "        shutil.copy(jsonfile, dst_dir_anno)\n",
    "        \n",
    "    output = parent_path + \"split_folder_output\" + \"-\" + path.year + \"-\" + path.month + \"-\" + path.day \n",
    "    \n",
    "    print(type(output))\n",
    "    \n",
    "    splitfolders.ratio(src_dir, # The location of dataset\n",
    "                   output=output, # The output location\n",
    "                   seed=42, # The number of seed\n",
    "                   ratio=(.7, .2, .1), # The ratio of split dataset\n",
    "                   group_prefix=None, # If your dataset contains more than one file like \".jpg\", \".pdf\", etc\n",
    "                   move=False # If you choose to move, turn this into True\n",
    "                   )\n",
    "    \n",
    "    shutil.rmtree(dst_dir_img)\n",
    "    shutil.rmtree(dst_dir_anno)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "6821c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(image, data, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    # Remove the channel dimension and convert the tensor back to numpy array\n",
    "    image_np = image.permute(1, 2, 0).numpy()\n",
    "    ax.imshow(image_np.astype(int))\n",
    "\n",
    "    keypoints = data.x[:, :2]  # Assuming the first two dimensions are x and y\n",
    "    # Create a graph from the edge_index\n",
    "    G = nx.Graph()\n",
    "    for i in range(keypoints.shape[0]):\n",
    "        G.add_node(i, pos=(keypoints[i][0].item(), keypoints[i][1].item()))\n",
    "    for edge in data.edge_index.t():\n",
    "        G.add_edge(edge[0].item(), edge[1].item())\n",
    "    \n",
    "    # Draw the graph\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    nx.draw(G, pos, node_color='r', node_size=50, ax=ax)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "f8c8b77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 15462 files [00:00, 18386.10 files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jc-merlab/Pictures/Data/split_folder_output-2023-06-27/train\n",
      "5411\n",
      "torch.Size([3, 480, 640])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KEYPOINTS_FOLDER_TRAIN = train_test_split(root_dir) +\"/train\" \n",
    "print(KEYPOINTS_FOLDER_TRAIN)\n",
    "dataset = RobotArmDataset(KEYPOINTS_FOLDER_TRAIN, transform=None,pre_transform=None)\n",
    "print(len(dataset))\n",
    "image, data = dataset[0]\n",
    "print(image.shape)# Get the first image and its associated data\n",
    "visualize_data(image, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "ec4ee939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RobotArmGCN(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(RobotArmGCN, self).__init__()\n",
    "#         self.conv1 = GCNConv(3, 16)\n",
    "#         self.conv2 = GCNConv(16, 3)\n",
    "\n",
    "#     def forward(self, data):\n",
    "#         x, edge_index = data.x, data.edge_index\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = torch.nn.functional.relu(x)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb08bf2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "f50560c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 15462 files [00:00, 18408.63 files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 15462 files [00:00, 18522.20 files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 15462 files [00:00, 18726.13 files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 50662.9921875\n",
      "Epoch: 1, Loss: 42015.59375\n",
      "Epoch: 2, Loss: 35059.1171875\n",
      "Epoch: 3, Loss: 29456.435546875\n",
      "Epoch: 4, Loss: 24938.33984375\n",
      "Epoch: 5, Loss: 21289.828125\n",
      "Epoch: 6, Loss: 18339.08203125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [355]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):  \u001b[38;5;66;03m# Adjust number of epochs as necessary\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader_train:\n\u001b[1;32m     21\u001b[0m         image, data \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     22\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch_geometric/data/dataset.py:258\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"In case :obj:`idx` is of type integer, will return the data object\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03mat index :obj:`idx` (and transforms it in case :obj:`transform` is\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03mpresent).\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03mIn case :obj:`idx` is a slicing object, *e.g.*, :obj:`[2:5]`, a list, a\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03mtuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type long or\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03mbool, will return a subset of the dataset at the specified indices.\"\"\"\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[0;32m--> 258\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "Input \u001b[0;32mIn [348]\u001b[0m, in \u001b[0;36mRobotArmDataset.get\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     20\u001b[0m         keypoints \u001b[38;5;241m=\u001b[39m [kp[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m kp \u001b[38;5;129;01min\u001b[39;00m keypoints]  \u001b[38;5;66;03m# Extract keypoints from each list\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         keypoints \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(keypoints)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Convert to numpy array and reshape\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m         image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)  \u001b[38;5;66;03m# Convert from BGR to RGB\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#         data = {\"image\": image, \"keypoints\": keypoints.tolist()}\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "KEYPOINTS_FOLDER_TRAIN = train_test_split(root_dir) +\"/train\" #train_test_split(root_dir) +\"/train\"\n",
    "KEYPOINTS_FOLDER_VAL = train_test_split(root_dir) +\"/val\"\n",
    "KEYPOINTS_FOLDER_TEST = train_test_split(root_dir) +\"/test\"\n",
    "\n",
    "dataset_train = RobotArmDataset(KEYPOINTS_FOLDER_TRAIN, transform=None,pre_transform=None)\n",
    "dataset_val = RobotArmDataset(KEYPOINTS_FOLDER_VAL, transform=None)\n",
    "dataset_test = RobotArmDataset(KEYPOINTS_FOLDER_TEST, transform=None)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=32)\n",
    "\n",
    "model = RobotArmGCN().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(100):  # Adjust number of epochs as necessary\n",
    "    for batch in dataloader_train:\n",
    "        image, data = batch\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = torch.nn.functional.mse_loss(out, data.y)  # Adjust loss function as necessary\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in your_test_data_loader:  # Replace with your DataLoader\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3a5d6972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "# from albumentations import Resize, Compose\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image\n",
    "image_path = KEYPOINTS_FOLDER_TRAIN + '/images/000000.rgb.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "# Define a transformation\n",
    "# Define a transformation\n",
    "transform = A.Compose([\n",
    "    A.Resize(224, 224)\n",
    "])\n",
    "\n",
    "# Apply the transformation\n",
    "transformed = transform(image=image)\n",
    "transformed_image = transformed[\"image\"]\n",
    "\n",
    "# Display the transformed image\n",
    "plt.imshow(transformed_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e40e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
