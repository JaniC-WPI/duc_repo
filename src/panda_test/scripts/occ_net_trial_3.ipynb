{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bedf1768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16908615680\n",
      "346030080\n",
      "308891136\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import json\n",
    "from os.path import expanduser\n",
    "import splitfolders\n",
    "import shutil\n",
    "from define_path import Def_Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A # Library for augmentations\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "\n",
    "import transforms, utils, engine, train\n",
    "from utils import collate_fn\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "print(t)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "print(r)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "print(a)\n",
    "# f = r-a  # free inside reserved\n",
    "\n",
    "weights_path = '/home/jc-merlab/Pictures/Data/trained_models/keypointsrcnn_weights_sim_b1_e25_v0.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b355d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to generalize home directory. User can change their parent path without entering their home directory\n",
    "path = Def_Path()\n",
    "\n",
    "parent_path =  path.home + \"/Pictures/\" + \"Data/\"\n",
    "\n",
    "root_dir = parent_path + path.year + \"-\" + path.month + \"-\" + path.day + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "237a5cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# torch.cuda.set_per_process_memory_fraction(0.9, 0)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2189cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transform():\n",
    "    return A.Compose([\n",
    "        A.Sequential([\n",
    "            A.RandomRotate90(p=1), # Random rotation of an image by 90 degrees zero or more times\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.3, brightness_by_max=True, always_apply=False, p=1), # Random change of brightness & contrast\n",
    "        ], p=1)\n",
    "#         A.Resize(640, 480)  # Resize all images to be 640x480\n",
    "    ],\n",
    "    keypoint_params=A.KeypointParams(format='xy'), # More about keypoint formats used in albumentations library read at https://albumentations.ai/docs/getting_started/keypoints_augmentation/\n",
    "    bbox_params=A.BboxParams(format='pascal_voc', label_fields=['bboxes_labels']) # Bboxes should have labels, read more at https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaae8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(src_dir):\n",
    "    dst_dir_img = src_dir + \"images\"\n",
    "    dst_dir_anno = src_dir + \"annotations\"\n",
    "    \n",
    "    if os.path.exists(dst_dir_img) and os.path.exists(dst_dir_anno):\n",
    "        print(\"folders exist\")\n",
    "    else:\n",
    "        os.mkdir(dst_dir_img)\n",
    "        os.mkdir(dst_dir_anno)\n",
    "        \n",
    "    for jpgfile in glob.iglob(os.path.join(src_dir, \"*.jpg\")):\n",
    "        shutil.copy(jpgfile, dst_dir_img)\n",
    "\n",
    "    for jsonfile in glob.iglob(os.path.join(src_dir, \"*.json\")):\n",
    "        shutil.copy(jsonfile, dst_dir_anno)\n",
    "        \n",
    "    output = parent_path + \"split_folder_output\" + \"-\" + path.year + \"-\" + path.month + \"-\" + path.day \n",
    "    \n",
    "    splitfolders.ratio(src_dir, # The location of dataset\n",
    "                   output=output, # The output location\n",
    "                   seed=42, # The number of seed\n",
    "                   ratio=(.7, .2, .1), # The ratio of split dataset\n",
    "                   group_prefix=None, # If your dataset contains more than one file like \".jpg\", \".pdf\", etc\n",
    "                   move=False # If you choose to move, turn this into True\n",
    "                   )\n",
    "    \n",
    "    shutil.rmtree(dst_dir_img)\n",
    "    shutil.rmtree(dst_dir_anno)\n",
    "    \n",
    "    return output  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9395a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KPDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, demo=False):                \n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.demo = demo # Use demo=True if you need transformed and original images (for example, for visualization purposes)\n",
    "        self.imgs_files = sorted(os.listdir(os.path.join(root, \"images\")))\n",
    "        self.annotations_files = sorted(os.listdir(os.path.join(root, \"annotations\")))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_file = self.imgs_files[idx]\n",
    "        img_path = os.path.join(self.root, \"images\", self.imgs_files[idx])\n",
    "        annotations_path = os.path.join(self.root, \"annotations\", self.annotations_files[idx])\n",
    "\n",
    "        img_original = cv2.imread(img_path)\n",
    "        img_original = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        with open(annotations_path) as f:\n",
    "            data = json.load(f)\n",
    "            bboxes_original = data['bboxes']\n",
    "            keypoints_original = data['keypoints']\n",
    "            \n",
    "            # All objects are keypoints on the robot\n",
    "            bboxes_labels_original = [] \n",
    "            bboxes_labels_original.append('base_joint')\n",
    "            bboxes_labels_original.append('joint2')\n",
    "            bboxes_labels_original.append('joint3')\n",
    "            bboxes_labels_original.append('joint4')\n",
    "            bboxes_labels_original.append('joint5')\n",
    "            bboxes_labels_original.append('joint6')  \n",
    "\n",
    "        if self.transform:   \n",
    "            # Converting keypoints from [x,y,visibility]-format to [x, y]-format + Flattening nested list of keypoints            \n",
    "            # For example, if we have the following list of keypoints for three objects (each object has two keypoints):\n",
    "            # [[obj1_kp1, obj1_kp2], [obj2_kp1, obj2_kp2], [obj3_kp1, obj3_kp2]], where each keypoint is in [x, y]-format            \n",
    "            # Then we need to convert it to the following list:\n",
    "            # [obj1_kp1, obj1_kp2, obj2_kp1, obj2_kp2, obj3_kp1, obj3_kp2]\n",
    "            keypoints_original_flattened = [el[0:2] for kp in keypoints_original for el in kp]\n",
    "            \n",
    "            # Apply augmentations\n",
    "            transformed = self.transform(image=img_original, bboxes=bboxes_original, bboxes_labels=bboxes_labels_original, keypoints=keypoints_original_flattened)\n",
    "            img = transformed['image']\n",
    "            bboxes = transformed['bboxes']\n",
    "            # Unflattening list transformed['keypoints']\n",
    "            # For example, if we have the following list of keypoints for three objects (each object has two keypoints):\n",
    "            # [obj1_kp1, obj1_kp2, obj2_kp1, obj2_kp2, obj3_kp1, obj3_kp2], where each keypoint is in [x, y]-format\n",
    "            # Then we need to convert it to the following list:\n",
    "            # [[obj1_kp1, obj1_kp2], [obj2_kp1, obj2_kp2], [obj3_kp1, obj3_kp2]]\n",
    "            keypoints_transformed_unflattened = np.reshape(np.array(transformed['keypoints']), (-1,1,2)).tolist()\n",
    "\n",
    "            # Converting transformed keypoints from [x, y]-format to [x,y,visibility]-format by appending original visibilities to transformed coordinates of keypoints\n",
    "            keypoints = []\n",
    "            for o_idx, obj in enumerate(keypoints_transformed_unflattened):\n",
    "#                 print(\"object\", obj)\n",
    "#                 print(\" obj index\", o_idx)# Iterating over objects\n",
    "                obj_keypoints = []\n",
    "                for k_idx, kp in enumerate(obj): # Iterating over keypoints in each object\n",
    "                    obj_keypoints.append(kp + [keypoints_original[o_idx][k_idx][2]])\n",
    "                keypoints.append(obj_keypoints)\n",
    "        \n",
    "        else:\n",
    "            img, bboxes, keypoints = img_original, bboxes_original, keypoints_original        \n",
    "        \n",
    "        # Convert everything into a torch tensor        \n",
    "        bboxes = torch.as_tensor(bboxes, dtype=torch.float32)       \n",
    "        target = {}\n",
    "        labels = [1, 2, 3, 4, 5, 6]            \n",
    "        target[\"boxes\"] = bboxes\n",
    "        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64) # all objects are joint positions\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "        target[\"area\"] = (bboxes[:, 3] - bboxes[:, 1]) * (bboxes[:, 2] - bboxes[:, 0])\n",
    "        target[\"iscrowd\"] = torch.zeros(len(bboxes), dtype=torch.int64)\n",
    "        target[\"keypoints\"] = torch.as_tensor(keypoints, dtype=torch.float32)\n",
    "        img = F.to_tensor(img)        \n",
    "        bboxes_original = torch.as_tensor(bboxes_original, dtype=torch.float32)\n",
    "        target_original = {}\n",
    "        target_original[\"boxes\"] = bboxes_original\n",
    "        target_original[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64) # all objects are glue tubes\n",
    "        target_original[\"image_id\"] = torch.tensor([idx])\n",
    "        target_original[\"area\"] = (bboxes_original[:, 3] - bboxes_original[:, 1]) * (bboxes_original[:, 2] - bboxes_original[:, 0])\n",
    "        target_original[\"iscrowd\"] = torch.zeros(len(bboxes_original), dtype=torch.int64)\n",
    "        target_original[\"keypoints\"] = torch.as_tensor(keypoints_original, dtype=torch.float32)        \n",
    "        img_original = F.to_tensor(img_original)\n",
    "\n",
    "        if self.demo:\n",
    "            return img, target, img_original, target_original, img_file\n",
    "        else:\n",
    "            return img, target, img_file\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58f915be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_keypoints, weights_path=None):\n",
    "    \n",
    "    anchor_generator = AnchorGenerator(sizes=(32, 64, 128, 256, 512), aspect_ratios=(0.25, 0.5, 0.75, 1.0, 2.0, 3.0, 4.0))\n",
    "    model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=False,\n",
    "                                                                   pretrained_backbone=True,\n",
    "                                                                   num_keypoints=num_keypoints,\n",
    "                                                                   num_classes = 7, # Background is the first class, object is the second class\n",
    "                                                                   rpn_anchor_generator=anchor_generator)\n",
    "\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        model.load_state_dict(state_dict)        \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1df0e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(self, vertices_dim=5, hidden_dim=128, num_vertices=6):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "        self.f_enc = nn.Linear(vertices_dim, hidden_dim)\n",
    "        self.f_e1 = nn.Linear((hidden_dim * 2)+2, hidden_dim)\n",
    "        self.f_v = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.f_e2 = nn.Linear((hidden_dim * 2)+2, 4)\n",
    "        self.num_vertices = num_vertices        \n",
    "    \n",
    "    def get_node_features(self, vertices):\n",
    "        print(\"Vertices in node features\", vertices)\n",
    "        node_features = []\n",
    "        for keypoint in vertices:\n",
    "            x, y, confidence, visibility, label = keypoint\n",
    "            node_features.append([x, y, confidence, visibility, label])        \n",
    "        nodes = torch.tensor(node_features, dtype=torch.float).to(device)\n",
    "        print(nodes)\n",
    "        return nodes\n",
    "\n",
    "    def get_edge_features(self, vertices):\n",
    "        edges = [(0,1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 0)]\n",
    "        edge_features = []\n",
    "        for edge in edges:\n",
    "            k1, k2 = vertices[edge[0]][:2], vertices[edge[1]][:2]\n",
    "            distance = torch.norm(k1 - k2)\n",
    "            angle = torch.atan2(k2[1] - k1[1], k2[0] - k1[0])\n",
    "            edge_features.append([distance.item(), angle.item()])\n",
    "            \n",
    "        edges = torch.tensor(edges, dtype=torch.long).to(device)\n",
    "        edge_features = torch.tensor(edge_features, dtype=torch.float).to(device)\n",
    "        return edges, edge_features\n",
    "\n",
    "    def forward(self, vertices):\n",
    "        nodes = self.get_node_features(vertices)\n",
    "        edges, edge_features = self.get_edge_features(vertices)\n",
    "        h1 = self.f_enc(nodes)\n",
    "        h1_source = h1[edges[:, 0]]\n",
    "        h1_target = h1[edges[:, 1]]\n",
    "        h_e1 = self.f_e1(torch.cat((h1_source, h1_target, edge_features), dim=1))  # Include edge feature in the input\n",
    "        h_j_2 = self.f_v(h_e1)\n",
    "        h2_source = h_j_2[edges[:, 0]]\n",
    "        h2_target = h_j_2[edges[:, 1]]\n",
    "        h_e2 = self.f_e2(torch.cat((h1_source, h1_target, edge_features), dim=1))  # Include edge feature in the input\n",
    "        h_e2_prob = torch.sigmoid(h_e2)\n",
    "        return vertices, h_e2_prob, edges, edge_features\n",
    "\n",
    "class GNNDecoder(nn.Module):\n",
    "    def __init__(self, vertices_dim=5, hidden_dim=128, num_vertices=6):\n",
    "        super(GNNDecoder, self).__init__()\n",
    "        self.f_e = nn.Linear((vertices_dim * 2)+2, 4)  # Concatenate two vertices features\n",
    "        self.f_h = nn.Linear(4, vertices_dim)  # Transform h_ij to the same dimension as vertices\n",
    "        self.f_v = nn.Linear(vertices_dim, vertices_dim)  # Update vertex feature\n",
    "    \n",
    "    def forward(self, vertices, h_e2_prob, edges, edge_features):\n",
    "        h_source = vertices[edges[:, 0]]\n",
    "        h_target = vertices[edges[:, 1]]\n",
    "        h = torch.zeros_like(vertices)\n",
    "\n",
    "        for idx, (i, j) in enumerate(edges):  # Iterate over edges\n",
    "            print(i, j, idx)\n",
    "            single_edge_features = edge_features[idx].unsqueeze(0)    \n",
    "            h_ij = h_e2_prob[idx] * self.f_e(torch.cat((h_source[idx].unsqueeze(0), h_target[idx].unsqueeze(0), single_edge_features), dim=1))  # Include edge weights in the input\n",
    "            h_ij_transformed = self.f_h(h_ij.squeeze())  # Transform h_ij to the same dimension as vertices\n",
    "            h[j] += h_ij_transformed  # Accumulate edge features to the target vertex\n",
    "\n",
    "        h_transformed = self.f_v(h.view(-1, vertices.shape[1]))  # Transform h\n",
    "        h_transformed = h_transformed.view(vertices.shape)  # Reshape back to original shape\n",
    "        vertices_g = vertices + h_transformed  # Update vertex features\n",
    "\n",
    "        return vertices_g  # Return vertices_g as the prediction and vertices_g itself as the mean for Gaussian distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90ea42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OccludedKeyPointLoss(nn.Module):\n",
    "    def __init__(self, delta=1.0):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def forward(self, vertices_pred, vertices_gt):\n",
    "#         vertices_gt = vertices_gt.squeeze()\n",
    "        visibility = vertices_gt[:, 3].unsqueeze(1)  # Extracting the visibility\n",
    "        vertices_pred = vertices_pred[:, :3]  # Considering only x, y coordinates, confidence_score\n",
    "        vertices_gt = vertices_gt[:, :3]  # Considering only x, y coordinates, confidence_score\n",
    "        # Compute differences\n",
    "        diff = (vertices_gt - vertices_pred).abs()\n",
    "        # Compute Huber loss\n",
    "        huber_loss = torch.where(diff < self.delta, 0.5 * diff**2, self.delta * (diff - 0.5 * self.delta))\n",
    "        return huber_loss.mean()\n",
    "    \n",
    "def visibility_loss (vertices_pred, vertices_gt):    \n",
    "    return func.cross_entropy(vertices_pred[:, 3], vertices_gt[:, 3])  # Loss based on visibility of keypoints\n",
    "\n",
    "def edge_loss(edges_prob, edges_gt):\n",
    "#     edges_gt_expanded = torch.zeros(edges_prob.shape, dtype=torch.float32)\n",
    "    # Compute the cross-entropy loss\n",
    "    loss = -torch.sum(edges_gt.to(device) * torch.log(torch.clamp(edges_prob, min=1e-7)))\n",
    "                      \n",
    "    return loss\n",
    "\n",
    "def temporal_consistency_loss(y_true_sequence, y_pred_sequence):\n",
    "    loss = 0\n",
    "    for t in range(1, len(y_true_sequence)):\n",
    "        # Selecting the x, y coordinates and visibility for true and predicted sequences\n",
    "        true_diff = y_true_sequence[t, :, :3] - y_true_sequence[t-1, :, :3]\n",
    "        pred_diff = y_pred_sequence[t, :, :3] - y_pred_sequence[t-1, :, :3]\n",
    "        loss += torch.mean(torch.abs(true_diff - pred_diff))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7fa6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointPipeline(nn.Module):\n",
    "    def __init__(self, weights_path, num_vertices):\n",
    "        super().__init__()\n",
    "\n",
    "        self.keypoint_model = torch.load(weights_path).to(device)\n",
    "        self.num_vertices = num_vertices\n",
    "        self.gnn_encoder = GNNEncoder()\n",
    "        self.gnn_decoder = GNNDecoder()\n",
    "\n",
    "    def process_model_output(self, output):\n",
    "        scores = output[0]['scores'].detach().cpu().numpy()\n",
    "        high_scores_idxs = np.where(scores > 0.7)[0].tolist()\n",
    "\n",
    "        post_nms_idxs = torchvision.ops.nms(output[0]['boxes'][high_scores_idxs], \n",
    "                                            output[0]['scores'][high_scores_idxs], 0.3).cpu().numpy()\n",
    "\n",
    "        confidence = output[0]['scores'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy()\n",
    "        labels = output[0]['labels'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy()\n",
    "        keypoints = []\n",
    "        for idx, kps in enumerate(output[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy()):\n",
    "            # Setting t_i = 1 because label is found\n",
    "            keypoints.append(list(map(int, kps[0,0:2])) + [confidence[idx]] + [1] + [labels[idx]])\n",
    "\n",
    "        # Create a dictionary where the key is the label and the value is the keypoint\n",
    "        label_to_keypoint = {}\n",
    "        for keypoint in keypoints:\n",
    "            label = keypoint[-1]\n",
    "            if label not in label_to_keypoint or label_to_keypoint[label][-2] < keypoint[-2]:\n",
    "                label_to_keypoint[label] = keypoint\n",
    "\n",
    "        # Use a dictionary to keep track of all possible keypoints and their locations.\n",
    "        # Initialize with placeholders for missing keypoints.\n",
    "        all_keypoints = {i: [0, 0, 0, 0, i] for i in range(1, self.num_vertices+1)}  # added another 0 for t_i\n",
    "\n",
    "        for label, keypoint in label_to_keypoint.items():\n",
    "            all_keypoints[label] = keypoint\n",
    "\n",
    "        # Convert the dictionary values back into a list\n",
    "        keypoints = list(all_keypoints.values())\n",
    "        keypoints = torch.stack([torch.tensor(kp) for kp in keypoints]).float().to(device)\n",
    "        visibility = keypoints[:, 3].unsqueeze(1)  # Extracting the visibility\n",
    "        keypoints_visible = keypoints * visibility  # Predicted visible vertices\n",
    "#         keypoints_occluded = keypoints * (1 - visibility)  # Predicted occluded vertices\n",
    "        print(\"Vertices as encoder input\", keypoints_visible)\n",
    "        vertices, self.enc_e, self.edges, self.edge_features = self.gnn_encoder(keypoints_visible)  # Adjust here to include edge weights\n",
    "        vertices_pred = self.gnn_decoder(vertices, self.enc_e, self.edges, self.edge_features)  # Adjust here to pass edge weights\n",
    "#         vertices_pred_occluded = torch.cat((vertices_pred, keypoints_visible[:, 3].unsqueeze(1)), dim=1)\n",
    "#         nonzero_indices = keypoints_occluded.nonzero(as_tuple=True)\n",
    "#         if nonzero_indices[0].size()[0] > 0:  # Check if there are any non-zero elements\n",
    "#             keypoints_occluded[nonzero_indices] = vertices_pred_occluded[nonzero_indices]\n",
    "        return vertices_pred\n",
    "\n",
    "    def process_image(self, img):\n",
    "        img = img.unsqueeze(0).to(device)\n",
    "        # Temporarily set the keypoint model to evaluation mode\n",
    "        keypoint_model_training = self.keypoint_model.training  # Save the current mode\n",
    "        self.keypoint_model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = self.keypoint_model(img)\n",
    "        # Set the keypoint model back to its previous mode\n",
    "        self.keypoint_model.train(keypoint_model_training)\n",
    "        img = (img[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "        labeled_keypoints = self.process_model_output(output)\n",
    "\n",
    "        return labeled_keypoints\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        outputs = []\n",
    "\n",
    "        for i in range(imgs.shape[0]):\n",
    "            labeled_keypoints = self.process_image(imgs[i])\n",
    "            outputs.append(labeled_keypoints)\n",
    "            \n",
    "        print(outputs)\n",
    "\n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "945ce7b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2662 files [00:00, 20517.09 files/s]\n",
      "Copying files: 2662 files [00:00, 20655.71 files/s]\n",
      "Copying files: 2662 files [00:00, 20243.75 files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 with images: ('001174.rgb.jpg', '001184.rgb.jpg', '000835.rgb.jpg', '001241.rgb.jpg', '000032.rgb.jpg', '000579.rgb.jpg', '000187.rgb.jpg', '000005.rgb.jpg', '000525.rgb.jpg', '000345.rgb.jpg', '001172.rgb.jpg', '000199.rgb.jpg', '001035.rgb.jpg', '000431.rgb.jpg', '001202.rgb.jpg', '000482.rgb.jpg')\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [304.0000, 218.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [321.0000, 230.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [381.0000, 308.0000,   0.9991,   1.0000,   5.0000],\n",
      "        [398.0000, 324.0000,   0.9972,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [304.0000, 218.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [321.0000, 230.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [381.0000, 308.0000,   0.9991,   1.0000,   5.0000],\n",
      "        [398.0000, 324.0000,   0.9972,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [304.0000, 218.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [321.0000, 230.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [381.0000, 308.0000,   0.9991,   1.0000,   5.0000],\n",
      "        [398.0000, 324.0000,   0.9972,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[287.7683, 380.1958,  39.0054, -80.7581,  40.4388],\n",
      "        [275.3290, 278.8095,  40.6188, -79.0873,  37.9271],\n",
      "        [319.1943, 218.0499,  33.5739, -62.1514,  34.4682],\n",
      "        [335.5782, 232.3573,  34.6300, -58.6513,  38.5456],\n",
      "        [396.8540, 310.7324,  44.1310, -69.7132,  50.3834],\n",
      "        [416.3273, 324.0165,  48.1921, -82.5349,  53.1668]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [296.0000, 213.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [314.0000, 223.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [365.0000, 308.0000,   0.9992,   1.0000,   5.0000],\n",
      "        [366.0000, 328.0000,   0.9878,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [296.0000, 213.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [314.0000, 223.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [365.0000, 308.0000,   0.9992,   1.0000,   5.0000],\n",
      "        [366.0000, 328.0000,   0.9878,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [296.0000, 213.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [314.0000, 223.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [365.0000, 308.0000,   0.9992,   1.0000,   5.0000],\n",
      "        [366.0000, 328.0000,   0.9878,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[283.6970, 374.2962,  42.4217, -83.1766,  42.5599],\n",
      "        [275.3290, 278.8095,  40.6188, -79.0873,  37.9271],\n",
      "        [311.6072, 213.6478,  32.4287, -61.1656,  33.3100],\n",
      "        [328.1981, 225.2854,  33.6957, -57.0610,  37.5815],\n",
      "        [380.7743, 310.9363,  43.4113, -68.5949,  49.7080],\n",
      "        [383.9733, 327.1347,  47.8652, -82.6780,  52.3814]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [259.0000, 203.0000,   0.9993,   1.0000,   3.0000],\n",
      "        [279.0000, 203.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [306.0000, 108.0000,   0.9979,   1.0000,   5.0000],\n",
      "        [325.0000,  99.0000,   0.9930,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [259.0000, 203.0000,   0.9993,   1.0000,   3.0000],\n",
      "        [279.0000, 203.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [306.0000, 108.0000,   0.9979,   1.0000,   5.0000],\n",
      "        [325.0000,  99.0000,   0.9930,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [259.0000, 203.0000,   0.9993,   1.0000,   3.0000],\n",
      "        [279.0000, 203.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [306.0000, 108.0000,   0.9979,   1.0000,   5.0000],\n",
      "        [325.0000,  99.0000,   0.9930,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[282.9105, 389.2906,  33.5885, -52.8229,  42.4530],\n",
      "        [275.3290, 278.8095,  40.6187, -79.0873,  37.9271],\n",
      "        [276.2629, 205.7689,  28.8198, -58.5026,  29.6438],\n",
      "        [291.5565, 203.9806,  31.0411, -52.8296,  34.3888],\n",
      "        [324.6984, 120.3874,  15.6153, -36.2322,  21.7273],\n",
      "        [340.3917, 112.3823,  15.4859, -27.6115,  24.8615]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [309.0000, 222.0000,   0.9990,   1.0000,   3.0000],\n",
      "        [325.0000, 236.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [350.0000, 332.0000,   0.9993,   1.0000,   5.0000],\n",
      "        [344.0000, 351.0000,   0.9700,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [309.0000, 222.0000,   0.9990,   1.0000,   3.0000],\n",
      "        [325.0000, 236.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [350.0000, 332.0000,   0.9993,   1.0000,   5.0000],\n",
      "        [344.0000, 351.0000,   0.9700,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [309.0000, 222.0000,   0.9990,   1.0000,   3.0000],\n",
      "        [325.0000, 236.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [350.0000, 332.0000,   0.9993,   1.0000,   5.0000],\n",
      "        [344.0000, 351.0000,   0.9700,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[281.0349, 369.0964,  45.3974, -87.2775,  43.9335],\n",
      "        [275.3290, 278.8095,  40.6188, -79.0873,  37.9271],\n",
      "        [323.9138, 221.6245,  34.4071, -62.8991,  35.3082],\n",
      "        [339.8279, 238.3242,  35.4046, -59.9549,  39.3153],\n",
      "        [367.0713, 335.1142,  45.1613, -72.7794,  51.2551],\n",
      "        [361.5183, 347.3176,  50.8461, -88.3204,  54.2779]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9998,   1.0000,   2.0000],\n",
      "        [179.0000, 298.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [176.0000, 277.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [207.0000, 183.0000,   0.9979,   1.0000,   5.0000],\n",
      "        [214.0000, 162.0000,   0.9975,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9998,   1.0000,   2.0000],\n",
      "        [179.0000, 298.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [176.0000, 277.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [207.0000, 183.0000,   0.9979,   1.0000,   5.0000],\n",
      "        [214.0000, 162.0000,   0.9975,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9998,   1.0000,   2.0000],\n",
      "        [179.0000, 298.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [176.0000, 277.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [207.0000, 183.0000,   0.9979,   1.0000,   5.0000],\n",
      "        [214.0000, 162.0000,   0.9975,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[271.5990, 369.9470,  44.4744, -64.8639,  48.0361],\n",
      "        [275.3290, 278.8095,  40.6186, -79.0873,  37.9271],\n",
      "        [197.5110, 299.2932,  36.2487, -70.1065,  36.8225],\n",
      "        [185.9895, 266.2582,  40.8472, -72.3727,  39.4571],\n",
      "        [220.5481, 181.5262,  26.8982, -54.4797,  28.3887],\n",
      "        [225.3482, 163.1357,  24.1938, -43.6552,  29.0049]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   1.0000,   1.0000,   2.0000],\n",
      "        [211.0000, 218.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [229.0000, 206.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [216.0000, 107.0000,   0.9977,   1.0000,   5.0000],\n",
      "        [208.0000,  86.0000,   0.9988,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   1.0000,   1.0000,   2.0000],\n",
      "        [211.0000, 218.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [229.0000, 206.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [216.0000, 107.0000,   0.9977,   1.0000,   5.0000],\n",
      "        [208.0000,  86.0000,   0.9988,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   1.0000,   1.0000,   2.0000],\n",
      "        [211.0000, 218.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [229.0000, 206.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [216.0000, 107.0000,   0.9977,   1.0000,   5.0000],\n",
      "        [208.0000,  86.0000,   0.9988,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[272.9683, 377.2809,  40.1168, -53.7746,  47.0795],\n",
      "        [275.3290, 278.8095,  40.6188, -79.0873,  37.9271],\n",
      "        [229.8319, 222.0946,  27.7705, -59.1115,  28.5132],\n",
      "        [239.6504, 203.1445,  31.4798, -54.3504,  33.3006],\n",
      "        [234.0114, 117.6402,  12.9884, -34.6940,  17.8065],\n",
      "        [220.4801,  95.1083,  11.9824, -23.8930,  19.3161]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [178.0000, 276.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [179.0000, 256.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [183.0000, 156.0000,   0.9986,   1.0000,   5.0000],\n",
      "        [182.0000, 134.0000,   0.9956,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [178.0000, 276.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [179.0000, 256.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [183.0000, 156.0000,   0.9986,   1.0000,   5.0000],\n",
      "        [182.0000, 134.0000,   0.9956,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [178.0000, 276.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [179.0000, 256.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [183.0000, 156.0000,   0.9986,   1.0000,   5.0000],\n",
      "        [182.0000, 134.0000,   0.9956,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[269.8607, 369.8214,  44.3670, -61.1779,  48.6788],\n",
      "        [275.3290, 278.8095,  40.6187, -79.0873,  37.9271],\n",
      "        [196.9369, 278.6133,  33.2137, -66.4098,  33.9052],\n",
      "        [188.7484, 246.8095,  38.0203, -67.1122,  37.2662],\n",
      "        [197.9407, 158.1137,  21.2889, -47.3902,  23.4605],\n",
      "        [192.5762, 136.2276,  19.5534, -36.1928,  24.6320]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9998,   1.0000,   2.0000],\n",
      "        [179.0000, 297.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [176.0000, 277.0000,   0.9994,   1.0000,   4.0000],\n",
      "        [250.0000, 213.0000,   0.9990,   1.0000,   5.0000],\n",
      "        [270.0000, 222.0000,   0.9985,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9998,   1.0000,   2.0000],\n",
      "        [179.0000, 297.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [176.0000, 277.0000,   0.9994,   1.0000,   4.0000],\n",
      "        [250.0000, 213.0000,   0.9990,   1.0000,   5.0000],\n",
      "        [270.0000, 222.0000,   0.9985,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9998,   1.0000,   2.0000],\n",
      "        [179.0000, 297.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [176.0000, 277.0000,   0.9994,   1.0000,   4.0000],\n",
      "        [250.0000, 213.0000,   0.9990,   1.0000,   5.0000],\n",
      "        [270.0000, 222.0000,   0.9985,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[274.7527, 369.6029,  44.9666, -72.6070,  46.8421],\n",
      "        [275.3290, 278.8095,  40.6186, -79.0873,  37.9271],\n",
      "        [197.5235, 298.3309,  36.1275, -69.9696,  36.6982],\n",
      "        [185.9273, 266.2281,  40.8712, -72.3018,  39.4963],\n",
      "        [261.2189, 208.0865,  33.5027, -60.2645,  35.0469],\n",
      "        [282.2296, 221.3686,  33.3915, -56.5043,  38.2573]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   1.0000,   1.0000,   2.0000],\n",
      "        [211.0000, 218.0000,   0.9999,   1.0000,   3.0000],\n",
      "        [228.0000, 206.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [321.0000, 170.0000,   0.9995,   1.0000,   5.0000],\n",
      "        [343.0000, 174.0000,   0.9974,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   1.0000,   1.0000,   2.0000],\n",
      "        [211.0000, 218.0000,   0.9999,   1.0000,   3.0000],\n",
      "        [228.0000, 206.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [321.0000, 170.0000,   0.9995,   1.0000,   5.0000],\n",
      "        [343.0000, 174.0000,   0.9974,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   1.0000,   1.0000,   2.0000],\n",
      "        [211.0000, 218.0000,   0.9999,   1.0000,   3.0000],\n",
      "        [228.0000, 206.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [321.0000, 170.0000,   0.9995,   1.0000,   5.0000],\n",
      "        [343.0000, 174.0000,   0.9974,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[283.0145, 384.0441,  36.7429, -63.1326,  42.6496],\n",
      "        [275.3290, 278.8095,  40.6188, -79.0873,  37.9271],\n",
      "        [229.8319, 222.0946,  27.7706, -59.1115,  28.5132],\n",
      "        [238.6530, 203.1316,  31.4533, -54.3491,  33.2595],\n",
      "        [333.5624, 172.8270,  27.7329, -47.2541,  32.7048],\n",
      "        [358.6934, 182.2811,  26.5059, -45.4441,  34.3364]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [183.0000, 254.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [190.0000, 235.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [106.0000, 181.0000,   0.9984,   1.0000,   5.0000],\n",
      "        [100.0000, 161.0000,   0.9977,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [183.0000, 254.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [190.0000, 235.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [106.0000, 181.0000,   0.9984,   1.0000,   5.0000],\n",
      "        [100.0000, 161.0000,   0.9977,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [183.0000, 254.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [190.0000, 235.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [106.0000, 181.0000,   0.9984,   1.0000,   5.0000],\n",
      "        [100.0000, 161.0000,   0.9977,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[263.9265, 360.6124,  49.2638, -65.4583,  51.2689],\n",
      "        [275.3290, 278.8095,  40.6188, -79.0873,  37.9271],\n",
      "        [202.1958, 257.5068,  30.6771, -63.3966,  31.3761],\n",
      "        [199.7762, 227.7861,  35.2606, -61.9150,  35.3047],\n",
      "        [123.9685, 187.1740,  18.6814, -45.9761,  21.5875],\n",
      "        [106.9958, 155.7195,  23.2187, -42.0962,  25.7382]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [304.0000, 218.0000,   0.9995,   1.0000,   3.0000],\n",
      "        [321.0000, 230.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [381.0000, 309.0000,   0.9989,   1.0000,   5.0000],\n",
      "        [398.0000, 324.0000,   0.9974,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [304.0000, 218.0000,   0.9995,   1.0000,   3.0000],\n",
      "        [321.0000, 230.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [381.0000, 309.0000,   0.9989,   1.0000,   5.0000],\n",
      "        [398.0000, 324.0000,   0.9974,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [304.0000, 218.0000,   0.9995,   1.0000,   3.0000],\n",
      "        [321.0000, 230.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [381.0000, 309.0000,   0.9989,   1.0000,   5.0000],\n",
      "        [398.0000, 324.0000,   0.9974,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[287.7683, 380.1958,  39.0054, -80.7582,  40.4388],\n",
      "        [275.3290, 278.8095,  40.6187, -79.0873,  37.9271],\n",
      "        [319.1943, 218.0498,  33.5737, -62.1514,  34.4682],\n",
      "        [335.5781, 232.3573,  34.6301, -58.6513,  38.5456],\n",
      "        [396.8685, 311.7361,  44.2257, -69.8276,  50.4907],\n",
      "        [416.3163, 323.9341,  48.2397, -82.6675,  53.1736]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [178.0000, 276.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [180.0000, 255.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [209.0000, 161.0000,   0.9991,   1.0000,   5.0000],\n",
      "        [230.0000, 167.0000,   0.9983,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [178.0000, 276.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [180.0000, 255.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [209.0000, 161.0000,   0.9991,   1.0000,   5.0000],\n",
      "        [230.0000, 167.0000,   0.9983,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [178.0000, 276.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [180.0000, 255.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [209.0000, 161.0000,   0.9991,   1.0000,   5.0000],\n",
      "        [230.0000, 167.0000,   0.9983,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[272.7364, 371.0272,  43.9244, -65.3384,  47.5445],\n",
      "        [275.3290, 278.8095,  40.6187, -79.0873,  37.9271],\n",
      "        [196.9369, 278.6133,  33.2137, -66.4098,  33.9052],\n",
      "        [189.7770, 245.8890,  37.9070, -66.9605,  37.1711],\n",
      "        [222.8213, 161.7777,  23.5444, -48.8855,  25.7862],\n",
      "        [240.3832, 168.1813,  25.3426, -42.5723,  30.8636]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [282.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [302.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [398.0000, 191.0000,   0.9983,   1.0000,   5.0000],\n",
      "        [417.0000, 178.0000,   0.9960,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [282.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [302.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [398.0000, 191.0000,   0.9983,   1.0000,   5.0000],\n",
      "        [417.0000, 178.0000,   0.9960,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [282.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [302.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [398.0000, 191.0000,   0.9983,   1.0000,   5.0000],\n",
      "        [417.0000, 178.0000,   0.9960,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[291.0576, 394.6582,  30.7083, -60.4382,  38.6128],\n",
      "        [275.3290, 278.8095,  40.6188, -79.0873,  37.9271],\n",
      "        [298.2749, 208.5565,  30.7801, -59.8394,  31.6384],\n",
      "        [315.5585, 214.9796,  32.3889, -54.8831,  36.1501],\n",
      "        [413.5999, 197.4400,  30.8581, -51.7913,  37.2985],\n",
      "        [436.7895, 190.8495,  27.2202, -48.7294,  36.1984]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [257.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [194.0000, 235.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [206.0000, 218.0000,   0.9996,   1.0000,   4.0000],\n",
      "        [264.0000, 136.0000,   0.9972,   1.0000,   5.0000],\n",
      "        [281.0000, 124.0000,   0.9978,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [257.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [194.0000, 235.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [206.0000, 218.0000,   0.9996,   1.0000,   4.0000],\n",
      "        [264.0000, 136.0000,   0.9972,   1.0000,   5.0000],\n",
      "        [281.0000, 124.0000,   0.9978,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [257.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [194.0000, 235.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [206.0000, 218.0000,   0.9996,   1.0000,   4.0000],\n",
      "        [264.0000, 136.0000,   0.9972,   1.0000,   5.0000],\n",
      "        [281.0000, 124.0000,   0.9978,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[278.1749, 381.2268,  38.1567, -57.8269,  44.8259],\n",
      "        [274.3681, 278.8530,  40.5564, -79.0548,  37.8630],\n",
      "        [213.0161, 238.7912,  29.0185, -61.0814,  29.6950],\n",
      "        [216.1165, 212.9336,  33.0001, -57.6233,  33.8924],\n",
      "        [277.8264, 140.1204,  21.3363, -42.2890,  25.3940],\n",
      "        [294.4908, 132.2327,  19.1126, -33.8890,  26.6576]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [296.0000, 213.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [314.0000, 223.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [319.0000, 321.0000,   0.9963,   1.0000,   5.0000],\n",
      "        [320.0000, 344.0000,   0.9841,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [296.0000, 213.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [314.0000, 223.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [319.0000, 321.0000,   0.9963,   1.0000,   5.0000],\n",
      "        [320.0000, 344.0000,   0.9841,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [296.0000, 213.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [314.0000, 223.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [319.0000, 321.0000,   0.9963,   1.0000,   5.0000],\n",
      "        [320.0000, 344.0000,   0.9841,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[277.8968, 365.2104,  47.6676, -87.9024,  45.5780],\n",
      "        [275.3290, 278.8095,  40.6188, -79.0873,  37.9271],\n",
      "        [311.6072, 213.6478,  32.4287, -61.1656,  33.3100],\n",
      "        [328.1981, 225.2854,  33.6958, -57.0610,  37.5815],\n",
      "        [336.2633, 325.1617,  42.3005, -69.1138,  48.4818],\n",
      "        [335.8472, 338.8477,  50.0234, -85.9370,  53.1361]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 282.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [194.0000, 235.0000,   0.9999,   1.0000,   3.0000],\n",
      "        [206.0000, 218.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [305.0000, 231.0000,   0.9993,   1.0000,   5.0000],\n",
      "        [317.0000, 248.0000,   0.9948,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 282.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [194.0000, 235.0000,   0.9999,   1.0000,   3.0000],\n",
      "        [206.0000, 218.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [305.0000, 231.0000,   0.9993,   1.0000,   5.0000],\n",
      "        [317.0000, 248.0000,   0.9948,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 282.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [194.0000, 235.0000,   0.9999,   1.0000,   3.0000],\n",
      "        [206.0000, 218.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [305.0000, 231.0000,   0.9993,   1.0000,   5.0000],\n",
      "        [317.0000, 248.0000,   0.9948,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[278.7456, 373.0321,  43.1297, -74.8552,  44.9870],\n",
      "        [275.3931, 277.9282,  40.4457, -78.9034,  37.7700],\n",
      "        [213.0923, 238.9551,  28.9293, -60.9396,  29.6608],\n",
      "        [216.1165, 212.9336,  33.0002, -57.6233,  33.8924],\n",
      "        [315.2854, 228.5143,  36.2184, -57.4538,  40.3183],\n",
      "        [331.9103, 249.4630,  36.6817, -62.4977,  42.2178]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Processing batch 2 with images: ('001265.rgb.jpg', '000294.rgb.jpg', '000046.rgb.jpg', '001005.rgb.jpg', '000698.rgb.jpg', '000266.rgb.jpg', '000593.rgb.jpg', '000671.rgb.jpg', '000754.rgb.jpg', '000446.rgb.jpg', '000610.rgb.jpg', '000806.rgb.jpg', '001009.rgb.jpg', '001239.rgb.jpg', '000066.rgb.jpg', '000839.rgb.jpg')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [310.0000, 223.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [326.0000, 237.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [407.0000, 292.0000,   0.9990,   1.0000,   5.0000],\n",
      "        [425.0000, 306.0000,   0.9966,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [310.0000, 223.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [326.0000, 237.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [407.0000, 292.0000,   0.9990,   1.0000,   5.0000],\n",
      "        [425.0000, 306.0000,   0.9966,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [310.0000, 223.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [326.0000, 237.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [407.0000, 292.0000,   0.9990,   1.0000,   5.0000],\n",
      "        [425.0000, 306.0000,   0.9966,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[290.5112, 385.9782,  34.8030, -75.8586,  38.1129],\n",
      "        [274.8946, 278.9728,  39.7658, -78.1051,  37.3763],\n",
      "        [324.4539, 222.5775,  33.9240, -62.3166,  35.0348],\n",
      "        [340.4619, 239.2930,  34.9357, -59.5541,  39.0120],\n",
      "        [422.2240, 294.6932,  42.7770, -68.0620,  49.1629],\n",
      "        [444.0237, 309.2318,  44.8586, -77.5748,  51.1402]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [183.0000, 254.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [191.0000, 234.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [224.0000, 141.0000,   0.9988,   1.0000,   5.0000],\n",
      "        [238.0000, 123.0000,   0.9978,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [183.0000, 254.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [191.0000, 234.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [224.0000, 141.0000,   0.9988,   1.0000,   5.0000],\n",
      "        [238.0000, 123.0000,   0.9978,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [183.0000, 254.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [191.0000, 234.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [224.0000, 141.0000,   0.9988,   1.0000,   5.0000],\n",
      "        [238.0000, 123.0000,   0.9978,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[274.0162, 376.4891,  40.0687, -57.8913,  46.0558],\n",
      "        [274.8946, 278.9728,  39.7658, -78.1051,  37.3763],\n",
      "        [201.7942, 257.5798,  29.9944, -62.5747,  30.9325],\n",
      "        [200.5058, 227.0369,  34.4884, -61.0479,  34.7869],\n",
      "        [237.9080, 144.1988,  20.3072, -43.3061,  23.6116],\n",
      "        [249.6354, 128.5144,  18.4282, -33.3941,  25.0180]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9998,   1.0000,   2.0000],\n",
      "        [180.0000, 297.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [176.0000, 277.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [155.0000, 180.0000,   0.9949,   1.0000,   5.0000],\n",
      "        [175.0000, 171.0000,   0.9948,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9998,   1.0000,   2.0000],\n",
      "        [180.0000, 297.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [176.0000, 277.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [155.0000, 180.0000,   0.9949,   1.0000,   5.0000],\n",
      "        [175.0000, 171.0000,   0.9948,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9998,   1.0000,   2.0000],\n",
      "        [180.0000, 297.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [176.0000, 277.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [155.0000, 180.0000,   0.9949,   1.0000,   5.0000],\n",
      "        [175.0000, 171.0000,   0.9948,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[268.1327, 365.5814,  46.1400, -65.7805,  48.8857],\n",
      "        [274.8946, 278.9728,  39.7657, -78.1051,  37.3763],\n",
      "        [198.0226, 298.3340,  35.4827, -69.1558,  36.3054],\n",
      "        [185.6906, 266.5807,  40.0421, -71.4404,  38.9776],\n",
      "        [170.3306, 181.0253,  22.6814, -51.6402,  24.2999],\n",
      "        [182.8937, 167.6631,  25.6344, -44.2008,  29.5092]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [281.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [301.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [385.0000, 265.0000,   0.9974,   1.0000,   5.0000],\n",
      "        [401.0000, 251.0000,   0.9973,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [281.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [301.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [385.0000, 265.0000,   0.9974,   1.0000,   5.0000],\n",
      "        [401.0000, 251.0000,   0.9973,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [281.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [301.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [385.0000, 265.0000,   0.9974,   1.0000,   5.0000],\n",
      "        [401.0000, 251.0000,   0.9973,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[287.7077, 385.7638,  35.0227, -70.2456,  39.5863],\n",
      "        [274.8946, 278.9728,  39.7658, -78.1051,  37.3763],\n",
      "        [296.9129, 208.6187,  30.0833, -59.0703,  31.1395],\n",
      "        [314.1364, 214.8991,  31.8237, -54.2697,  35.7206],\n",
      "        [399.0947, 268.1310,  39.0329, -61.4673,  45.5798],\n",
      "        [419.6350, 256.4585,  37.2523, -66.4917,  43.8154]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [233.0000, 207.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [253.0000, 201.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [348.0000, 224.0000,   0.9983,   1.0000,   5.0000],\n",
      "        [370.0000, 232.0000,   0.9973,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [233.0000, 207.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [253.0000, 201.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [348.0000, 224.0000,   0.9983,   1.0000,   5.0000],\n",
      "        [370.0000, 232.0000,   0.9973,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [233.0000, 207.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [253.0000, 201.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [348.0000, 224.0000,   0.9983,   1.0000,   5.0000],\n",
      "        [370.0000, 232.0000,   0.9973,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[284.3232, 382.4309,  36.9585, -69.2710,  41.3134],\n",
      "        [274.8946, 278.9728,  39.7658, -78.1051,  37.3763],\n",
      "        [250.8063, 210.7232,  27.0910, -57.4848,  28.0779],\n",
      "        [264.1485, 200.2271,  30.2523, -52.1255,  33.0681],\n",
      "        [360.0113, 225.7865,  34.2688, -54.2777,  40.0779],\n",
      "        [386.4140, 237.2269,  34.3828, -59.2596,  41.3500]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [183.0000, 253.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [191.0000, 234.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [267.0000, 170.0000,   0.9993,   1.0000,   5.0000],\n",
      "        [284.0000, 185.0000,   0.9982,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [183.0000, 253.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [191.0000, 234.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [267.0000, 170.0000,   0.9993,   1.0000,   5.0000],\n",
      "        [284.0000, 185.0000,   0.9982,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [183.0000, 253.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [191.0000, 234.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [267.0000, 170.0000,   0.9993,   1.0000,   5.0000],\n",
      "        [284.0000, 185.0000,   0.9982,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[276.4573, 375.1890,  41.0068, -65.8882,  45.1270],\n",
      "        [274.8946, 278.9728,  39.7658, -78.1051,  37.3763],\n",
      "        [201.8308, 256.6538,  29.8506, -62.4175,  30.7939],\n",
      "        [200.4472, 227.0102,  34.5116, -60.9785,  34.8250],\n",
      "        [278.6645, 169.9602,  26.6466, -48.8431,  30.0460],\n",
      "        [296.7830, 189.1409,  27.1165, -45.9789,  33.8131]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   1.0000,   1.0000,   2.0000],\n",
      "        [211.0000, 218.0000,   0.9996,   1.0000,   3.0000],\n",
      "        [228.0000, 206.0000,   0.9996,   1.0000,   4.0000],\n",
      "        [191.0000, 114.0000,   0.9982,   1.0000,   5.0000],\n",
      "        [202.0000,  96.0000,   0.9966,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   1.0000,   1.0000,   2.0000],\n",
      "        [211.0000, 218.0000,   0.9996,   1.0000,   3.0000],\n",
      "        [228.0000, 206.0000,   0.9996,   1.0000,   4.0000],\n",
      "        [191.0000, 114.0000,   0.9982,   1.0000,   5.0000],\n",
      "        [202.0000,  96.0000,   0.9966,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   1.0000,   1.0000,   2.0000],\n",
      "        [211.0000, 218.0000,   0.9996,   1.0000,   3.0000],\n",
      "        [228.0000, 206.0000,   0.9996,   1.0000,   4.0000],\n",
      "        [191.0000, 114.0000,   0.9982,   1.0000,   5.0000],\n",
      "        [202.0000,  96.0000,   0.9966,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[271.8203, 375.6464,  40.4010, -54.5737,  46.9547],\n",
      "        [274.8946, 278.9728,  39.7659, -78.1051,  37.3763],\n",
      "        [229.4431, 222.1391,  27.1299, -58.3390,  28.0897],\n",
      "        [238.3384, 203.2050,  30.8857, -53.7362,  32.8763],\n",
      "        [209.4102, 125.1275,  12.0363, -34.4259,  16.8930],\n",
      "        [212.1993, 101.5968,  14.3703, -26.3227,  20.9785]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [232.0000, 207.0000,   0.9995,   1.0000,   3.0000],\n",
      "        [252.0000, 201.0000,   0.9996,   1.0000,   4.0000],\n",
      "        [346.0000, 170.0000,   0.9952,   1.0000,   5.0000],\n",
      "        [357.0000, 151.0000,   0.9989,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [232.0000, 207.0000,   0.9995,   1.0000,   3.0000],\n",
      "        [252.0000, 201.0000,   0.9996,   1.0000,   4.0000],\n",
      "        [346.0000, 170.0000,   0.9952,   1.0000,   5.0000],\n",
      "        [357.0000, 151.0000,   0.9989,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [232.0000, 207.0000,   0.9995,   1.0000,   3.0000],\n",
      "        [252.0000, 201.0000,   0.9996,   1.0000,   4.0000],\n",
      "        [346.0000, 170.0000,   0.9952,   1.0000,   5.0000],\n",
      "        [357.0000, 151.0000,   0.9989,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[284.4024, 388.1736,  33.6197, -58.3995,  41.1147],\n",
      "        [274.8946, 278.9728,  39.7658, -78.1051,  37.3763],\n",
      "        [249.8590, 210.7878,  27.0151, -57.4397,  28.0056],\n",
      "        [263.1021, 200.1588,  30.2517, -52.1176,  33.0449],\n",
      "        [359.1695, 174.5346,  27.2268, -46.3876,  33.0192],\n",
      "        [374.3450, 162.4863,  22.4290, -41.4095,  30.9096]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [257.0000, 203.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [278.0000, 203.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [363.0000, 253.0000,   0.9988,   1.0000,   5.0000],\n",
      "        [383.0000, 261.0000,   0.9954,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [257.0000, 203.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [278.0000, 203.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [363.0000, 253.0000,   0.9988,   1.0000,   5.0000],\n",
      "        [383.0000, 261.0000,   0.9954,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [257.0000, 203.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [278.0000, 203.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [363.0000, 253.0000,   0.9988,   1.0000,   5.0000],\n",
      "        [383.0000, 261.0000,   0.9954,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[285.4759, 382.0281,  37.1776, -72.5457,  40.7496],\n",
      "        [274.8946, 278.9728,  39.7658, -78.1051,  37.3763],\n",
      "        [273.9554, 205.8895,  28.0621, -57.6909,  29.0864],\n",
      "        [290.1169, 203.8729,  30.5125, -52.2202,  33.9902],\n",
      "        [376.0410, 255.4639,  37.3811, -58.5271,  43.6987],\n",
      "        [400.0482, 264.7139,  38.5665, -66.6701,  44.9875]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [194.0000, 235.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [206.0000, 218.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [283.0000, 155.0000,   0.9988,   1.0000,   5.0000],\n",
      "        [305.0000, 156.0000,   0.9989,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [194.0000, 235.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [206.0000, 218.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [283.0000, 155.0000,   0.9988,   1.0000,   5.0000],\n",
      "        [305.0000, 156.0000,   0.9989,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [194.0000, 235.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [206.0000, 218.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [283.0000, 155.0000,   0.9988,   1.0000,   5.0000],\n",
      "        [305.0000, 156.0000,   0.9989,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[279.1172, 380.7701,  37.8109, -61.0026,  43.7430],\n",
      "        [274.8946, 278.9728,  39.7658, -78.1051,  37.3763],\n",
      "        [212.7427, 239.0161,  28.2630, -60.2299,  29.2011],\n",
      "        [215.8086, 213.0494,  32.3962, -56.9684,  33.4961],\n",
      "        [295.3409, 157.2798,  24.5098, -45.1146,  28.7244],\n",
      "        [318.6180, 162.9823,  23.4727, -40.4567,  30.9783]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [232.0000, 207.0000,   0.9981,   1.0000,   3.0000],\n",
      "        [251.0000, 201.0000,   0.9996,   1.0000,   4.0000],\n",
      "        [216.0000, 107.0000,   0.9978,   1.0000,   5.0000],\n",
      "        [211.0000,  86.0000,   0.9970,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [232.0000, 207.0000,   0.9981,   1.0000,   3.0000],\n",
      "        [251.0000, 201.0000,   0.9996,   1.0000,   4.0000],\n",
      "        [216.0000, 107.0000,   0.9978,   1.0000,   5.0000],\n",
      "        [211.0000,  86.0000,   0.9970,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [232.0000, 207.0000,   0.9981,   1.0000,   3.0000],\n",
      "        [251.0000, 201.0000,   0.9996,   1.0000,   4.0000],\n",
      "        [216.0000, 107.0000,   0.9978,   1.0000,   5.0000],\n",
      "        [211.0000,  86.0000,   0.9970,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[272.7591, 377.5646,  39.3212, -52.9656,  46.4891],\n",
      "        [274.8946, 278.9728,  39.7658, -78.1051,  37.3763],\n",
      "        [249.8589, 210.7877,  27.0138, -57.4396,  28.0057],\n",
      "        [262.0994, 200.1370,  30.2314, -52.1226,  33.0080],\n",
      "        [235.5027, 120.2216,  11.1375, -33.0826,  16.6829],\n",
      "        [223.0764,  94.7958,  11.9584, -23.7438,  19.3297]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [257.0000, 203.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [279.0000, 203.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [350.0000, 134.0000,   0.9980,   1.0000,   5.0000],\n",
      "        [358.0000, 113.0000,   0.9988,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [257.0000, 203.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [279.0000, 203.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [350.0000, 134.0000,   0.9980,   1.0000,   5.0000],\n",
      "        [358.0000, 113.0000,   0.9988,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [257.0000, 203.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [279.0000, 203.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [350.0000, 134.0000,   0.9980,   1.0000,   5.0000],\n",
      "        [358.0000, 113.0000,   0.9988,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[285.3159, 392.0737,  31.3517, -52.8911,  40.5634],\n",
      "        [274.8946, 278.9728,  39.7658, -78.1051,  37.3763],\n",
      "        [273.9554, 205.8895,  28.0620, -57.6909,  29.0864],\n",
      "        [291.1213, 203.8981,  30.5303, -52.2122,  34.0259],\n",
      "        [366.1011, 143.0865,  21.2444, -40.8793,  27.5342],\n",
      "        [375.7850, 128.1255,  16.7272, -31.9887,  26.3628]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [281.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [301.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [386.0000, 266.0000,   0.9979,   1.0000,   5.0000],\n",
      "        [407.0000, 264.0000,   0.9985,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [281.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [301.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [386.0000, 266.0000,   0.9979,   1.0000,   5.0000],\n",
      "        [407.0000, 264.0000,   0.9985,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [281.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [301.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [386.0000, 266.0000,   0.9979,   1.0000,   5.0000],\n",
      "        [407.0000, 264.0000,   0.9985,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[288.3333, 385.7492,  35.0162, -71.6240,  39.2666],\n",
      "        [274.8946, 278.9728,  39.7658, -78.1051,  37.3763],\n",
      "        [296.9129, 208.6187,  30.0833, -59.0703,  31.1395],\n",
      "        [314.1364, 214.8991,  31.8237, -54.2697,  35.7206],\n",
      "        [400.0949, 269.1322,  39.1629, -61.5882,  45.7334],\n",
      "        [425.2346, 268.6042,  39.2631, -68.6880,  45.8186]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 282.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [310.0000, 222.0000,   0.9990,   1.0000,   3.0000],\n",
      "        [326.0000, 236.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [350.0000, 332.0000,   0.9994,   1.0000,   5.0000],\n",
      "        [342.0000, 349.0000,   0.9851,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 282.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [310.0000, 222.0000,   0.9990,   1.0000,   3.0000],\n",
      "        [326.0000, 236.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [350.0000, 332.0000,   0.9994,   1.0000,   5.0000],\n",
      "        [342.0000, 349.0000,   0.9851,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 282.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [310.0000, 222.0000,   0.9990,   1.0000,   3.0000],\n",
      "        [326.0000, 236.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [350.0000, 332.0000,   0.9994,   1.0000,   5.0000],\n",
      "        [342.0000, 349.0000,   0.9851,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[280.2265, 368.9572,  44.6271, -86.0920,  43.4755],\n",
      "        [274.9587, 278.0901,  39.5942, -77.9219,  37.2200],\n",
      "        [324.4560, 221.6636,  33.7781, -62.0655,  34.9187],\n",
      "        [340.4639, 238.3791,  34.7903, -59.3030,  38.8960],\n",
      "        [366.6536, 335.2285,  44.3421, -71.9200,  50.6709],\n",
      "        [359.0809, 345.5378,  49.6262, -87.0478,  53.3136]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9998,   1.0000,   2.0000],\n",
      "        [179.0000, 298.0000,   0.9996,   1.0000,   3.0000],\n",
      "        [176.0000, 277.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [110.0000, 203.0000,   0.9924,   1.0000,   5.0000],\n",
      "        [129.0000, 193.0000,   0.9906,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9998,   1.0000,   2.0000],\n",
      "        [179.0000, 298.0000,   0.9996,   1.0000,   3.0000],\n",
      "        [176.0000, 277.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [110.0000, 203.0000,   0.9924,   1.0000,   5.0000],\n",
      "        [129.0000, 193.0000,   0.9906,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9998,   1.0000,   2.0000],\n",
      "        [179.0000, 298.0000,   0.9996,   1.0000,   3.0000],\n",
      "        [176.0000, 277.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [110.0000, 203.0000,   0.9924,   1.0000,   5.0000],\n",
      "        [129.0000, 193.0000,   0.9906,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[264.7705, 359.9315,  49.1639, -69.0664,  50.3610],\n",
      "        [274.8946, 278.9728,  39.7657, -78.1051,  37.3763],\n",
      "        [197.0915, 299.4064,  35.4984, -69.2211,  36.3381],\n",
      "        [185.6597, 266.4869,  40.0863, -71.5436,  38.9828],\n",
      "        [126.6016, 204.8129,  22.8474, -53.4884,  24.4027],\n",
      "        [134.7934, 184.6678,  28.7836, -49.4613,  30.9582]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [259.0000, 203.0000,   0.9993,   1.0000,   3.0000],\n",
      "        [279.0000, 203.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [279.0000, 105.0000,   0.9974,   1.0000,   5.0000],\n",
      "        [287.0000,  84.0000,   0.9974,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [259.0000, 203.0000,   0.9993,   1.0000,   3.0000],\n",
      "        [279.0000, 203.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [279.0000, 105.0000,   0.9974,   1.0000,   5.0000],\n",
      "        [287.0000,  84.0000,   0.9974,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [259.0000, 203.0000,   0.9993,   1.0000,   3.0000],\n",
      "        [279.0000, 203.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [279.0000, 105.0000,   0.9974,   1.0000,   5.0000],\n",
      "        [287.0000,  84.0000,   0.9974,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[279.2033, 386.0392,  34.6711, -50.9850,  43.4640],\n",
      "        [274.8946, 278.9728,  39.7658, -78.1051,  37.3763],\n",
      "        [275.8776, 205.8035,  28.1851, -57.7559,  29.2133],\n",
      "        [291.2054, 203.9846,  30.4956, -52.2438,  34.0008],\n",
      "        [298.4203, 118.5041,  13.1910, -34.4512,  19.3330],\n",
      "        [301.5452,  96.7657,  12.4721, -24.1548,  21.3552]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Processing batch 3 with images: ('000856.rgb.jpg', '000883.rgb.jpg', '001021.rgb.jpg', '001223.rgb.jpg', '000977.rgb.jpg', '001077.rgb.jpg', '000752.rgb.jpg', '001187.rgb.jpg', '001073.rgb.jpg', '000076.rgb.jpg', '001056.rgb.jpg', '000886.rgb.jpg', '000022.rgb.jpg', '000129.rgb.jpg', '000674.rgb.jpg', '001212.rgb.jpg')\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   1.0000,   1.0000,   2.0000],\n",
      "        [282.0000, 207.0000,   0.9996,   1.0000,   3.0000],\n",
      "        [302.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [332.0000, 119.0000,   0.9989,   1.0000,   5.0000],\n",
      "        [348.0000, 106.0000,   0.9930,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   1.0000,   1.0000,   2.0000],\n",
      "        [282.0000, 207.0000,   0.9996,   1.0000,   3.0000],\n",
      "        [302.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [332.0000, 119.0000,   0.9989,   1.0000,   5.0000],\n",
      "        [348.0000, 106.0000,   0.9930,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   1.0000,   1.0000,   2.0000],\n",
      "        [282.0000, 207.0000,   0.9996,   1.0000,   3.0000],\n",
      "        [302.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [332.0000, 119.0000,   0.9989,   1.0000,   5.0000],\n",
      "        [348.0000, 106.0000,   0.9930,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[283.8412, 391.1837,  31.1375, -51.4182,  40.5964],\n",
      "        [274.3301, 278.9933,  39.0702, -77.1120,  36.9963],\n",
      "        [297.3792, 208.5132,  29.6206, -58.3283,  30.9098],\n",
      "        [314.7006, 214.8481,  31.3726, -53.6426,  35.4814],\n",
      "        [350.7431, 131.5189,  16.6845, -38.1120,  23.2445],\n",
      "        [363.9637, 119.9903,  15.9367, -29.2432,  25.6637]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [282.0000, 207.0000,   0.9999,   1.0000,   3.0000],\n",
      "        [302.0000, 214.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [391.0000, 170.0000,   0.9983,   1.0000,   5.0000],\n",
      "        [413.0000, 169.0000,   0.9981,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [282.0000, 207.0000,   0.9999,   1.0000,   3.0000],\n",
      "        [302.0000, 214.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [391.0000, 170.0000,   0.9983,   1.0000,   5.0000],\n",
      "        [413.0000, 169.0000,   0.9981,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [282.0000, 207.0000,   0.9999,   1.0000,   3.0000],\n",
      "        [302.0000, 214.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [391.0000, 170.0000,   0.9983,   1.0000,   5.0000],\n",
      "        [413.0000, 169.0000,   0.9981,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[289.4319, 394.3799,  29.3194, -57.5627,  37.8741],\n",
      "        [274.3301, 278.9933,  39.0702, -77.1120,  36.9963],\n",
      "        [297.3792, 208.5132,  29.6208, -58.3284,  30.9098],\n",
      "        [314.6933, 215.8188,  31.4866, -53.7761,  35.6004],\n",
      "        [406.4062, 177.4958,  26.7619, -47.3667,  33.4510],\n",
      "        [431.0763, 181.8588,  25.1178, -44.2450,  34.7552]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [282.0000, 206.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [301.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [395.0000, 242.0000,   0.9992,   1.0000,   5.0000],\n",
      "        [398.0000, 220.0000,   0.9945,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [282.0000, 206.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [301.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [395.0000, 242.0000,   0.9992,   1.0000,   5.0000],\n",
      "        [398.0000, 220.0000,   0.9945,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [282.0000, 206.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [301.0000, 213.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [395.0000, 242.0000,   0.9992,   1.0000,   5.0000],\n",
      "        [398.0000, 220.0000,   0.9945,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[287.0036, 387.6293,  33.1907, -65.2705,  39.1750],\n",
      "        [274.3301, 278.9933,  39.0702, -77.1120,  36.9963],\n",
      "        [297.4413, 207.6263,  29.4527, -58.1476,  30.7557],\n",
      "        [313.6950, 214.8825,  31.3234, -53.5354,  35.4486],\n",
      "        [408.5999, 245.6598,  36.2134, -57.7474,  42.9640],\n",
      "        [417.2368, 228.9084,  31.5632, -58.4445,  39.2267]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 366.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [310.0000, 223.0000,   0.9992,   1.0000,   3.0000],\n",
      "        [326.0000, 237.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [322.0000, 335.0000,   0.9750,   1.0000,   5.0000],\n",
      "        [308.0000, 339.0000,   0.9653,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 366.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [310.0000, 223.0000,   0.9992,   1.0000,   3.0000],\n",
      "        [326.0000, 237.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [322.0000, 335.0000,   0.9750,   1.0000,   5.0000],\n",
      "        [308.0000, 339.0000,   0.9653,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 366.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [310.0000, 223.0000,   0.9992,   1.0000,   3.0000],\n",
      "        [326.0000, 237.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [322.0000, 335.0000,   0.9750,   1.0000,   5.0000],\n",
      "        [308.0000, 339.0000,   0.9653,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[275.2763, 362.6571,  46.8787, -85.7497,  45.2091],\n",
      "        [274.2689, 278.9620,  39.0971, -77.0462,  37.0368],\n",
      "        [323.9341, 222.5056,  33.3839, -61.5291,  34.7300],\n",
      "        [339.9353, 239.1637,  34.4396, -58.8598,  38.7233],\n",
      "        [339.0602, 339.0666,  42.3911, -70.7399,  48.9068],\n",
      "        [323.4860, 333.9487,  47.4560, -84.7590,  50.6658]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [281.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [301.0000, 213.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [323.0000, 308.0000,   0.9959,   1.0000,   5.0000],\n",
      "        [338.0000, 298.0000,   0.9981,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [281.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [301.0000, 213.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [323.0000, 308.0000,   0.9959,   1.0000,   5.0000],\n",
      "        [338.0000, 298.0000,   0.9981,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [281.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [301.0000, 213.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [323.0000, 308.0000,   0.9959,   1.0000,   5.0000],\n",
      "        [338.0000, 298.0000,   0.9981,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[279.1509, 371.6725,  42.3736, -78.8683,  43.2984],\n",
      "        [274.3301, 278.9933,  39.0702, -77.1120,  36.9963],\n",
      "        [296.4056, 208.5363,  29.5720, -58.3078,  30.8548],\n",
      "        [313.6552, 214.7810,  31.3720, -53.6350,  35.4583],\n",
      "        [338.0105, 311.4313,  40.1959, -64.9851,  46.8503],\n",
      "        [352.8859, 295.0815,  43.4162, -76.5855,  47.5408]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [283.0000, 207.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [302.0000, 213.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [356.0000, 130.0000,   0.9982,   1.0000,   5.0000],\n",
      "        [363.0000, 109.0000,   0.9985,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [283.0000, 207.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [302.0000, 213.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [356.0000, 130.0000,   0.9982,   1.0000,   5.0000],\n",
      "        [363.0000, 109.0000,   0.9985,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [283.0000, 207.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [302.0000, 213.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [356.0000, 130.0000,   0.9982,   1.0000,   5.0000],\n",
      "        [363.0000, 109.0000,   0.9985,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[285.2724, 392.8866,  30.1709, -51.2862,  39.8884],\n",
      "        [274.3301, 278.9933,  39.0702, -77.1120,  36.9963],\n",
      "        [298.3532, 208.4908,  29.6689, -58.3484,  30.9646],\n",
      "        [314.7442, 214.8931,  31.3538, -53.6583,  35.4680],\n",
      "        [373.5870, 140.9735,  19.5384, -40.4386,  26.1558],\n",
      "        [380.6045, 124.5603,  15.8907, -30.6326,  25.8499]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [257.0000, 203.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [278.0000, 203.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [363.0000, 253.0000,   0.9995,   1.0000,   5.0000],\n",
      "        [381.0000, 267.0000,   0.9977,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [257.0000, 203.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [278.0000, 203.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [363.0000, 253.0000,   0.9995,   1.0000,   5.0000],\n",
      "        [381.0000, 267.0000,   0.9977,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [257.0000, 203.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [278.0000, 203.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [363.0000, 253.0000,   0.9995,   1.0000,   5.0000],\n",
      "        [381.0000, 267.0000,   0.9977,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[284.5049, 381.0699,  36.9448, -72.4463,  40.4969],\n",
      "        [274.3301, 278.9933,  39.0702, -77.1120,  36.9963],\n",
      "        [273.4550, 205.8056,  27.5605, -56.9356,  28.8095],\n",
      "        [289.6666, 203.7766,  30.0748, -51.6074,  33.7379],\n",
      "        [375.5085, 255.3361,  36.8644, -57.8001,  43.3854],\n",
      "        [397.4518, 270.4159,  38.6084, -66.6591,  45.2725]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [296.0000, 213.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [314.0000, 223.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [366.0000, 308.0000,   0.9989,   1.0000,   5.0000],\n",
      "        [358.0000, 324.0000,   0.9908,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [296.0000, 213.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [314.0000, 223.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [366.0000, 308.0000,   0.9989,   1.0000,   5.0000],\n",
      "        [358.0000, 324.0000,   0.9908,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [296.0000, 213.0000,   0.9997,   1.0000,   3.0000],\n",
      "        [314.0000, 223.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [366.0000, 308.0000,   0.9989,   1.0000,   5.0000],\n",
      "        [358.0000, 324.0000,   0.9908,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[281.4576, 373.1380,  41.4578, -81.0417,  42.0759],\n",
      "        [274.3301, 278.9933,  39.0702, -77.1120,  36.9963],\n",
      "        [310.7029, 213.6140,  31.2449, -59.6392,  32.5621],\n",
      "        [327.3030, 225.1431,  32.6408, -55.7743,  36.8862],\n",
      "        [380.6941, 310.8139,  42.1164, -66.9787,  48.8622],\n",
      "        [375.2106, 323.5964,  45.3732, -80.1016,  50.4033]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [283.0000, 207.0000,   0.9996,   1.0000,   3.0000],\n",
      "        [302.0000, 213.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [355.0000, 130.0000,   0.9985,   1.0000,   5.0000],\n",
      "        [349.0000, 109.0000,   0.9988,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [283.0000, 207.0000,   0.9996,   1.0000,   3.0000],\n",
      "        [302.0000, 213.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [355.0000, 130.0000,   0.9985,   1.0000,   5.0000],\n",
      "        [349.0000, 109.0000,   0.9988,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [283.0000, 207.0000,   0.9996,   1.0000,   3.0000],\n",
      "        [302.0000, 213.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [355.0000, 130.0000,   0.9985,   1.0000,   5.0000],\n",
      "        [349.0000, 109.0000,   0.9988,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[283.8728, 391.0164,  31.2363, -51.8142,  40.5881],\n",
      "        [274.3301, 278.9933,  39.0702, -77.1120,  36.9963],\n",
      "        [298.3532, 208.4908,  29.6689, -58.3484,  30.9646],\n",
      "        [314.7442, 214.8931,  31.3537, -53.6583,  35.4680],\n",
      "        [372.6029, 140.9800,  19.5007, -40.4282,  26.1076],\n",
      "        [367.0514, 125.0456,  15.0933, -30.1811,  25.0122]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [180.0000, 298.0000,   0.9993,   1.0000,   3.0000],\n",
      "        [176.0000, 278.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [107.0000, 206.0000,   0.9955,   1.0000,   5.0000],\n",
      "        [ 91.0000, 189.0000,   0.9833,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [180.0000, 298.0000,   0.9993,   1.0000,   3.0000],\n",
      "        [176.0000, 278.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [107.0000, 206.0000,   0.9955,   1.0000,   5.0000],\n",
      "        [ 91.0000, 189.0000,   0.9833,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [180.0000, 298.0000,   0.9993,   1.0000,   3.0000],\n",
      "        [176.0000, 278.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [107.0000, 206.0000,   0.9955,   1.0000,   5.0000],\n",
      "        [ 91.0000, 189.0000,   0.9833,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[262.2078, 357.8541,  49.4919, -67.5096,  50.7341],\n",
      "        [274.3301, 278.9933,  39.0702, -77.1120,  36.9963],\n",
      "        [197.4952, 299.2977,  34.9640, -68.4012,  36.0722],\n",
      "        [185.2625, 267.6096,  39.5452, -70.8448,  38.7428],\n",
      "        [123.2987, 207.8151,  22.5362, -53.1586,  24.3000],\n",
      "        [ 97.9462, 182.3158,  25.6033, -47.2825,  27.8273]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [283.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [302.0000, 214.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [377.0000, 149.0000,   0.9984,   1.0000,   5.0000],\n",
      "        [391.0000, 131.0000,   0.9982,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [283.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [302.0000, 214.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [377.0000, 149.0000,   0.9984,   1.0000,   5.0000],\n",
      "        [391.0000, 131.0000,   0.9982,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [283.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [302.0000, 214.0000,   0.9998,   1.0000,   4.0000],\n",
      "        [377.0000, 149.0000,   0.9984,   1.0000,   5.0000],\n",
      "        [391.0000, 131.0000,   0.9982,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[287.7144, 394.6483,  29.1728, -53.2685,  38.6987],\n",
      "        [274.3301, 278.9933,  39.0702, -77.1120,  36.9963],\n",
      "        [298.3532, 208.4908,  29.6690, -58.3484,  30.9646],\n",
      "        [314.7375, 215.8648,  31.4671, -53.7913,  35.5865],\n",
      "        [393.3936, 158.1220,  23.2430, -43.9207,  29.8882],\n",
      "        [409.1978, 145.9477,  19.4106, -36.1568,  29.3242]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [282.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [302.0000, 214.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [392.0000, 171.0000,   0.9994,   1.0000,   5.0000],\n",
      "        [410.0000, 158.0000,   0.9980,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [282.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [302.0000, 214.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [392.0000, 171.0000,   0.9994,   1.0000,   5.0000],\n",
      "        [410.0000, 158.0000,   0.9980,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [282.0000, 207.0000,   0.9998,   1.0000,   3.0000],\n",
      "        [302.0000, 214.0000,   0.9999,   1.0000,   4.0000],\n",
      "        [392.0000, 171.0000,   0.9994,   1.0000,   5.0000],\n",
      "        [410.0000, 158.0000,   0.9980,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[289.2779, 394.9178,  29.0140, -56.1863,  37.9403],\n",
      "        [274.3301, 278.9933,  39.0702, -77.1120,  36.9963],\n",
      "        [297.3792, 208.5132,  29.6208, -58.3284,  30.9098],\n",
      "        [314.6933, 215.8188,  31.4866, -53.7761,  35.6004],\n",
      "        [407.3660, 178.4351,  26.9309, -47.5230,  33.6289],\n",
      "        [428.5309, 171.6253,  23.4788, -42.6160,  33.1045]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [180.0000, 297.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [176.0000, 276.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [211.0000, 184.0000,   0.9985,   1.0000,   5.0000],\n",
      "        [230.0000, 195.0000,   0.9990,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [180.0000, 297.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [176.0000, 276.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [211.0000, 184.0000,   0.9985,   1.0000,   5.0000],\n",
      "        [230.0000, 195.0000,   0.9990,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [180.0000, 297.0000,   0.9994,   1.0000,   3.0000],\n",
      "        [176.0000, 276.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [211.0000, 184.0000,   0.9985,   1.0000,   5.0000],\n",
      "        [230.0000, 195.0000,   0.9990,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[271.0816, 368.1794,  44.2073, -67.6918,  47.0293],\n",
      "        [274.3301, 278.9933,  39.0702, -77.1120,  36.9963],\n",
      "        [197.5085, 298.3338,  34.8459, -68.2672,  35.9498],\n",
      "        [185.3288, 265.8089,  39.2329, -70.4158,  38.4732],\n",
      "        [223.5968, 182.3984,  26.1861, -53.2295,  28.1356],\n",
      "        [239.7333, 194.1229,  28.3481, -47.9887,  33.5360]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m y_true_sequence\u001b[38;5;241m.\u001b[39mappend(vertices_gt)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m vertices_pred \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     56\u001b[0m y_pred_sequence\u001b[38;5;241m.\u001b[39mappend(vertices_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36mKeypointPipeline.forward\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m     68\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(imgs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 71\u001b[0m     labeled_keypoints \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(labeled_keypoints)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs)\n",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36mKeypointPipeline.process_image\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeypoint_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 59\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeypoint_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Set the keypoint model back to its previous mode\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeypoint_model\u001b[38;5;241m.\u001b[39mtrain(keypoint_model_training)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py:101\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     94\u001b[0m             degen_bb: List[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m boxes[bb_idx]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     95\u001b[0m             torch\u001b[38;5;241m.\u001b[39m_assert(\n\u001b[1;32m     96\u001b[0m                 \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     97\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll bounding boxes should have positive height and width.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Found invalid box \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdegen_bb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for target at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m             )\n\u001b[0;32m--> 101\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    103\u001b[0m     features \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/detection/backbone_utils.py:57\u001b[0m, in \u001b[0;36mBackboneWithFPN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[0;32m---> 57\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfpn(x)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:69\u001b[0m, in \u001b[0;36mIntermediateLayerGetter.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m out \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 69\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_layers:\n\u001b[1;32m     71\u001b[0m         out_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_layers[name]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/resnet.py:158\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    155\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(out)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m identity\n\u001b[1;32m    161\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = KeypointPipeline(weights_path, num_vertices=6)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss\n",
    "criterion = OccludedKeyPointLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 25  # Define your number of epochs\n",
    "batch_size = 16\n",
    "\n",
    "KEYPOINTS_FOLDER_TRAIN = train_test_split(root_dir) +\"/train\" #train_test_split(root_dir) +\"/train\"\n",
    "KEYPOINTS_FOLDER_VAL = train_test_split(root_dir) +\"/val\"\n",
    "KEYPOINTS_FOLDER_TEST = train_test_split(root_dir) +\"/test\"\n",
    "\n",
    "dataset_train = KPDataset(KEYPOINTS_FOLDER_TRAIN, transform=None, demo=False)\n",
    "dataset_val = KPDataset(KEYPOINTS_FOLDER_VAL, transform=None, demo=False)\n",
    "dataset_test = KPDataset(KEYPOINTS_FOLDER_TEST, transform=None, demo=False)\n",
    "\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "data_loader_val = DataLoader(dataset_val, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "v = 5\n",
    "\n",
    "# Initialize sequences for true and predicted keypoints\n",
    "y_true_sequence = []\n",
    "y_pred_sequence = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for i, batch in enumerate(data_loader_train):\n",
    "        img_tuple, target_dict_tuple, img_files = batch\n",
    "        print(f\"Processing batch {i+1} with images:\", img_files)\n",
    "        \n",
    "        imgs = [img.to(device) for img in img_tuple]  # Create list of images\n",
    "\n",
    "        # Process each image individually\n",
    "        losses = []\n",
    "        for i in range(len(imgs)):\n",
    "            img = imgs[i].unsqueeze(0)  # Unsqueeze to add batch dimension\n",
    "\n",
    "            # Prepare ground truth vertices for the image\n",
    "            keypoints = target_dict_tuple[i]['keypoints'].to(device)\n",
    "            visibility = torch.ones((keypoints.shape[0], keypoints.shape[1], 1)).to(device)\n",
    "            vertices_gt = torch.cat((keypoints, visibility), dim=2).unsqueeze(0)  # Unsqueeze to add batch dimension\n",
    "            vertices_gt = vertices_gt.squeeze()            \n",
    "            y_true_sequence.append(vertices_gt)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(img)\n",
    "            vertices_pred = output[0]\n",
    "            y_pred_sequence.append(vertices_pred)\n",
    "            \n",
    "            edges_prob = model.enc_e\n",
    "            edges = model.edges\n",
    "            edge_features = model.edge_features\n",
    "            edges_gt = torch.cat((edges, edge_features), dim=1) \n",
    "\n",
    "            # Compute loss for the image\n",
    "            huber_loss = criterion(vertices_pred, vertices_gt)\n",
    "            ce_loss = edge_loss(edges_prob, edges_gt)\n",
    "            vis_loss = visibility_loss(vertices_pred, vertices_gt)\n",
    "\n",
    "            loss = huber_loss + ce_loss + vis_loss\n",
    "            losses.append(loss)  # Store loss for the image\n",
    "            \n",
    "        # Convert true and predicted sequences to tensors\n",
    "        y_true_tensor = torch.stack(y_true_sequence)\n",
    "        y_pred_tensor = torch.stack(y_pred_sequence)\n",
    "        \n",
    "        # Compute temporal consistency loss\n",
    "        temporal_loss = temporal_consistency_loss(y_true_tensor, y_pred_tensor)\n",
    "\n",
    "        # Average loss over all images in the batch\n",
    "        other_losses = torch.mean(torch.stack(losses))\n",
    "        \n",
    "        # Combine temporal loss with other losses\n",
    "        total_loss = other_losses + temporal_loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Clear the sequences for the next batch\n",
    "        y_true_sequence.clear()\n",
    "        y_pred_sequence.clear()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    eta = epoch_time * (num_epochs - epoch - 1)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, ETA: {eta} seconds')\n",
    "\n",
    "model_save_path = f\"/home/jc-merlab/Pictures/Data/trained_models/keypointsrcnn_weights_occ_b{batch_size}_e{num_epochs}_v{v}.pth\"\n",
    "\n",
    "torch.save(model, model_save_path)\n",
    "    \n",
    "# Save the state dict of the model, not the entire model\n",
    "# torch.save(model.state_dict(), model_save_path)\n",
    "    \n",
    "torch.save(model, model_save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dfef6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save(img, vertices, filename):\n",
    "    print(\"type of image befor conversion\",type(img))    \n",
    "    print(\"type of vertices before conversion\", type(vertices))\n",
    "    print(img)\n",
    "    img = (img.permute(1,2,0).cpu().numpy() * 255).astype(np.uint8)\n",
    "#     img = (img * 255).astype(np.uint8)  # Convert back from [0, 1] range to [0, 255]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    vertices = vertices.cpu().numpy()\n",
    "\n",
    "    print(f\"Image shape before saving: {img.shape}\")  # print the image shape\n",
    "    print(\"type of vertices\", type(vertices))\n",
    "#     print(\"entered vertices\", vertices)\n",
    "#     print(\"entered image\", img)\n",
    "\n",
    "    # Convert grayscale to BGR if necessary\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "    for i in range(vertices.shape[0]):\n",
    "        img = cv2.circle(img, (int(vertices[i, 0]), int(vertices[i, 1])), radius=2, color=(0, 0, 255), thickness=-1)\n",
    "        \n",
    "    result = cv2.imwrite(filename, img)\n",
    "    print(f\"Image saved at {filename}: {result}\")  # print if save was successful\n",
    "\n",
    "    # If the image didn't save correctly, save the image data to a text file for examination\n",
    "    if not result:\n",
    "        with open(filename + \".txt\", \"w\") as f:\n",
    "            np.savetxt(f, img.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f14beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_save_model(model, data_loader_test):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    total_trifocal_loss = 0.0\n",
    "    total_ce_loss = 0.0\n",
    "    total_vis_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    y_true_sequence = []\n",
    "    y_pred_sequence = []\n",
    "\n",
    "    # We don't need to track gradients during evaluation\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(data_loader_test):\n",
    "            img_tuple, target_dict_tuple, img_files = batch\n",
    "\n",
    "            total_batch_loss = 0.0\n",
    "            total_batch_trifocal_loss = 0.0\n",
    "            total_batch_ce_loss = 0.0\n",
    "            total_batch_vis_loss = 0.0\n",
    "\n",
    "            # Process each image individually\n",
    "            for i in range(len(img_tuple)):\n",
    "                img = img_tuple[i].to(device)\n",
    "                target = target_dict_tuple[i]\n",
    "\n",
    "                # Prepare ground truth vertices for the image\n",
    "                keypoints = target['keypoints'].to(device)\n",
    "                visibility = torch.ones((keypoints.shape[0], keypoints.shape[1], 1)).to(device)\n",
    "                vertices_gt = torch.cat((keypoints, visibility), dim=2).unsqueeze(0)  # Unsqueeze to add batch dimension\n",
    "                vertices_gt = vertices_gt.squeeze()\n",
    "                y_true_sequence.append(vertices_gt)\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(img.unsqueeze(0))\n",
    "                vertices_pred = output[0]\n",
    "                y_pred_sequence.append(vertices_pred)\n",
    "\n",
    "                edges_prob = model.enc_e\n",
    "                edges = model.edges\n",
    "                edge_features = model.edge_features\n",
    "                edges_gt = torch.cat((edges, edge_features), dim=1) \n",
    "\n",
    "                trifocal_loss = criterion(vertices_pred, vertices_gt)\n",
    "                ce_loss = edge_loss(edges_prob, edges_gt)\n",
    "                vis_loss = visibility_loss(vertices_pred, vertices_gt)\n",
    "                loss = trifocal_loss + ce_loss + vis_loss\n",
    "\n",
    "                total_batch_loss += loss.item()\n",
    "                total_batch_trifocal_loss += trifocal_loss.item()\n",
    "                total_batch_ce_loss += ce_loss.item()\n",
    "                total_batch_vis_loss += vis_loss.item()\n",
    "\n",
    "                # Visualize and save the prediction\n",
    "                filename = f'/home/jc-merlab/Pictures/Data/occ_vis_data/image_{idx}_{i}.jpg'\n",
    "                visualize_and_save(img, vertices_pred, filename)\n",
    "                print(f\"Image saved at {filename}\")  # Print statement to confirm image save\n",
    "\n",
    "            # Convert true and predicted sequences to tensors\n",
    "            y_true_tensor = torch.stack(y_true_sequence)\n",
    "            y_pred_tensor = torch.stack(y_pred_sequence)\n",
    "\n",
    "            # Compute temporal consistency loss\n",
    "            temporal_loss = temporal_consistency_loss(y_true_tensor, y_pred_tensor)\n",
    "\n",
    "            total_loss += (total_batch_loss + temporal_loss.item()) / len(img_tuple)\n",
    "            total_trifocal_loss += total_batch_trifocal_loss / len(img_tuple)\n",
    "            total_ce_loss += total_batch_ce_loss / len(img_tuple)\n",
    "            num_batches += 1\n",
    "\n",
    "            # Clear the sequences for the next batch\n",
    "            y_true_sequence.clear()\n",
    "            y_pred_sequence.clear()\n",
    "    \n",
    "    # Average the loss over all batches\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_trifocal_loss = total_trifocal_loss / num_batches\n",
    "    avg_ce_loss = total_ce_loss / num_batches\n",
    "    \n",
    "    print(f'Avg. Test Loss: {avg_loss}, Avg. Trifocal Loss: {avg_trifocal_loss}, Avg. Cross Entropy Loss: {avg_ce_loss}')\n",
    "    return avg_loss, avg_trifocal_loss, avg_ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5740f228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices as encoder input tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [179.0000, 298.0000,   0.9992,   1.0000,   3.0000],\n",
      "        [176.0000, 278.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [230.0000, 195.0000,   0.9985,   1.0000,   5.0000],\n",
      "        [249.0000, 203.0000,   0.9990,   1.0000,   6.0000]], device='cuda:0')\n",
      "Vertices in node features tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [179.0000, 298.0000,   0.9992,   1.0000,   3.0000],\n",
      "        [176.0000, 278.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [230.0000, 195.0000,   0.9985,   1.0000,   5.0000],\n",
      "        [249.0000, 203.0000,   0.9990,   1.0000,   6.0000]], device='cuda:0')\n",
      "tensor([[258.0000, 367.0000,   1.0000,   1.0000,   1.0000],\n",
      "        [258.0000, 283.0000,   0.9999,   1.0000,   2.0000],\n",
      "        [179.0000, 298.0000,   0.9992,   1.0000,   3.0000],\n",
      "        [176.0000, 278.0000,   0.9997,   1.0000,   4.0000],\n",
      "        [230.0000, 195.0000,   0.9985,   1.0000,   5.0000],\n",
      "        [249.0000, 203.0000,   0.9990,   1.0000,   6.0000]], device='cuda:0')\n",
      "edge prob shape before sigmoid torch.Size([6, 128])\n",
      "edge prob shape torch.Size([6, 128])\n",
      "shape of just edges tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5],\n",
      "        [5, 0]], device='cuda:0')\n",
      "h_source and h_target shapes torch.Size([6, 5]) torch.Size([6, 5])\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0') 0\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0') 1\n",
      "tensor(2, device='cuda:0') tensor(3, device='cuda:0') 2\n",
      "tensor(3, device='cuda:0') tensor(4, device='cuda:0') 3\n",
      "tensor(4, device='cuda:0') tensor(5, device='cuda:0') 4\n",
      "tensor(5, device='cuda:0') tensor(0, device='cuda:0') 5\n",
      "[tensor([[ 2.5786e+02,  3.6730e+02,  3.6518e-01,  8.8958e-01, -1.1888e+01],\n",
      "        [ 2.5787e+02,  2.8362e+02,  2.4355e-01,  9.8086e-01, -4.3538e+00],\n",
      "        [ 1.7889e+02,  2.9848e+02,  3.9121e-01,  1.0120e+00, -7.0228e+00],\n",
      "        [ 1.7619e+02,  2.7857e+02,  5.8169e-01,  9.0099e-01, -1.6922e+00],\n",
      "        [ 2.3007e+02,  1.9572e+02,  2.8116e-01,  8.8307e-01,  1.9299e+00],\n",
      "        [ 2.4926e+02,  2.0352e+02,  8.0286e-01,  9.6992e-01, -7.5073e-01]],\n",
      "       device='cuda:0')]\n",
      "type of image befor conversion <class 'torch.Tensor'>\n",
      "type of vertices before conversion <class 'torch.Tensor'>\n",
      "tensor([[[0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         ...,\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980]],\n",
      "\n",
      "        [[0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         ...,\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980]],\n",
      "\n",
      "        [[0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         ...,\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],\n",
      "         [0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980]]],\n",
      "       device='cuda:0')\n",
      "Image shape before saving: (480, 640, 3)\n",
      "type of vertices <class 'numpy.ndarray'>\n",
      "Image saved at /home/jc-merlab/Pictures/Data/occ_vis_data/image_0_0.jpg: True\n",
      "Image saved at /home/jc-merlab/Pictures/Data/occ_vis_data/image_0_0.jpg\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# avg_loss, avg_trifocal_loss, avg_ce_loss, all_preds = test_and_save_model(model, data_loader_test)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m avg_loss, avg_trifocal_loss, avg_ce_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtest_and_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mtest_and_save_model\u001b[0;34m(model, data_loader_test)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Compute temporal consistency loss\u001b[39;00m\n\u001b[1;32m     64\u001b[0m temporal_loss \u001b[38;5;241m=\u001b[39m temporal_consistency_loss(y_true_tensor, y_pred_tensor)\n\u001b[0;32m---> 66\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (total_batch_loss \u001b[38;5;241m+\u001b[39m \u001b[43mtemporal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(img_tuple)\n\u001b[1;32m     67\u001b[0m total_trifocal_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_batch_trifocal_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(img_tuple)\n\u001b[1;32m     68\u001b[0m total_ce_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_batch_ce_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(img_tuple)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "# avg_loss, avg_trifocal_loss, avg_ce_loss, all_preds = test_and_save_model(model, data_loader_test)\n",
    "\n",
    "avg_loss, avg_trifocal_loss, avg_ce_loss = test_and_save_model(model, data_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58949932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Directory containing images\n",
    "dir_path = '/home/jc-merlab/Pictures/Data/occ_vis_data/'\n",
    "images = []\n",
    "\n",
    "# Ensure the images are sorted by name\n",
    "for f in sorted(os.listdir(dir_path)):\n",
    "    if f.endswith('.jpg') or f.endswith('.png'):  # Check for image file extension\n",
    "        images.append(f)\n",
    "\n",
    "# Determine the width and height from the first image\n",
    "image_path = os.path.join(dir_path, images[0])\n",
    "frame = cv2.imread(image_path)\n",
    "cv2.imshow('video',frame)\n",
    "height, width, channels = frame.shape\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Be sure to use the correct codec\n",
    "video_filename = 'output.mp4'\n",
    "video = cv2.VideoWriter(video_filename, fourcc, 3.0, (width, height))\n",
    "\n",
    "for image in images:\n",
    "    image_path = os.path.join(dir_path, image)\n",
    "    frame = cv2.imread(image_path)\n",
    "    video.write(frame)  # Write out frame to video\n",
    "\n",
    "# Release everything when job is finished\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"The output video is\", video_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0007f54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "h1 shape torch.Size([6, 128])\n",
      "value of edges tensor([[1, 2],\n",
      "        [2, 3],\n",
      "        [4, 5]], device='cuda:0')\n",
      "h1_source shape:  torch.Size([3, 128])\n",
      "h1_target shape:  torch.Size([3, 128])\n",
      "edges_weights shape:  torch.Size([3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [64,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [65,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [66,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [67,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [68,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [69,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [70,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [71,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [72,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [73,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [74,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [75,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [76,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [77,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [78,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [79,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [80,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [81,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [82,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [83,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [84,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [85,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [86,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [87,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [88,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [89,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [90,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [91,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [92,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [93,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [94,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [95,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [96,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [97,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [98,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [99,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [100,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [101,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [102,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [103,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [104,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [105,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [106,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [107,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [108,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [109,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [110,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [111,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [112,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [113,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [114,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [115,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [116,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [117,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [118,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [119,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [120,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [121,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [122,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [123,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [124,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [125,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [126,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [127,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [0,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [1,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [2,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [3,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [4,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [5,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [6,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [7,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [8,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [9,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [10,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [11,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [12,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [13,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [14,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [15,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [16,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [17,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [18,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [19,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [20,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [21,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [22,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [23,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [24,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [25,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [26,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [27,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [28,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [29,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [30,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [31,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [32,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [33,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [34,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [35,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [36,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [37,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [38,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [39,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [40,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [41,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [42,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [43,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [44,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [45,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [46,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [47,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [48,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [49,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [50,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [51,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [52,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [53,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [54,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [55,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [56,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [57,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [58,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [59,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [60,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [61,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [62,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [63,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 19\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(keypoints)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mKeypointPipeline.forward\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m     71\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(imgs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 74\u001b[0m     labeled_keypoints \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(labeled_keypoints)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs)\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mKeypointPipeline.process_image\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeypoint_model\u001b[38;5;241m.\u001b[39mtrain(keypoint_model_training)\n\u001b[1;32m     65\u001b[0m img \u001b[38;5;241m=\u001b[39m (img[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m---> 66\u001b[0m labeled_keypoints \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_model_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labeled_keypoints\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mKeypointPipeline.process_model_output\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m     42\u001b[0m keypoints_visible \u001b[38;5;241m=\u001b[39m keypoints \u001b[38;5;241m*\u001b[39m visibility  \u001b[38;5;66;03m# Predicted visible vertices\u001b[39;00m\n\u001b[1;32m     43\u001b[0m keypoints_occluded \u001b[38;5;241m=\u001b[39m keypoints \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m visibility)  \u001b[38;5;66;03m# Predicted occluded vertices\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m vertices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_e, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medges, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medges_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeypoints_visible\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust here to include edge weights\u001b[39;00m\n\u001b[1;32m     46\u001b[0m vertices_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnn_decoder(vertices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_e, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medges, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medges_weights)  \u001b[38;5;66;03m# Adjust here to pass edge weights\u001b[39;00m\n\u001b[1;32m     47\u001b[0m vertices_pred_occluded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((vertices_pred, keypoints_visible[:, \u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mGNNEncoder.forward\u001b[0;34m(self, vertices)\u001b[0m\n\u001b[1;32m     52\u001b[0m h_e1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_e1(torch\u001b[38;5;241m.\u001b[39mcat((h1_source, h1_target, edges_weights\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Include edge weights in the input\u001b[39;00m\n\u001b[1;32m     53\u001b[0m h_j_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_v(h_e1)\n\u001b[0;32m---> 54\u001b[0m h2_source \u001b[38;5;241m=\u001b[39m \u001b[43mh_j_2\u001b[49m\u001b[43m[\u001b[49m\u001b[43medges\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     55\u001b[0m h2_target \u001b[38;5;241m=\u001b[39m h_j_2[edges[:, \u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m     56\u001b[0m h_e2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_e2(torch\u001b[38;5;241m.\u001b[39mcat((h1_source, h1_target, edges_weights\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Include edge weights in the input\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home/jc-merlab/Pictures/Data/trained_models/keypointsrcnn_weights_occ_b8_e25_v4.pth'\n",
    "\n",
    "model = torch.load(model_path).to(device)\n",
    "\n",
    "\n",
    "image = Image.open(\"/home/jc-merlab/Pictures/Data/planar_occluded/002626.rgb.jpg\")\n",
    "print(type(image))\n",
    "\n",
    "img = F.to_tensor(image).to(device)\n",
    "img.unsqueeze_(0)\n",
    "# print(image.shape)\n",
    "# image = list(image)\n",
    "# print(type(images))\n",
    "# images = list(image.to(device) for image in images)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    output = model(img)\n",
    "    \n",
    "keypoints = output[0]\n",
    "\n",
    "print(keypoints)\n",
    "plt.imshow(image)\n",
    "\n",
    "# Assuming each keypoint is a tensor representing (x, y)\n",
    "for i, keypoint in enumerate(keypoints):\n",
    "    print(f'Key point {i}: {keypoint}')\n",
    "    keypoint = keypoint.cpu().numpy()\n",
    "    plt.plot(keypoint[0], keypoint[1], 'ro')\n",
    "plt.show()\n",
    "\n",
    "# Plotting the image\n",
    "\n",
    "# plt.imshow(image)\n",
    "\n",
    "# for keypoint in output[0]:\n",
    "#     plt.plot(keypoint[0], keypoint[1], 'ro')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d23048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7eb2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
