{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55bff8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from models.resnet import ResNet\n",
    "from models.unet import UNet\n",
    "from models.skip import skip\n",
    "from models.dcgan import dcgan\n",
    "import torch\n",
    "import torch.optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "from torchmetrics.image import TotalVariation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "# from utils.inpainting_utils import *\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "PLOT = True\n",
    "imsize = -1\n",
    "dim_div_by = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e5f381d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16908615680\n",
      "517996544\n",
      "503718400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import json\n",
    "from os.path import expanduser\n",
    "import splitfolders\n",
    "import shutil\n",
    "# from define_path import Def_Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "# from torchsummary import summary\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A # Library for augmentations\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "\n",
    "# # Get the directory of the current script\n",
    "# current_script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# # Navigate up to the 'scripts' directory\n",
    "# scripts_dir = os.path.dirname(current_script_dir)\n",
    "\n",
    "# # Add 'scripts' directory to sys.path\n",
    "# sys.path.append(scripts_dir)\n",
    "\n",
    "import transforms, utils, engine, train\n",
    "from utils import collate_fn\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "\n",
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "print(t)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "print(r)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "print(a)\n",
    "f = r-a  # free inside reserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b474141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbe8d0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = UNet()\n",
    "trained_unet = '/home/jc-merlab/Pictures/Data/trained_models/inpainting/14Dec_att_generative_was_YCB.pth'\n",
    "net.load_state_dict(torch.load(trained_unet))\n",
    "# discriminator = Discriminator()\n",
    "# trained_discriminator = '/home/jc-merlab/Pictures/Data/trained_models/inpainting/14Dec_att_discrimiator_was_YCB.pth'\n",
    "# discriminator.load_state_dict(torch.load(trained_discriminator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e9b620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "net.to(device)\n",
    "\n",
    "image_transform = T.Compose([\n",
    "    T.Resize((480, 640)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.209555113170385, 0.22507974363977162, 0.20982026500023962], std=[0.20639409678896012, 0.19208633033458372, 0.20659148273508857]),\n",
    "])\n",
    "\n",
    "\n",
    "def denormalize(tensor, means, stds):\n",
    "    means = torch.tensor(means).view(-1, 1, 1)\n",
    "    stds = torch.tensor(stds).view(-1, 1, 1)\n",
    "\n",
    "    if tensor.is_cuda:\n",
    "        means = means.to(tensor.device)\n",
    "        stds = stds.to(tensor.device)\n",
    "    tensor = tensor * stds + means\n",
    "\n",
    "    return tensor\n",
    "\n",
    "def predict_frame(frame):\n",
    "    # Convert frame to PIL Image to apply torchvision transforms\n",
    "    frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    frame = image_transform(frame).unsqueeze(0)  # Add batch dimension\n",
    "    frame = frame.cuda()  # or .cpu() if not using GPU\n",
    "    with torch.no_grad():\n",
    "        prediction = net(frame)\n",
    "    # Optionally, reverse normalization or other transformations here\n",
    "    # Convert the tensor to a numpy array for OpenCV to display or save\n",
    "    prediction = denormalize(prediction, [0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857])\n",
    "\n",
    "    prediction = prediction.squeeze().cpu().numpy()\n",
    "    prediction = np.transpose(prediction, (1, 2, 0))  # Change from (C, H, W) to (H, W, C)\n",
    "    prediction = (prediction * 255).astype(np.uint8)\n",
    "    return prediction\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture('/home/jc-merlab/Pictures/panda_data/images_for_occlusion/4/occ_test_4.avi')\n",
    "# Prepare for saving the output video (if needed)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('/home/jc-merlab/Pictures/panda_data/images_for_occlusion/4/occ_test_4_op.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Process and predict the frame\n",
    "    output_frame = predict_frame(frame)\n",
    "    # Save or display the frame\n",
    "    out.write(output_frame)\n",
    "    cv2.imshow('frame', output_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press Q to stop\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c58e2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
