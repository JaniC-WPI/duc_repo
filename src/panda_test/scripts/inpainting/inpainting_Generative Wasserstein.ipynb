{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPAINTING => Attention UNet + Discriminator (Wassersteins Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from models.resnet import ResNet\n",
    "from models.unet import UNet\n",
    "from models.skip import skip\n",
    "from models.dcgan import dcgan\n",
    "import torch\n",
    "import torch.optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "from torchmetrics.image import TotalVariation\n",
    "\n",
    "from utils.inpainting_utils import *\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "PLOT = True\n",
    "imsize = -1\n",
    "dim_div_by = 64\n",
    "\n",
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "print(t)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "print(r)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "print(a)\n",
    "f = r-a  # free inside reserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/jc-merlab/Venk/Augmented_Data/images'\n",
    "label_path = '/home/jc-merlab/Venk/Augmented_Data/labels'\n",
    "\n",
    "img_list = []\n",
    "for images in os.listdir(train_path):\n",
    "    if (images.endswith(\".jpg\")):\n",
    "        img_list.append(images)\n",
    "        \n",
    "\n",
    "img_list_sorted = sorted(img_list)\n",
    "\n",
    "\n",
    "lbl_list = []\n",
    "for images in os.listdir(label_path):\n",
    "    if (images.endswith(\".jpg\")):\n",
    "        lbl_list.append(images)\n",
    "        \n",
    "\n",
    "lbl_list_sorted = sorted(lbl_list)\n",
    "\n",
    "\n",
    "\n",
    "# data_list = []\n",
    "# for file in os.listdir(train_path):\n",
    "\n",
    "#     #If file is a json, construct it's full path and open it, append all json data to list\n",
    "#     if file.endswith('json'):\n",
    "#         data_list.append(file)\n",
    "\n",
    "# data_list_sorted = sorted(data_list)\n",
    "# print(data_list_sorted)\n",
    "# print(len(data_list_sorted))\n",
    "\n",
    "print(img_list_sorted)\n",
    "print(len(img_list_sorted))\n",
    "print(lbl_list_sorted)\n",
    "print(len(lbl_list_sorted))\n",
    "\n",
    "dtype = torch.float32\n",
    "net = UNet()\n",
    "net = net.type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels, 64, normalization=False),  # input is 3 x 256 x 256\n",
    "            *discriminator_block(64, 128),                                # output is 128 x 128 x 128\n",
    "            *discriminator_block(128, 256),                               # output is 256 x 64 x 64\n",
    "            *discriminator_block(256, 512),\n",
    "            *discriminator_block(512, 1024),                                # output is 512 x 32 x 32\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),                                   # Padding to match size\n",
    "            nn.Conv2d(1024, 1, 4, padding=1)                               # Final output is 1 x 16 x 16\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.final = nn.Linear(15*20, 1)  # Adjust the input features to match the flattened size\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, img):\n",
    "        output = self.model(img)\n",
    "        output = self.flatten(output)\n",
    "        output = self.final(output)\n",
    "        return output   #self.sigmoid(output)\n",
    "\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(8, 3, 480, 640)\n",
    "\n",
    "# Getting the discriminator output for the input tensor\n",
    "output = discriminator(input_tensor)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# class ImageLabelDataset(Dataset):\n",
    "#     def __init__(self, image_dir, label_dir, transform=None):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             image_dir (string): Directory with all the images.\n",
    "#             label_dir (string): Directory with all the labels.\n",
    "#             transform (callable, optional): Optional transform to be applied on a sample.\n",
    "#         \"\"\"\n",
    "#         self.image_dir = image_dir\n",
    "#         self.label_dir = label_dir\n",
    "#         self.image_files = os.listdir(image_dir)\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_files)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_name = os.path.join(self.image_dir, self.image_files[idx])\n",
    "#         label_name = os.path.join(self.label_dir, self.image_files[idx])\n",
    "        \n",
    "#         image = Image.open(img_name)\n",
    "#         label = Image.open(label_name)\n",
    "\n",
    "#         if self.transform:\n",
    "#             torch.manual_seed(0)\n",
    "#             image = self.transform(image)\n",
    "#             label = self.transform(label)\n",
    "\n",
    "#         return image, label\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((480, 640)),  \n",
    "#     transforms.RandomHorizontalFlip(p=0.25),\n",
    "#     transforms.RandomRotation(degrees=(0, 20)),\n",
    "#     transforms.RandomVerticalFlip(p=0.25),\n",
    "#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "#     transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),\n",
    "#     transforms.ToTensor()\n",
    "\n",
    "# ])\n",
    "\n",
    "def denormalize(tensor, means, stds):\n",
    "    means = torch.tensor(means).view(-1, 1, 1)\n",
    "    stds = torch.tensor(stds).view(-1, 1, 1)\n",
    "\n",
    "    if tensor.is_cuda:\n",
    "        means = means.to(tensor.device)\n",
    "        stds = stds.to(tensor.device)\n",
    "    tensor = tensor * stds + means\n",
    "\n",
    "    return tensor\n",
    "\n",
    "class ImageLabelDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, image_transform=None, label_transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.image_files = os.listdir(image_dir)\n",
    "        self.image_transform = image_transform\n",
    "        self.label_transform = label_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        label_name = os.path.join(self.label_dir, self.image_files[idx])\n",
    "\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = Image.open(label_name).convert('RGB')  # Assuming label is grayscale\n",
    "\n",
    "        seed = np.random.randint(2147483647)  # make a seed with numpy generator \n",
    "        \n",
    "        if self.image_transform or self.label_transform:\n",
    "            random.seed(seed)  # apply this seed to img transforms\n",
    "            torch.manual_seed(seed)\n",
    "            image = self.image_transform(image)\n",
    "\n",
    "            random.seed(seed)  # apply this seed to label transforms\n",
    "            torch.manual_seed(seed)\n",
    "            label = self.label_transform(label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((480, 640)),\n",
    "    transforms.RandomHorizontalFlip(p=0.1),\n",
    "    # transforms.RandomRotation(degrees=(-5, 5)),\n",
    "    # # transforms.RandomVerticalFlip(p=0.1),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.2, saturation=0.1, hue=0.1),\n",
    "    # transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),\n",
    "    transforms.RandomEqualize(p=0.01),\n",
    "    transforms.RandomAutocontrast(p=0.01),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.209555113170385, 0.22507974363977162, 0.20982026500023962], std=[0.20639409678896012, 0.19208633033458372, 0.20659148273508857]),\n",
    "])\n",
    "\n",
    "label_transform = transforms.Compose([\n",
    "    transforms.Resize((480, 640)),\n",
    "    transforms.RandomHorizontalFlip(p=0.1),\n",
    "    # transforms.RandomRotation(degrees=(-5, 5)),\n",
    "    # transforms.RandomVerticalFlip(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.209555113170385, 0.22507974363977162, 0.20982026500023962], std=[0.20639409678896012, 0.19208633033458372, 0.20659148273508857]),\n",
    "])\n",
    "\n",
    "image_dir = train_path\n",
    "label_dir = label_path\n",
    "dataset = ImageLabelDataset(image_dir=image_dir, label_dir=label_dir, \n",
    "                            image_transform=image_transform, \n",
    "                            label_transform=label_transform)\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.9 * total_size)\n",
    "val_size = (total_size - train_size) // 2\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "s  = sum(np.prod(list(p.size())) for p in net.parameters())\n",
    "print ('Number of params: %d' % s)\n",
    "\n",
    "mse = torch.nn.MSELoss().type(dtype)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    if batch_idx < 2:    \n",
    "        # print(data.shape, target.shape)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        idx = np.random.randint(0, len(data))\n",
    "        print(data.shape, target.shape)\n",
    "        print(data[idx,:,:,:].permute(1,2,0).shape)\n",
    "        inp = data[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "        # out = output[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "        lab = target[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "        print(lab.shape, type(lab))\n",
    "        data = denormalize(data, [0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857] )\n",
    "        target = denormalize(target,[0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857])\n",
    "        for i, (j, k) in enumerate(zip(data, target)):\n",
    "        \n",
    "            plt.figure(figsize=(10, 5))\n",
    "\n",
    "            ax1 = plt.subplot(1, 2, 1)\n",
    "            # print(i.shape, j.shape, k.shape)\n",
    "            plt.imshow(j.permute(1,2,0).detach().cpu().clone().numpy())\n",
    "            ax1.set_title('Input')\n",
    "            ax1.axis('off')\n",
    "\n",
    "\n",
    "            ax3 = plt.subplot(1, 2, 2)\n",
    "            plt.imshow(k.permute(1,2,0).detach().cpu().clone().numpy())\n",
    "            ax3.set_title('Target')\n",
    "            ax3.axis('off') \n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def wasserstein_loss(predictions, is_real):\n",
    "    return predictions.mean() if is_real else -predictions.mean()\n",
    "\n",
    "def discriminator_loss(real_predictions, fake_predictions):\n",
    "    return fake_predictions.mean() - real_predictions.mean()\n",
    "\n",
    "def compute_gradient_penalty(discriminator, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=device)\n",
    "    alpha = alpha.expand_as(real_samples)\n",
    "    \n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples))  #.requires_grad_(True)\n",
    "    interpolates.requires_grad_(True)\n",
    "    d_interpolates = discriminator(interpolates)\n",
    "    \n",
    "    fake = torch.ones(d_interpolates.size(), device=device, requires_grad=False)\n",
    "    \n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    \n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "# betas = (0.9, 0.95)\n",
    "# batch_size = 16\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss().type(dtype) \n",
    "reconstruction_criterion = nn.MSELoss().type(dtype) \n",
    "\n",
    "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=0.0001) #  , weight_decay = 0.0001) #,betas= betas , lr = 0.0001\n",
    "\"\"\"weight decay = 0.001 is tried.\"\"\"\n",
    "# optimizer_unet = torch.optim.Adam(unet.parameters(), lr=lr, betas=betas)\n",
    "optimizer_g = optim.Adam(net.parameters(), lr=0.0001) #, weight_decay = 0.0001) #,betas= betas\n",
    "real_label = 0.9\n",
    "fake_label = 0.1\n",
    "# lambda_adv = 0.00001\n",
    "lambda_adv = 0.000001\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "discriminator.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lpips import LPIPS\n",
    "from pytorch_fid import fid_score\n",
    "\n",
    "lpips_fn = LPIPS(net='alex').to(device)\n",
    "\n",
    "lpips_scores, fid_scores, tv_scores = [], [], []\n",
    "\n",
    "def calculate_tv(img):\n",
    "    \"\"\"\n",
    "    Compute the Total Variation (TV) of an image.\n",
    "    Args:\n",
    "        img (Tensor): The image tensor. Shape (N, C, H, W).\n",
    "    Returns:\n",
    "        float: The total variation of the image.\n",
    "    \"\"\"\n",
    "    batch_size, _, h, w = img.size()\n",
    "    tv_h = torch.pow(img[:, :, 1:, :] - img[:, :, :-1, :], 2).sum()\n",
    "    tv_w = torch.pow(img[:, :, :, 1:] - img[:, :, :, :-1], 2).sum()\n",
    "    return (tv_h + tv_w) / (batch_size * h * w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_final_unet_before_augmentation = '/home/jc-merlab/Venk/deep-image-prior-master/saved models/13Dec_att_generative_was_YCB.pth'\n",
    "net.load_state_dict(torch.load(trained_model_final_unet_before_augmentation))\n",
    "# trained_model_23_nov = '/home/jc-merlab/Venk/deep-image-prior-master/saved models/24nov_aug.pth'\n",
    "# net.load_state_dict(torch.load(trained_model_23_nov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = '/home/jc-merlab/Venk/DIP_augmentation_2/Checkpoints'\n",
    "\n",
    "lambda_gp = 10\n",
    "# lambda_gp = 10\n",
    "# lambda_gp = 100 \n",
    "for epoch in range(10):\n",
    "    print(\"Epoch\",epoch+1)\n",
    "    net.train()\n",
    "    discriminator.train()\n",
    "    d_loss = 0\n",
    "    g_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # print(\"Batch\",batch_idx)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        fake_images = net(data)\n",
    "        real_images = target\n",
    "        \n",
    "        optimizer_d.zero_grad()\n",
    "        real_predictions = discriminator(real_images)\n",
    "        fake_predictions = discriminator(fake_images.detach())\n",
    "        d_loss_real = wasserstein_loss(real_predictions, True)\n",
    "        d_loss_fake = wasserstein_loss(fake_predictions, False)\n",
    "        \n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_images.data, fake_images.data)\n",
    "        d_loss_total = d_loss_real + d_loss_fake + lambda_gp * gradient_penalty\n",
    "        \n",
    "        d_loss_total.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        optimizer_g.zero_grad()\n",
    "        fake_images = net(data)\n",
    "        trick_predictions = discriminator(fake_images)\n",
    "        g_loss_recon = reconstruction_criterion(fake_images, real_images)\n",
    "        g_loss_adv = -trick_predictions.mean()  \n",
    "        g_loss_total = g_loss_recon + lambda_adv * g_loss_adv\n",
    "        g_loss_total.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        d_loss += d_loss_total.item()\n",
    "        g_loss += g_loss_total.item()\n",
    "    idx = np.random.randint(0, len(data))\n",
    "    data = denormalize(data, [0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857] )\n",
    "    fake_images = denormalize(fake_images,[0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857])\n",
    "    inp = data[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "    out = fake_images[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "    lab = target[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "    # print(out.shape, type(out), lab.shape, type(lab))\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    plt.imshow(inp)\n",
    "    ax1.set_title('Input')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    plt.imshow(out)\n",
    "    ax2.set_title('Output')\n",
    "    ax2.axis('off')  \n",
    "\n",
    "    # ax3 = plt.subplot(1, 3, 3)\n",
    "    # plt.imshow(lab)\n",
    "    # ax3.set_title('Target')\n",
    "    # ax3.axis('off') \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'generator state_dict': net.state_dict(),\n",
    "        'discriminator state dict': discriminator.state_dict(),\n",
    "        'generator optimizer': optimizer_g.state_dict(),\n",
    "        'discriminator optimizer': optimizer_d.state_dict(),\n",
    "        'generator train_loss': g_loss,\n",
    "        'discriminator train loss': d_loss\n",
    "    }\n",
    "    checkpoint_filename = os.path.join(CHECKPOINT_PATH, f'checkpoint_epoch_{epoch+10}.pth')\n",
    "    torch.save(checkpoint, checkpoint_filename)\n",
    "    print(f\"Checkpoint saved to {checkpoint_filename}\")\n",
    "\n",
    "    net.eval()\n",
    "    discriminator.eval()\n",
    "    val_d_loss = 0\n",
    "    val_g_loss = 0\n",
    "    val_loss, lpips_val, tv_val, fid_val = 0, 0, 0, 0\n",
    "    with torch.no_grad(): \n",
    "         \n",
    "        for batch_idx, (data, target) in enumerate(val_loader): \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            fake_images = net(data)\n",
    "            real_images = target\n",
    "\n",
    "            real_labels =0.9*torch.ones((real_images.size(0), 1), device=device)\n",
    "            fake_labels = 0.1*torch.ones((fake_images.size(0), 1), device=device)\n",
    "\n",
    "            real_predictions = discriminator(real_images)\n",
    "            fake_predictions = discriminator(fake_images)\n",
    "            d_loss_real = criterion(real_predictions, real_labels)\n",
    "            d_loss_fake = criterion(fake_predictions, fake_labels)\n",
    "            fake_images = fake_images.to(device)\n",
    "            real_images = real_images.to(device)\n",
    "            lpips_value = lpips_fn(fake_images, real_images).mean()\n",
    "            lpips_val += lpips_value.item()\n",
    "            tv_value = calculate_tv(fake_images)\n",
    "            tv_val += tv_value.item()\n",
    "            \n",
    "            d_loss_total = d_loss_real + d_loss_fake\n",
    "\n",
    "            trick_labels = 0.9*torch.ones(fake_images.size(0), 1, device=device)\n",
    "            trick_predictions = discriminator(fake_images)\n",
    "            g_loss_recon = reconstruction_criterion(fake_images, real_images)\n",
    "            g_loss_adv = criterion(trick_predictions, trick_labels)\n",
    "            g_loss_total = g_loss_recon + lambda_adv * g_loss_adv\n",
    "\n",
    "            val_d_loss += d_loss_total.item()\n",
    "            val_g_loss += g_loss_total.item()\n",
    "    # net.eval()\n",
    "    # discriminator.eval()\n",
    "\n",
    "    # with torch.no_grad():  # No gradients needed for evaluation, which saves memory and computations\n",
    "    #     val_d_loss = 0\n",
    "    #     val_g_loss = 0\n",
    "    #     val_g_recon_loss = 0\n",
    "    #     val_g_adv_loss = 0\n",
    "        \n",
    "    #     for batch_idx, (data, target) in enumerate(val_loader):  # Replace 'val_loader' with your validation data loader\n",
    "    #         data, target = data.to(device), target.to(device)\n",
    "    #         fake_images = net(data)\n",
    "    #         real_images = target\n",
    "\n",
    "    #         # Evaluate discriminator's performance\n",
    "    #         real_predictions = discriminator(real_images)\n",
    "    #         fake_predictions = discriminator(fake_images)\n",
    "    #         d_loss_real_val = wasserstein_loss(real_predictions, True)\n",
    "    #         d_loss_fake_val = wasserstein_loss(fake_predictions, False)\n",
    "    #         torch.set_grad_enabled(True)\n",
    "    #         gradient_penalty_val = compute_gradient_penalty(discriminator, real_images.data, fake_images.data)\n",
    "    #         torch.set_grad_enabled(False)\n",
    "    #         d_loss_total_val = d_loss_real_val + d_loss_fake_val + lambda_gp * gradient_penalty_val\n",
    "\n",
    "    #         # Evaluate generator's performance\n",
    "    #         trick_predictions_val = discriminator(fake_images)\n",
    "    #         g_loss_recon_val = reconstruction_criterion(fake_images, real_images)\n",
    "    #         g_loss_adv_val = -trick_predictions_val.mean()  \n",
    "    #         g_loss_total_val = g_loss_recon_val + lambda_adv * g_loss_adv_val\n",
    "\n",
    "    #         # Accumulate the validation losses\n",
    "    #         val_d_loss += d_loss_total_val.item()\n",
    "    #         val_g_loss += g_loss_total_val.item()\n",
    "    #         val_g_recon_loss += g_loss_recon_val.item()\n",
    "    #         val_g_adv_loss += g_loss_adv_val.item()\n",
    "    print(\"Validation:\")\n",
    "    idx = np.random.randint(0, len(data))\n",
    "    data = denormalize(data, [0.2015333830875326, 0.23070823518400257, 0.22909179679415806], [0.18555881044550504, 0.19490512330453, 0.2298110065725662] )\n",
    "    fake_images = denormalize(fake_images,[0.2015333830875326, 0.23070823518400257, 0.22909179679415806], [0.18555881044550504, 0.19490512330453, 0.2298110065725662])    \n",
    "    inp = data[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "    out = fake_images[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "    lab = target[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "    # print(out.shape, type(out), lab.shape, type(lab))\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    plt.imshow(inp)\n",
    "    ax1.set_title('Input')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    plt.imshow(out)\n",
    "    ax2.set_title('Output')\n",
    "    ax2.axis('off')  \n",
    "\n",
    "    # ax3 = plt.subplot(1, 3, 3)\n",
    "    # plt.imshow(lab)\n",
    "    # ax3.set_title('Target')\n",
    "    # ax3.axis('off') \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    val_d_loss /= len(val_loader)\n",
    "    val_g_loss /= len(val_loader)\n",
    "    lpips_val /= len(val_loader)\n",
    "    tv_val /= len(val_loader)\n",
    "    # fid_val /= len(val_loader)\n",
    "    lpips_scores.append(lpips_val)\n",
    "    tv_scores.append(tv_val)\n",
    "    # val_g_recon_loss /= len(val_loader)\n",
    "    # val_g_adv_loss /= len(val_loader)\n",
    "    writer.add_scalar(\"Discriminator Loss/Validation\", val_d_loss, epoch)\n",
    "    writer.add_scalar(\"Generator Loss/Validation\", val_g_loss, epoch)\n",
    "    writer.add_scalar(\"Metrics/LPIPS\", lpips_val, epoch)\n",
    "    writer.add_scalar(\"Metrics/Total Variation\", tv_val, epoch)\n",
    "    # writer.add_scalar(\"Discriminator Loss/Validation\", val_g_recon_loss, epoch)\n",
    "    # writer.add_scalar(\"Generator Loss/Validation\", val_g_adv_loss, epoch)\n",
    "    print(f'Validation Discriminator Loss: {val_d_loss}')\n",
    "    print(f'Validation Generator Loss: {val_g_loss}')\n",
    "    # print(f'Validation Generator Reconstruction Loss: {val_g_recon_loss}')\n",
    "    # print(f'Validation Generator Adversarial Loss: {val_g_adv_loss}')\n",
    "    d_loss /= len(train_loader)\n",
    "    g_loss /= len(train_loader)\n",
    "    writer.add_scalar(\"Discriminator Loss/Epoch\", d_loss, epoch)\n",
    "    writer.add_scalar(\"Generator Loss/ Epoch\", g_loss, epoch)\n",
    "    print(f'Discriminator Loss Epoch {epoch}: {d_loss}')\n",
    "    print(f'Generator Loss Epoch {epoch}: {g_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), '/home/jc-merlab/Venk/deep-image-prior-master/saved models/14Dec_att_generative_was_YCB.pth')\n",
    "torch.save(discriminator.state_dict(), '/home/jc-merlab/Venk/deep-image-prior-master/saved models/14Dec_att_discrimiator_was_YCB.pth')\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# torch.save(net.state_dict(), '/home/jc-merlab/Venk/deep-image-prior-master/saved models/20_nov_evening_att_generative_was.pth')\n",
    "# torch.save(discriminator.state_dict(), '/home/jc-merlab/Venk/deep-image-prior-master/saved models/20_nov_evening_discriminator_was.pth')\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# torch.save(net.state_dict(), '/home/jc-merlab/Venk/deep-image-prior-master/saved models/24_nov_evening_att_generative_was.pth')\n",
    "# torch.save(discriminator.state_dict(), '/home/jc-merlab/Venk/deep-image-prior-master/saved models/24_nov_evening_discriminator_was.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.load_state_dict(torch.load('/home/jc-merlab/Venk/deep-image-prior-master/saved models/16_nov_evening_att_generative_was.pth')) #5_att_generative_was\n",
    "# discriminator.load_state_dict(torch.load('/home/jc-merlab/Venk/deep-image-prior-master/saved models/16_nov_evening_discriminator_was.pth'))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# net.load_state_dict(torch.load('/home/jc-merlab/Venk/deep-image-prior-master/saved models/20_nov_evening_att_generative_was.pth')) #5_att_generative_was\n",
    "# discriminator.load_state_dict(torch.load('/home/jc-merlab/Venk/deep-image-prior-master/saved models/20_nov_evening_discriminator_was.pth'))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "net.load_state_dict(torch.load('/home/jc-merlab/Venk/deep-image-prior-master/saved models/14Dec_att_generative_was_YCB.pth')) #5_att_generative_was\n",
    "discriminator.load_state_dict(torch.load('/home/jc-merlab/Venk/deep-image-prior-master/saved models/14Dec_att_discrimiator_was_YCB.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "p1 = '/home/jc-merlab/Venk/16Nov_test/KP_test_wasserstein/input/'\n",
    "p2 = '/home/jc-merlab/Venk/16Nov_test/KP_test_wasserstein/labels/'\n",
    "p3 = '/home/jc-merlab/Venk/16Nov_test/KP_test_wasserstein/inpainted/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to call net.eval() and discriminator.eval() to set dropout and batch normalization layers \n",
    "# to evaluation mode before running inference\n",
    "net.eval()\n",
    "discriminator.eval()\n",
    "m = 0\n",
    "\n",
    "with torch.no_grad():  # No gradients needed for testing, which saves memory and computations\n",
    "    test_d_loss = 0\n",
    "    test_g_loss = 0\n",
    "    test_g_recon_loss = 0\n",
    "    test_g_adv_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(test_loader):  # Replace 'test_loader' with your test data loader\n",
    "        if batch_idx < 5:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            fake_images = net(data)\n",
    "            real_images = target\n",
    "\n",
    "            # Evaluate discriminator's performance\n",
    "            real_predictions = discriminator(real_images)\n",
    "            fake_predictions = discriminator(fake_images)\n",
    "            d_loss_real_test = wasserstein_loss(real_predictions, True)\n",
    "            d_loss_fake_test = wasserstein_loss(fake_predictions, False)\n",
    "            d_loss_total_test = d_loss_real_test + d_loss_fake_test\n",
    "\n",
    "            # Evaluate generator's performance\n",
    "            trick_predictions_test = discriminator(fake_images)\n",
    "            g_loss_recon_test = reconstruction_criterion(fake_images, real_images)\n",
    "            g_loss_adv_test = -trick_predictions_test.mean()  \n",
    "            g_loss_total_test = g_loss_recon_test + lambda_adv * g_loss_adv_test\n",
    "\n",
    "            # Accumulate the test losses\n",
    "            test_d_loss += d_loss_total_test.item()\n",
    "            test_g_loss += g_loss_total_test.item()\n",
    "            test_g_recon_loss += g_loss_recon_test.item()\n",
    "            test_g_adv_loss += g_loss_adv_test.item()\n",
    "\n",
    "        \n",
    "            data = denormalize(data, [0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857] )\n",
    "            fake_images = denormalize(fake_images,[0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857])\n",
    "            inp = data[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "            for h,(i, j, k) in enumerate(zip(fake_images, data, target)):\n",
    "                if batch_idx == 0 and h == 0:\n",
    "                    iterator = 0\n",
    "                \n",
    "                inp = j.permute(1,2,0).detach().cpu().clone().numpy()\n",
    "                out = i.permute(1,2,0).detach().cpu().clone().numpy()\n",
    "                lab = k.permute(1,2,0).detach().cpu().clone().numpy()\n",
    "                # print(out.shape, type(out), lab.shape, type(lab))\n",
    "                \n",
    "                m = iterator + m + 1\n",
    "                name = p1 + f'{m}.jpg'\n",
    "                name2 = p2 + f'{m}.jpg'\n",
    "                name3 = p3 + f'{m}.jpg'\n",
    "\n",
    "                # print(name)\n",
    "                # print(name2)\n",
    "                # print(name3)\n",
    "                # cv2.imwrite(name, inp*255)\n",
    "                # cv2.imwrite(name2, lab*255)\n",
    "                # cv2.imwrite(name3, out*255)\n",
    "                plt.figure(figsize=(20, 20))\n",
    "\n",
    "                ax1 = plt.subplot(1, 2, 1)\n",
    "                plt.imshow(inp)\n",
    "                ax1.set_title('Input')\n",
    "                ax1.axis('off')\n",
    "\n",
    "                ax2 = plt.subplot(1, 2, 2)\n",
    "                plt.imshow(out)\n",
    "                ax2.set_title('Output')\n",
    "                ax2.axis('off')  \n",
    "\n",
    "                # # ax3 = plt.subplot(1, 3, 3)\n",
    "                # # plt.imshow(lab)\n",
    "                # # ax3.set_title('Target')\n",
    "                # # ax3.axis('off') \n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    # Calculate the average losses for the entire test set\n",
    "    test_d_loss /= len(test_loader)\n",
    "    test_g_loss /= len(test_loader)\n",
    "    test_g_recon_loss /= len(test_loader)\n",
    "    test_g_adv_loss /= len(test_loader)\n",
    "\n",
    "    # Print the average test losses\n",
    "    print(f'Test Discriminator Loss: {test_d_loss}')\n",
    "    print(f'Test Generator Loss: {test_g_loss}')\n",
    "    print(f'Test Generator Reconstruction Loss: {test_g_recon_loss}')\n",
    "    print(f'Test Generator Adversarial Loss: {test_g_adv_loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on unknown dataset. (The style of making of the dataset is different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/home/jc-merlab/Venk/panda_raw_with_occ/test_27Oct'\n",
    "\n",
    "#021277.rgb.jpg\n",
    "\n",
    "imglst = []\n",
    "for i, img in enumerate(os.listdir(p)):\n",
    "    # if i < 16:\n",
    "        if (images.endswith(\".jpg\")):\n",
    "            imglst.append(img)\n",
    "\n",
    "\n",
    "imglst_sorted = sorted(imglst)\n",
    "print(imglst_sorted, \"\\n\", len(imglst_sorted))\n",
    "\n",
    "testset = ImageLabelDataset(image_dir=p, label_dir=p, image_transform=image_transform, label_transform=label_transform)\n",
    "test = DataLoader(testset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "discriminator.eval()\n",
    "\n",
    "test_d_loss = 0\n",
    "test_g_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        fake_images = net(data)\n",
    "        real_images = target\n",
    "\n",
    "        real_labels = 0.9 * torch.ones((real_images.size(0), 1), device=device)\n",
    "        fake_labels = 0.1 * torch.ones((fake_images.size(0), 1), device=device)\n",
    "\n",
    "        real_predictions = discriminator(real_images)\n",
    "        fake_predictions = discriminator(fake_images)\n",
    "        d_loss_real = criterion(real_predictions, real_labels)\n",
    "        d_loss_fake = criterion(fake_predictions, fake_labels)\n",
    "        d_loss_total = d_loss_real + d_loss_fake\n",
    "\n",
    "        trick_labels = 0.9 * torch.ones(fake_images.size(0), 1, device=device)\n",
    "        trick_predictions = discriminator(fake_images)\n",
    "        g_loss_recon = reconstruction_criterion(fake_images, real_images)\n",
    "        g_loss_adv = criterion(trick_predictions, trick_labels)\n",
    "        g_loss_total = g_loss_recon + lambda_adv * g_loss_adv\n",
    "\n",
    "        test_d_loss += d_loss_total.item()\n",
    "        test_g_loss += g_loss_total.item()\n",
    "        data = denormalize(data, [0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857] )\n",
    "        fake_images = denormalize(fake_images,[0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857])\n",
    "        inp = data[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "        out = fake_images[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "        lab = target[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "        # print(out.shape, type(out), lab.shape, type(lab))\n",
    "\n",
    "        plt.figure(figsize=(20, 20))\n",
    "\n",
    "        ax1 = plt.subplot(1, 2, 1)\n",
    "        plt.imshow(inp)\n",
    "        ax1.set_title('Input')\n",
    "        ax1.axis('off')\n",
    "\n",
    "        ax2 = plt.subplot(1, 2, 2)\n",
    "        plt.imshow(out)\n",
    "        ax2.set_title('Output')\n",
    "        ax2.axis('off')  \n",
    "\n",
    "        # ax3 = plt.subplot(1, 3, 3)\n",
    "        # plt.imshow(lab)\n",
    "        # ax3.set_title('Target')\n",
    "        # ax3.axis('off') \n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        test_d_loss /= len(data)\n",
    "        test_g_loss /= len(data)\n",
    "\n",
    "        print(f'Test Discriminator Loss: {test_d_loss}')\n",
    "        print(f'Test Generator Loss: {test_g_loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jnegierbgiebrig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "p1 = '/home/jc-merlab/Venk/Nov_11_2023_Testing/inpaint/images/'\n",
    "p2 = '/home/jc-merlab/Venk/Nov_11_2023_Testing/inpaint/labels/'\n",
    "dest = '/home/jc-merlab/Venk/Nov_11_2023_Testing/detect_kps/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageLabelDataset(image_dir=p1, label_dir=p2, image_transform=image_transform, label_transform=label_transform)\n",
    "test_loader = DataLoader(dataset, batch_size=12, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "discriminator.eval()\n",
    "m = 0\n",
    "test_d_loss = 0\n",
    "test_g_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if batch_idx <5:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            fake_images = net(data)\n",
    "            real_images = target\n",
    "\n",
    "            real_labels = 0.9 * torch.ones((real_images.size(0), 1), device=device)\n",
    "            fake_labels = 0.1 * torch.ones((fake_images.size(0), 1), device=device)\n",
    "\n",
    "            real_predictions = discriminator(real_images)\n",
    "            fake_predictions = discriminator(fake_images)\n",
    "            d_loss_real = criterion(real_predictions, real_labels)\n",
    "            d_loss_fake = criterion(fake_predictions, fake_labels)\n",
    "            d_loss_total = d_loss_real + d_loss_fake\n",
    "\n",
    "            trick_labels = 0.9 * torch.ones(fake_images.size(0), 1, device=device)\n",
    "            trick_predictions = discriminator(fake_images)\n",
    "            g_loss_recon = reconstruction_criterion(fake_images, real_images)\n",
    "            g_loss_adv = criterion(trick_predictions, trick_labels)\n",
    "            g_loss_total = g_loss_recon + lambda_adv * g_loss_adv\n",
    "\n",
    "            test_d_loss += d_loss_total.item()\n",
    "            test_g_loss += g_loss_total.item()\n",
    "            data = denormalize(data, [0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857] )\n",
    "            fake_images = denormalize(fake_images,[0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857])\n",
    "\n",
    "            for h,(i, j, k) in enumerate(zip(fake_images, data, target)):\n",
    "                if batch_idx == 0 and h == 0:\n",
    "                    iterator = 0\n",
    "\n",
    "                inp = j.permute(1,2,0).detach().cpu().clone().numpy()\n",
    "                out = i.permute(1,2,0).detach().cpu().clone().numpy()\n",
    "                lab = k.permute(1,2,0).detach().cpu().clone().numpy()\n",
    "                # print(out.shape, type(out), lab.shape, type(lab))\n",
    "                \n",
    "                m = iterator + m + 1\n",
    "                name = p1 + f'{m}.jpg'\n",
    "\n",
    "                print(name)\n",
    "                # cv2.imwrite(name, out*255)\n",
    "\n",
    "                plt.figure(figsize=(20, 20))\n",
    "\n",
    "                ax1 = plt.subplot(1, 2, 1)\n",
    "                plt.imshow(inp)\n",
    "                ax1.set_title('Input')\n",
    "                ax1.axis('off')\n",
    "\n",
    "                ax2 = plt.subplot(1, 2, 2)\n",
    "                plt.imshow(out)\n",
    "                ax2.set_title('Output')\n",
    "                ax2.axis('off')  \n",
    "\n",
    "                # ax3 = plt.subplot(1, 3, 3)\n",
    "                # plt.imshow(lab)\n",
    "                # ax3.set_title('Target')\n",
    "                # ax3.axis('off') \n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "            test_d_loss /= len(data)\n",
    "            test_g_loss /= len(data)\n",
    "\n",
    "            print(f'Test Discriminator Loss: {test_d_loss}')\n",
    "            print(f'Test Generator Loss: {test_g_loss}')\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing random sofa objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "p1 = '/home/jc-merlab/Venk/New_Objects_Test_28_Nov/images'\n",
    "p2 = '/home/jc-merlab/Venk/New_Objects_Test_28_Nov/labels'\n",
    "# dest = '/home/jc-merlab/Venk/Nov_11_2023_Testing/detect_kps/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= ImageLabelDataset(image_dir=p1, label_dir=p2, image_transform=image_transform, label_transform=label_transform)\n",
    "te = DataLoader(d, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, target) in enumerate(te):\n",
    "    if batch_idx < 2:    \n",
    "        # print(data.shape, target.shape)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        idx = np.random.randint(0, len(data))\n",
    "        print(data.shape, target.shape)\n",
    "        print(data[idx,:,:,:].permute(1,2,0).shape)\n",
    "        inp = data[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "        # out = output[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "        lab = target[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "        print(lab.shape, type(lab))\n",
    "        data = denormalize(data, [0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857] )\n",
    "        target = denormalize(target,[0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857])\n",
    "        for i, (j, k) in enumerate(zip(data, target)):\n",
    "        \n",
    "            plt.figure(figsize=(10, 5))\n",
    "\n",
    "            ax1 = plt.subplot(1, 2, 1)\n",
    "            # print(i.shape, j.shape, k.shape)\n",
    "            plt.imshow(j.permute(1,2,0).detach().cpu().clone().numpy())\n",
    "            ax1.set_title('Input')\n",
    "            ax1.axis('off')\n",
    "\n",
    "\n",
    "            ax3 = plt.subplot(1, 2, 2)\n",
    "            plt.imshow(k.permute(1,2,0).detach().cpu().clone().numpy())\n",
    "            ax3.set_title('Target')\n",
    "            ax3.axis('off') \n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "discriminator.eval()\n",
    "m = 0\n",
    "test_d_loss = 0\n",
    "test_g_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(te):\n",
    "        if batch_idx <5:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            fake_images = net(data)\n",
    "            real_images = target\n",
    "\n",
    "            real_labels = 0.9 * torch.ones((real_images.size(0), 1), device=device)\n",
    "            fake_labels = 0.1 * torch.ones((fake_images.size(0), 1), device=device)\n",
    "\n",
    "            real_predictions = discriminator(real_images)\n",
    "            fake_predictions = discriminator(fake_images)\n",
    "            d_loss_real = criterion(real_predictions, real_labels)\n",
    "            d_loss_fake = criterion(fake_predictions, fake_labels)\n",
    "            d_loss_total = d_loss_real + d_loss_fake\n",
    "\n",
    "            trick_labels = 0.9 * torch.ones(fake_images.size(0), 1, device=device)\n",
    "            trick_predictions = discriminator(fake_images)\n",
    "            g_loss_recon = reconstruction_criterion(fake_images, real_images)\n",
    "            g_loss_adv = criterion(trick_predictions, trick_labels)\n",
    "            g_loss_total = g_loss_recon + lambda_adv * g_loss_adv\n",
    "\n",
    "            test_d_loss += d_loss_total.item()\n",
    "            test_g_loss += g_loss_total.item()\n",
    "            data = denormalize(data, [0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857] )\n",
    "            fake_images = denormalize(fake_images,[0.209555113170385, 0.22507974363977162, 0.20982026500023962], [0.20639409678896012, 0.19208633033458372, 0.20659148273508857])\n",
    "\n",
    "            for h,(i, j, k) in enumerate(zip(fake_images, data, target)):\n",
    "                if batch_idx == 0 and h == 0:\n",
    "                    iterator = 0\n",
    "\n",
    "                inp = j.permute(1,2,0).detach().cpu().clone().numpy()\n",
    "                out = i.permute(1,2,0).detach().cpu().clone().numpy()\n",
    "                lab = k.permute(1,2,0).detach().cpu().clone().numpy()\n",
    "                # print(out.shape, type(out), lab.shape, type(lab))\n",
    "                \n",
    "                m = iterator + m + 1\n",
    "                name = p1 + f'{m}.jpg'\n",
    "\n",
    "                print(name)\n",
    "                # cv2.imwrite(name, out*255)\n",
    "\n",
    "                plt.figure(figsize=(20, 20))\n",
    "\n",
    "                ax1 = plt.subplot(1, 2, 1)\n",
    "                plt.imshow(inp)\n",
    "                ax1.set_title('Input')\n",
    "                ax1.axis('off')\n",
    "\n",
    "                ax2 = plt.subplot(1, 2, 2)\n",
    "                plt.imshow(out)\n",
    "                ax2.set_title('Output')\n",
    "                ax2.axis('off')  \n",
    "\n",
    "                # ax3 = plt.subplot(1, 3, 3)\n",
    "                # plt.imshow(lab)\n",
    "                # ax3.set_title('Target')\n",
    "                # ax3.axis('off') \n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "            test_d_loss /= len(data)\n",
    "            test_g_loss /= len(data)\n",
    "\n",
    "            print(f'Test Discriminator Loss: {test_d_loss}')\n",
    "            print(f'Test Generator Loss: {test_g_loss}')\n",
    "        else:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
