{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for **\"Inpainting\"** figures $6$, $8$ and 7 (top) from the main paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from models.resnet import ResNet\n",
    "from models.unet import UNet\n",
    "from models.skip import skip\n",
    "from models.dcgan import dcgan\n",
    "import torch\n",
    "import torch.optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "from torchmetrics.image import TotalVariation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "# from utils.inpainting_utils import *\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "PLOT = True\n",
    "imsize = -1\n",
    "dim_div_by = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# NET_TYPE = 'UNET' # one of skip_depth4|skip_depth2|UNET|ResNet\n",
    "NET_TYPE = 'UNET'\n",
    "dtype = torch.float32\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "num_channels = 3\n",
    "\n",
    "INPUT = 'meshgrid'\n",
    "input_depth =  num_channels  # Changed to reflect batch size and channel number\n",
    "num_iter = 4001\n",
    "show_every = 900\n",
    "figsize = 8\n",
    "reg_noise_std = 0.00\n",
    "param_noise = True\n",
    "\n",
    "if NET_TYPE == 'UNET':\n",
    "    # net = UNet(num_input_channels=input_depth, num_output_channels=3, \n",
    "    #             feature_scale=8, more_layers=1, \n",
    "    #             concat_x=False, upsample_mode='deconv', \n",
    "    #             pad='zero', norm_layer=torch.nn.InstanceNorm2d, need_sigmoid=True, need_bias=True)\n",
    "    # net = UNet(num_input_channels=input_depth, num_output_channels=3, \n",
    "    #         feature_scale=2, more_layers=0, \n",
    "    #         concat_x=False, upsample_mode='deconv', \n",
    "    #         pad='zero', norm_layer=torch.nn.InstanceNorm2d, need_sigmoid=True, need_bias=True)\n",
    "    net = UNet()\n",
    "    LR = 0.001\n",
    "    param_noise = False\n",
    "\n",
    "\n",
    "net = net.type(dtype)\n",
    "\n",
    "# inputs = get_noisee(batch_size, 3, INPUT, 256, noise_type='u', var=1./10)\n",
    "# print(inputs.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (e1): encoder_block(\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (e2): encoder_block(\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (e3): encoder_block(\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (e4): encoder_block(\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (e5): encoder_block(\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (e6): encoder_block(\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (e7): encoder_block(\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (e8): encoder_block(\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (b): conv_block(\n",
      "    (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (d1): decoder_block(\n",
      "    (up): ConvTranspose2d(2048, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (attention): AttentionBlock(\n",
      "      (W_g): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (W_x): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (psi): Sequential(\n",
      "        (0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (d2): decoder_block(\n",
      "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (attention): AttentionBlock(\n",
      "      (W_g): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (W_x): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (psi): Sequential(\n",
      "        (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (d3): decoder_block(\n",
      "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (attention): AttentionBlock(\n",
      "      (W_g): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (W_x): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (psi): Sequential(\n",
      "        (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (d4): decoder_block(\n",
      "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (attention): AttentionBlock(\n",
      "      (W_g): Sequential(\n",
      "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (W_x): Sequential(\n",
      "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (psi): Sequential(\n",
      "        (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (d5): decoder_block(\n",
      "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (attention): AttentionBlock(\n",
      "      (W_g): Sequential(\n",
      "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (W_x): Sequential(\n",
      "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (psi): Sequential(\n",
      "        (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (d6): decoder_block(\n",
      "    (up): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (attention): AttentionBlock(\n",
      "      (W_g): Sequential(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (W_x): Sequential(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (psi): Sequential(\n",
      "        (0): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (d7): decoder_block(\n",
      "    (up): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (attention): AttentionBlock(\n",
      "      (W_g): Sequential(\n",
      "        (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (W_x): Sequential(\n",
      "        (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (psi): Sequential(\n",
      "        (0): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (d8): decoder_block(\n",
      "    (up): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (attention): AttentionBlock(\n",
      "      (W_g): Sequential(\n",
      "        (0): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (W_x): Sequential(\n",
      "        (0): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (psi): Sequential(\n",
      "        (0): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (outputs): Conv2d(8, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (noise): GaussianNoiseLayer()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# class ImageLabelDataset(Dataset):\n",
    "#     def __init__(self, image_dir, label_dir, image_transform=None, label_transform=None):\n",
    "#         self.image_dir = image_dir\n",
    "#         self.label_dir = label_dir\n",
    "#         self.image_files = os.listdir(image_dir)\n",
    "#         self.image_transform = image_transform\n",
    "#         self.label_transform = label_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_files)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_name = os.path.join(self.image_dir, self.image_files[idx])\n",
    "#         label_name = os.path.join(self.label_dir, self.image_files[idx])\n",
    "\n",
    "#         image = Image.open(img_name).convert('RGB')\n",
    "#         label = Image.open(label_name).convert('RGB')  # Assuming label is grayscale\n",
    "\n",
    "#         seed = np.random.randint(2147483647)  # make a seed with numpy generator \n",
    "        \n",
    "#         if self.image_transform or self.label_transform:\n",
    "#             random.seed(seed)  # apply this seed to img transforms\n",
    "#             torch.manual_seed(seed)\n",
    "#             image = self.image_transform(image)\n",
    "\n",
    "#             random.seed(seed)  # apply this seed to label transforms\n",
    "#             torch.manual_seed(seed)\n",
    "#             label = self.label_transform(label)\n",
    "\n",
    "#         return image, label\n",
    "\n",
    "# image_transform = transforms.Compose([\n",
    "#     transforms.Resize((480, 640)),\n",
    "#     # transforms.RandomHorizontalFlip(p=0.15),\n",
    "#     # transforms.RandomRotation(degrees=(-5, 5)),\n",
    "#     # # transforms.RandomVerticalFlip(p=0.1),\n",
    "#     # transforms.ColorJitter(brightness=0.3, contrast=0.2, saturation=0.1, hue=0.1),\n",
    "#     # transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),\n",
    "#     # transforms.RandomEqualize(p=0.01),\n",
    "#     # transforms.RandomAutocontrast(p=0.01),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# label_transform = transforms.Compose([\n",
    "#     transforms.Resize((480, 640)),\n",
    "#     # transforms.RandomHorizontalFlip(p=0.15),\n",
    "#     # transforms.RandomRotation(degrees=(-5, 5)),\n",
    "#     # transforms.RandomVerticalFlip(p=0.1),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# # class TrainTransform:\n",
    "# #     def __init__(self):\n",
    "# #         self.transform = A.Compose([\n",
    "# #             A.Resize(480,480),\n",
    "# #             # A.RandomRotate90(p=0.2),\n",
    "# #             A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=1),\n",
    "# #             ToTensorV2()\n",
    "# #         ])\n",
    "\n",
    "# #     def __call__(self, image, label):\n",
    "# #         return self.transform(image=image, label=label)\n",
    "    \n",
    "# # train_transform = TrainTransform()\n",
    "\n",
    "# image_dir = train_path\n",
    "# label_dir = label_path\n",
    "# dataset = ImageLabelDataset(image_dir=image_dir, label_dir=label_dir, \n",
    "#                             image_transform=image_transform, \n",
    "#                             label_transform=label_transform)\n",
    "\n",
    "# total_size = len(dataset)\n",
    "# train_size = int(0.9 * total_size)\n",
    "# val_size = (total_size - train_size) // 2\n",
    "# test_size = total_size - train_size - val_size\n",
    "\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# s  = sum(np.prod(list(p.size())) for p in net.parameters())\n",
    "# print ('Number of params: %d' % s)\n",
    "\n",
    "mse = torch.nn.MSELoss().type(dtype)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#     if batch_idx < 2:    \n",
    "#         # print(data.shape, target.shape)\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         idx = np.random.randint(0, len(data))\n",
    "#         print(data.shape, target.shape)\n",
    "#         print(data[idx,:,:,:].permute(1,2,0).shape)\n",
    "#         inp = data[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "#         # out = output[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "#         lab = target[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "#         print(lab.shape, type(lab))\n",
    "#         for i, (j, k) in enumerate(zip(data, target)):\n",
    "        \n",
    "#             plt.figure(figsize=(10, 5))\n",
    "\n",
    "#             ax1 = plt.subplot(1, 2, 1)\n",
    "#             # print(i.shape, j.shape, k.shape)\n",
    "#             plt.imshow(j.permute(1,2,0).detach().cpu().clone().numpy())\n",
    "#             ax1.set_title('Input')\n",
    "#             ax1.axis('off')\n",
    "\n",
    "\n",
    "#             ax3 = plt.subplot(1, 2, 2)\n",
    "#             plt.imshow(k.permute(1,2,0).detach().cpu().clone().numpy())\n",
    "#             ax3.set_title('Target')\n",
    "#             ax3.axis('off') \n",
    "\n",
    "#             plt.tight_layout()\n",
    "#             plt.show()\n",
    "\n",
    "#     else:\n",
    "#         break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net.load_state_dict(torch.load('/home/jc-merlab/Venk/deep-image-prior-master/saved models/10_att_augment.pth'))\n",
    "trained_model_23_nov = '/home/jc-merlab/Pictures/Data/trained_models/inpainting/14Dec_att_generative_was_YCB.pth'\n",
    "net.load_state_dict(torch.load(trained_model_23_nov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "# net = net.to(device)\n",
    "# criterion = nn.MSELoss().type(dtype)  \n",
    "# # criterion = nn.L1Loss().type(dtype)\n",
    "# # criterion = StructuralSimilarityIndexMeasure().type(dtype).to(device)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "# num_epochs = 30\n",
    "\n",
    "# for epoch in range(num_epochs):  \n",
    "#     net.train()\n",
    "#     train_loss = 0\n",
    "\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         # print(data.shape, target.shape)\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "        \n",
    "#         # net_input = get_noisee(data.shape[0], input_depth, INPUT, data.shape[2:]).to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         output = net(data)\n",
    "        \n",
    "#         loss = criterion(output, target)\n",
    "#         train_loss = train_loss + loss.item()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "            \n",
    "#     net.eval()\n",
    "#     val_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in val_loader:\n",
    "\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             # print(data.shape, target.shape)\n",
    "#             # net_input = get_noisee(data.shape[0], input_depth, INPUT, data.shape[2:]).to(device)\n",
    "#             output = net(data)\n",
    "#             # print(output.shape)\n",
    "#             valloss = criterion(output, target)\n",
    "#             val_loss = val_loss + valloss.item()\n",
    "#             idx = np.random.randint(0, len(data))\n",
    "\n",
    "#         print(data[idx,:,:,:].permute(1,2,0).shape)\n",
    "#         inp = data[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "#         out = output[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "#         lab = target[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "#         # print(out.shape, type(out), lab.shape, type(lab))\n",
    "\n",
    "#         plt.figure(figsize=(15, 15))\n",
    "\n",
    "#         ax1 = plt.subplot(1, 2, 1)\n",
    "#         plt.imshow(inp)\n",
    "#         ax1.set_title('Input')\n",
    "#         ax1.axis('off')\n",
    "\n",
    "#         ax2 = plt.subplot(1, 2, 2)\n",
    "#         plt.imshow(out)\n",
    "#         ax2.set_title('Output')\n",
    "#         ax2.axis('off')  \n",
    "\n",
    "#         # ax3 = plt.subplot(1, 3, 3)\n",
    "#         # plt.imshow(lab)\n",
    "#         # ax3.set_title('Target')\n",
    "#         # ax3.axis('off') \n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "            \n",
    "    \n",
    "#     val_loss /= len(val_loader)\n",
    "#     train_loss /= len(train_loader)\n",
    "#     writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "#     writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "#     print(f\"Training Loss after Epoch {epoch}: {train_loss}\")\n",
    "#     print(f\"Validation Loss after Epoch {epoch}: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), '/home/jc-merlab/Venk/deep-image-prior-master/saved models/22nov_aug.pth')\n",
    "# torch.save(net.state_dict(), '/home/jc-merlab/Venk/deep-image-prior-master/saved models/24nov_aug.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.load_state_dict(torch.load('/home/jc-merlab/Venk/deep-image-prior-master/saved models/22nov_aug.pth'))\n",
    "# net.load_state_dict(torch.load('/home/jc-merlab/Venk/deep-image-prior-master/saved models/24nov_aug.pth'))\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.eval()\n",
    "# import cv2\n",
    "# with torch.no_grad():\n",
    "#     for batch_idx, (data, target) in enumerate(test_loader):\n",
    "#         # if batch_idx < 2:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "            \n",
    "#             # net_input = get_noisee(data.shape[0], input_depth, INPUT, data.shape[2:]).to(device)\n",
    "            \n",
    "#             output = net(data)\n",
    "            \n",
    "#             print(data.shape)\n",
    "#             idx = np.random.randint(0, len(data))\n",
    "\n",
    "#             print(data[idx,:,:,:].permute(1,2,0).shape)\n",
    "#             inp = data[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "#             out = output[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "#             lab = target[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "#             # print(out.shape, type(out), lab.shape, type(lab))\n",
    "            \n",
    "\n",
    "#             # cv2.imwrite(f'/home/jc-merlab/Venk/deep-image-prior-master/KP_Test/{7+batch_idx}.jpg',out*255)\n",
    "#             plt.figure(figsize=(15, 15))\n",
    "\n",
    "#             ax1 = plt.subplot(1, 2, 1)\n",
    "#             plt.imshow(inp)\n",
    "#             ax1.set_title('Input')\n",
    "#             ax1.axis('off')\n",
    "\n",
    "#             ax2 = plt.subplot(1, 2, 2)\n",
    "#             plt.imshow(out)\n",
    "#             ax2.set_title('Output')\n",
    "#             ax2.axis('off')  \n",
    "\n",
    "#             # ax3 = plt.subplot(1, 3, 3)\n",
    "#             # plt.imshow(lab)\n",
    "#             # ax3.set_title('Target')\n",
    "#             # ax3.axis('off') \n",
    "\n",
    "#             plt.tight_layout()\n",
    "#             plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = '/home/jc-merlab/Venk/panda_raw_with_occ/test_27Oct'\n",
    "\n",
    "# #021277.rgb.jpg\n",
    "\n",
    "# imglst = []\n",
    "# for i, img in enumerate(os.listdir(p)):\n",
    "#     # if i < 16:\n",
    "#         if (images.endswith(\".jpg\")):\n",
    "#             imglst.append(img)\n",
    "\n",
    "\n",
    "# imglst_sorted = sorted(imglst)\n",
    "# print(imglst_sorted, \"\\n\", len(imglst_sorted))\n",
    "\n",
    "# testset = dataset = ImageLabelDataset(image_dir=p, label_dir=p, image_transform=image_transform,label_transform=label_transform)\n",
    "# test = DataLoader(testset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# net.eval()\n",
    "# with torch.no_grad():\n",
    "#     for batch_idx, (data, target) in enumerate(test):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "        \n",
    "#         # net_input = get_noisee(data.shape[0], input_depth, INPUT, data.shape[2:]).to(device)\n",
    "        \n",
    "#         output = net(data)\n",
    "        \n",
    "#         print(data.shape)\n",
    "#         idx = np.random.randint(0, len(data))\n",
    "\n",
    "#         # print(data[idx,:,:,:].permute(1,2,0).shape)\n",
    "#         # inp = data[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "#         # out = output[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "#         # lab = target[idx,:,:,:].permute(1,2,0).detach().cpu().clone().numpy()\n",
    "#         # print(out.shape, type(out), lab.shape, type(lab))\n",
    "#         for h,(i, j, k) in enumerate(zip(output, data, target)):\n",
    "            \n",
    "#             plt.figure(figsize=(10, 5))\n",
    "\n",
    "#             ax1 = plt.subplot(1, 3, 1)\n",
    "#             # print(i.shape, j.shape, k.shape)\n",
    "#             plt.imshow(j.permute(1,2,0).detach().cpu().clone().numpy())\n",
    "#             ax1.set_title('Input')\n",
    "#             ax1.axis('off')\n",
    "\n",
    "#             name = \"/home/jc-merlab/Venk/deep-image-prior-master/KP_Test/\" + f'{batch_idx+h}.jpg'\n",
    "#             print(name)\n",
    "#             ax2 = plt.subplot(1, 3, 2)\n",
    "#             plt.imshow(i.permute(1,2,0).detach().cpu().clone().numpy())\n",
    "#             # cv2.imwrite(name,(i.permute(1,2,0).detach().cpu().clone().numpy())*255)\n",
    "#             ax2.set_title('Output')\n",
    "#             ax2.axis('off')  \n",
    "\n",
    "#             ax3 = plt.subplot(1, 3, 3)\n",
    "#             plt.imshow(k.permute(1,2,0).detach().cpu().clone().numpy())\n",
    "#             ax3.set_title('Target')\n",
    "#             ax3.axis('off') \n",
    "\n",
    "#             plt.tight_layout()\n",
    "#             plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16908615680\n",
      "517996544\n",
      "504766976\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import json\n",
    "from os.path import expanduser\n",
    "import splitfolders\n",
    "import shutil\n",
    "# from define_path import Def_Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "# from torchsummary import summary\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A # Library for augmentations\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "\n",
    "# # Get the directory of the current script\n",
    "# current_script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# # Navigate up to the 'scripts' directory\n",
    "# scripts_dir = os.path.dirname(current_script_dir)\n",
    "\n",
    "# # Add 'scripts' directory to sys.path\n",
    "# sys.path.append(scripts_dir)\n",
    "\n",
    "import transforms, utils, engine, train\n",
    "from utils import collate_fn\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "\n",
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "print(t)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "print(r)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "print(a)\n",
    "f = r-a  # free inside reserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture('/home/jc-merlab/Pictures/panda_data/images_for_occlusion/1/occ_test_1.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# trained_model_23_nov = '/home/jc-merlab/Venk/deep-image-prior-master/saved models/24nov_aug.pth'\n",
    "# net.load_state_dict(torch.load(trained_model_23_nov))\n",
    "# Prepare video writer\n",
    "out = cv2.VideoWriter('/home/jc-merlab/Pictures/panda_data/images_for_occlusion/1/occ_test_1_op.avi', cv2.VideoWriter_fourcc(*'XVID'), fps, (frame_width, frame_height))\n",
    "net.eval()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(frame)\n",
    "    plt.show()\n",
    "\n",
    "    # Convert frame to tensor and normalize\n",
    "    frame_tensor = torch.from_numpy(frame).float()\n",
    "    frame_tensor = frame_tensor.permute(2, 0, 1) / 255.0  # Normalize and convert HWC to CHW\n",
    "    frame_tensor = frame_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Move to GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        frame_tensor = frame_tensor.to('cuda')\n",
    "\n",
    "    # Inference\n",
    "    inpainted_frame_tensor = net(frame_tensor)\n",
    "\n",
    "    # Move to CPU and convert to numpy for visualization\n",
    "    inpainted_frame_tensor = inpainted_frame_tensor.to('cpu').detach()\n",
    "    inpainted_frame = inpainted_frame_tensor.squeeze(0).permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Assuming the output is in [0, 1], we scale to [0, 255] for visualization\n",
    "    inpainted_frame = (inpainted_frame * 255).astype(np.uint8)\n",
    "\n",
    "    # Convert RGB to BGR for OpenCV\n",
    "    inpainted_frame_bgr = cv2.cvtColor(inpainted_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Display the frame\n",
    "    plt.imshow(inpainted_frame)\n",
    "    plt.show()\n",
    "\n",
    "    # Write the frame into the file\n",
    "    out.write(inpainted_frame_bgr)  # Make sure to write BGR image\n",
    "\n",
    "# Release everything when done\n",
    "cap.release()\n",
    "out.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
