{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f533ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import json\n",
    "from os.path import expanduser\n",
    "import splitfolders\n",
    "import shutil\n",
    "from define_path import Def_Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A # Library for augmentations\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "\n",
    "import transforms, utils, engine, train\n",
    "from utils import collate_fn\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "\n",
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "print(t)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "print(r)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "print(a)\n",
    "# f = r-a  # free inside reserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27dc182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to generalize home directory. User can change their parent path without entering their home directory\n",
    "path = Def_Path()\n",
    "\n",
    "# parent_path =  path.home + \"/Workspace/WPI/Summer2023/ws/duc_repo/src/panda_test/\" + \"data/kp_test_images/\"\n",
    "# parent_path =  path.home + \"/Workspace/WPI/Summer2023/ws/duc_repo/src/panda_test/\" + \"data/sim_marker/\"\n",
    "parent_path = \"/home/jc-merlab/Pictures/Data/\"\n",
    "\n",
    "# root_dir = parent_path + path.year + \"-\" + path.month + \"-\" + path.day + \"/\"\n",
    "root_dir = parent_path + \"occ_panda_physical_dataset\" + \"/\"\n",
    "\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d2fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# torch.cuda.set_per_process_memory_fraction(0.9, 0)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this fucntion tranforms an input image for diverseifying data for training\n",
    "def train_transform():\n",
    "    return A.Compose([\n",
    "        A.Sequential([\n",
    "            A.RandomRotate90(p=1), # Random rotation of an image by 90 degrees zero or more times\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.2, brightness_by_max=True, always_apply=False, p=1), # Random change of brightness & contrast\n",
    "        ], p=1)\n",
    "    ],\n",
    "    keypoint_params=A.KeypointParams(format='xy'), # More about keypoint formats used in albumentations library read at https://albumentations.ai/docs/getting_started/keypoints_augmentation/\n",
    "    bbox_params=A.BboxParams(format='pascal_voc', label_fields=['bboxes_labels']) # Bboxes should have labels, read more at https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is to split the dataset into train, test and validation folder.\n",
    "def train_test_split(src_dir):\n",
    "    dst_dir_img = src_dir + \"images\"\n",
    "    dst_dir_anno = src_dir + \"annotations\"\n",
    "    \n",
    "    if os.path.exists(dst_dir_img) and os.path.exists(dst_dir_anno):\n",
    "        print(\"folders exist\")\n",
    "    else:\n",
    "        os.mkdir(dst_dir_img)\n",
    "        os.mkdir(dst_dir_anno)\n",
    "        \n",
    "    for jpgfile in glob.iglob(os.path.join(src_dir, \"*.jpg\")):\n",
    "        shutil.copy(jpgfile, dst_dir_img)\n",
    "\n",
    "#     for jsonfile in glob.iglob(os.path.join(src_dir, \"*.json\")):\n",
    "#         shutil.copy(jsonfile, dst_dir_anno)\n",
    "        \n",
    "    for jsonfile in glob.iglob(os.path.join(src_dir, \"*.json\")):\n",
    "        if not jsonfile.endswith(\"_vel.json\") and not jsonfile.endswith(\"_combined.json\"):\n",
    "            shutil.copy(jsonfile, dst_dir_anno) \n",
    "        \n",
    "#     output = parent_path + \"split_folder_output\" + \"-\" + path.year + \"-\" + path.month + \"-\" + path.day \n",
    "\n",
    "    output = src_dir + \"split_folder_output\"\n",
    "    \n",
    "    print(output)\n",
    "    \n",
    "    splitfolders.ratio(src_dir, # The location of dataset\n",
    "                   output=output, # The output location\n",
    "                   seed=42, # The number of seed\n",
    "                   ratio=(.7, .2, .1), # The ratio of split dataset\n",
    "                   group_prefix=None, # If your dataset contains more than one file like \".jpg\", \".pdf\", etc\n",
    "                   move=False # If you choose to move, turn this into True\n",
    "                   )\n",
    "    \n",
    "    shutil.rmtree(dst_dir_img)\n",
    "    shutil.rmtree(dst_dir_anno)\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, demo=False):                \n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.demo = demo # Use demo=True if you need transformed and original images (for example, for visualization purposes)\n",
    "        self.imgs_files = sorted(os.listdir(os.path.join(root, \"images\")))\n",
    "        self.annotations_files = sorted(os.listdir(os.path.join(root, \"annotations\")))\n",
    "#         self.imgs_files = [file for file in sorted(os.listdir(root)) if file.endswith(\".jpg\")]\n",
    "#         self.annotations_files = [file for file in sorted(os.listdir(root)) if file.endswith(\".json\")]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         img_path = os.path.join(self.root, self.imgs_files[idx])\n",
    "#         annotations_path = os.path.join(self.root, self.annotations_files[idx])\n",
    "        img_path = os.path.join(self.root, \"images\", self.imgs_files[idx])\n",
    "        annotations_path = os.path.join(self.root, \"annotations\", self.annotations_files[idx])\n",
    "\n",
    "        img_original = cv2.imread(img_path)\n",
    "        img_original = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB)        \n",
    "        \n",
    "        with open(annotations_path) as f:\n",
    "            data = json.load(f)\n",
    "#             bboxes_original = data['bboxes'][:3]\n",
    "            bboxes_original = data['bboxes']\n",
    "#             print(\"bounding boxes\", bboxes_original)\n",
    "#             keypoints_original = data['keypoints'][:3]\n",
    "            keypoints_original = data['keypoints']\n",
    "#             print(\"original keypoints\", np.array(keypoints_original))\n",
    "#             print(\"original keypoints shape\", (np.array(keypoints_original)).shape)\n",
    "            \n",
    "            # All objects are keypoints on the robot\n",
    "            bboxes_labels_original = [] \n",
    "            bboxes_labels_original.append('base_joint')\n",
    "            bboxes_labels_original.append('joint2')\n",
    "            bboxes_labels_original.append('joint3')\n",
    "            bboxes_labels_original.append('joint4')\n",
    "            bboxes_labels_original.append('joint5')\n",
    "            bboxes_labels_original.append('joint6') \n",
    "            bboxes_labels_original.append('joint7')\n",
    "            bboxes_labels_original.append('joint8')\n",
    "            bboxes_labels_original.append('joint9')\n",
    "#             bboxes_labels_original.append('panda_finger_1')\n",
    "#             bboxes_labels_original.append('panda_finger_2')\n",
    "            \n",
    "#         print(bboxes_original)\n",
    "#         print(bboxes_labels_original)\n",
    "\n",
    "        if self.transform:   \n",
    "            # Converting keypoints from [x,y,visibility]-format to [x, y]-format + Flattening nested list of keypoints            \n",
    "            # For example, if we have the following list of keypoints for three objects (each object has two keypoints):\n",
    "            # [[obj1_kp1, obj1_kp2], [obj2_kp1, obj2_kp2], [obj3_kp1, obj3_kp2]], where each keypoint is in [x, y]-format            \n",
    "            # Then we need to convert it to the following list:\n",
    "            # [obj1_kp1, obj1_kp2, obj2_kp1, obj2_kp2, obj3_kp1, obj3_kp2]\n",
    "            keypoints_original_flattened = [el[0:2] for kp in keypoints_original for el in kp]\n",
    "            \n",
    "            # Apply augmentations\n",
    "            transformed = self.transform(image=img_original, bboxes=bboxes_original, bboxes_labels=bboxes_labels_original, keypoints=keypoints_original_flattened)\n",
    "            img = transformed['image']\n",
    "            bboxes = transformed['bboxes']\n",
    "            # Unflattening list transformed['keypoints']\n",
    "            # For example, if we have the following list of keypoints for three objects (each object has two keypoints):\n",
    "            # [obj1_kp1, obj1_kp2, obj2_kp1, obj2_kp2, obj3_kp1, obj3_kp2], where each keypoint is in [x, y]-format\n",
    "            # Then we need to convert it to the following list:\n",
    "            # [[obj1_kp1, obj1_kp2], [obj2_kp1, obj2_kp2], [obj3_kp1, obj3_kp2]]\n",
    "            keypoints_transformed_unflattened = np.reshape(np.array(transformed['keypoints']), (-1,1,2)).tolist()\n",
    "\n",
    "            # Converting transformed keypoints from [x, y]-format to [x,y,visibility]-format by appending original visibilities to transformed coordinates of keypoints\n",
    "            keypoints = []\n",
    "            for o_idx, obj in enumerate(keypoints_transformed_unflattened):\n",
    "#                 print(\"object\", obj)\n",
    "#                 print(\" obj index\", o_idx)# Iterating over objects\n",
    "                obj_keypoints = []\n",
    "                for k_idx, kp in enumerate(obj): # Iterating over keypoints in each object\n",
    "#                     print(\"kp index\", k_idx)\n",
    "#                     print(\"key points\",kp)\n",
    "#                     print(\"keypoints original second iter\", [keypoints_original[0][o_idx][k_idx]],\n",
    "#                           [keypoints_original[o_idx][k_idx][0]], [keypoints_original[o_idx][k_idx][1]], \\\n",
    "#                          [keypoints_original[o_idx][k_idx][2]], [keypoints_original[o_idx][k_idx][3]])\n",
    "                    # kp - coordinates of keypoint\n",
    "                    # keypoints_original[o_idx][k_idx][2] - original visibility of keypoint\n",
    "                    obj_keypoints.append(kp + [keypoints_original[o_idx][k_idx][2]])\n",
    "                keypoints.append(obj_keypoints)\n",
    "#             print(keypoints)\n",
    "        \n",
    "        else:\n",
    "            img, bboxes, keypoints = img_original, bboxes_original, keypoints_original        \n",
    "        \n",
    "        # Convert everything into a torch tensor        \n",
    "        bboxes = torch.as_tensor(bboxes, dtype=torch.float32)       \n",
    "        target = {}\n",
    "#         labels = [1, 2, 3]\n",
    "        labels = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "#         labels = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "#         labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]            \n",
    "        target[\"boxes\"] = bboxes\n",
    "        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64) # all objects are joint positions\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "        target[\"area\"] = (bboxes[:, 3] - bboxes[:, 1]) * (bboxes[:, 2] - bboxes[:, 0])\n",
    "        target[\"iscrowd\"] = torch.zeros(len(bboxes), dtype=torch.int64)\n",
    "        target[\"keypoints\"] = torch.as_tensor(keypoints, dtype=torch.float32)\n",
    "        img = F.to_tensor(img)        \n",
    "        bboxes_original = torch.as_tensor(bboxes_original, dtype=torch.float32)\n",
    "        target_original = {}\n",
    "        target_original[\"boxes\"] = bboxes_original\n",
    "        target_original[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64) \n",
    "        target_original[\"image_id\"] = torch.tensor([idx])\n",
    "        target_original[\"area\"] = (bboxes_original[:, 3] - bboxes_original[:, 1]) * (bboxes_original[:, 2] - bboxes_original[:, 0])\n",
    "        target_original[\"iscrowd\"] = torch.zeros(len(bboxes_original), dtype=torch.int64)\n",
    "        target_original[\"keypoints\"] = torch.as_tensor(keypoints_original, dtype=torch.float32)        \n",
    "        img_original = F.to_tensor(img_original)\n",
    "\n",
    "        if self.demo:\n",
    "            return img, target, img_original, target_original\n",
    "        else:\n",
    "            return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs_files)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6bc2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYPOINTS_FOLDER_TRAIN = train_test_split(root_dir) +\"/test\" \n",
    "dataset = ClassDataset(KEYPOINTS_FOLDER_TRAIN, transform=train_transform(), demo=True)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "iterator = iter(data_loader)\n",
    "batch = next(iterator)\n",
    "# print(batch[2])\n",
    "\n",
    "# print(\"Original targets:\\n\", batch[3], \"\\n\\n\")\n",
    "# print(\"Transformed targets:\\n\", batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaeafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to visualize how the transformed data looks \n",
    "\n",
    "keypoints_classes_ids2names = {0: 'base_joint', 1: 'joint2', 2: 'joint3', 3: 'joint4', 4: 'joint5', 5: 'joint6',\\\n",
    "                              6:'joint7', 7:'joint8', 8:'panda_finger_1', 9:'panda_finger_2'}\n",
    "\n",
    "def visualize(image, bboxes, keypoints, image_original=None, bboxes_original=None, keypoints_original=None):\n",
    "    fontsize = 18\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        start_point = (bbox[0], bbox[1])\n",
    "        end_point = (bbox[2], bbox[3])\n",
    "        image = cv2.rectangle(image.copy(), start_point, end_point, (0,255,0), 2)\n",
    "    \n",
    "    for idx, kps in enumerate(keypoints):\n",
    "        for kp in kps:\n",
    "            image = cv2.circle(image.copy(), tuple(kp), 2, (255,0,0), 10)\n",
    "#         image = cv2.putText(image.copy(), \" \" + keypoints_classes_ids2names[idx], tuple(kp), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "    if image_original is None and keypoints_original is None:\n",
    "        plt.figure(figsize=(40,40))\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    else:\n",
    "        for bbox in bboxes_original:\n",
    "            start_point = (bbox[0], bbox[1])\n",
    "            end_point = (bbox[2], bbox[3])\n",
    "            image_original = cv2.rectangle(image_original.copy(), start_point, end_point, (0,255,0), 2)\n",
    "        \n",
    "        print(keypoints_original)\n",
    "        for idx, kps in enumerate(keypoints_original):\n",
    "            print(idx)\n",
    "            print(kps)\n",
    "            for kp in kps:\n",
    "                print(kp)\n",
    "                image_original = cv2.circle(image_original, tuple(kp), 5, (255,0,0), 2)\n",
    "#             image_original = cv2.putText(image_original, \" \" + keypoints_classes_ids2names[idx], tuple(kp), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "        f, ax = plt.subplots(1, 2, figsize=(40, 20))\n",
    "\n",
    "        ax[0].imshow(image_original)\n",
    "        ax[0].set_title('Original image', fontsize=fontsize)\n",
    "\n",
    "        ax[1].imshow(image)\n",
    "        ax[1].set_title('Transformed image', fontsize=fontsize)\n",
    "        \n",
    "        return None\n",
    "        \n",
    "image = (batch[0][0].permute(1,2,0).numpy() * 255).astype(np.uint8)\n",
    "bboxes = batch[1][0]['boxes'].detach().cpu().numpy().astype(np.int32).tolist()\n",
    "\n",
    "keypoints = []\n",
    "# for kps in batch1[1][0]['keypoints'].detach().cpu().numpy().astype(np.int32).tolist():\n",
    "#     keypoints.append([kp[:2] for kp in [kps]])\n",
    "    \n",
    "for kps in batch[1][0]['keypoints'].detach().cpu().numpy().astype(np.int32).tolist():\n",
    "    keypoints.append([kp[:2] for kp in kps])\n",
    "\n",
    "image_original = (batch[2][0].permute(1,2,0).numpy() * 255).astype(np.uint8)\n",
    "bboxes_original = batch[3][0]['boxes'].detach().cpu().numpy().astype(np.int32).tolist()\n",
    "\n",
    "keypoints_original = []\n",
    "# for kps in batch1[3][0]['keypoints'].detach().cpu().numpy().astype(np.int32).tolist():\n",
    "#     keypoints_original.append([kp[:2] for kp in [kps]])\n",
    "    \n",
    "for kps in batch[3][0]['keypoints'].detach().cpu().numpy().astype(np.int32).tolist():\n",
    "    keypoints_original.append([kp[:2] for kp in kps])\n",
    "\n",
    "visualize(image, bboxes, keypoints, image_original, bboxes_original, keypoints_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_keypoints, weights_path=None):\n",
    "    \n",
    "    anchor_generator = AnchorGenerator(sizes=(32, 64, 128, 256, 512), aspect_ratios=(0.25, 0.5, 0.75, 1.0, 2.0, 3.0, 4.0))\n",
    "    model = torchvision.models.detection.keypointrcnn_resnet50_fpn(weights=False,\n",
    "                                                                   weights_backbone=True,\n",
    "                                                                   num_keypoints=num_keypoints,\n",
    "                                                                   num_classes = 8, # Background is the first class, object is the second class\n",
    "                                                                   rpn_anchor_generator=anchor_generator)\n",
    "\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        model.load_state_dict(state_dict)        \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc8ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_keypoints = 9\n",
    "model = get_model(num_keypoints, weights_path=None)\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf76c17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_keypoints = 9\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "split_folder_path = train_test_split(root_dir)\n",
    "\n",
    "KEYPOINTS_FOLDER_TRAIN = split_folder_path +\"/train\" #train_test_split(root_dir) +\"/train\"\n",
    "KEYPOINTS_FOLDER_VAL = split_folder_path +\"/val\"\n",
    "KEYPOINTS_FOLDER_TEST = split_folder_path +\"/test\"\n",
    "\n",
    "dataset_train = ClassDataset(KEYPOINTS_FOLDER_TRAIN, transform=train_transform(), demo=False)\n",
    "# dataset_train = ClassDataset(KEYPOINTS_FOLDER_TRAIN, transform=None, demo=False)\n",
    "dataset_val = ClassDataset(KEYPOINTS_FOLDER_VAL, transform=None, demo=False)\n",
    "dataset_test = ClassDataset(KEYPOINTS_FOLDER_TEST, transform=None, demo=False)\n",
    "\n",
    "# batch_sizes = [3,2]\n",
    "# epochs_lst = [30,50,100]\n",
    "\n",
    "# batch_sizes = [3, 2, 1]\n",
    "# epochs_lst = [25, 30]\n",
    "batch_sizes = [1]\n",
    "epochs_lst = [25, 30]\n",
    "\n",
    "v = 2\n",
    "\n",
    "for b_size in batch_sizes:\n",
    "    for epochs in epochs_lst:\n",
    "        data_loader_train = DataLoader(dataset_train, batch_size=b_size, shuffle=True, collate_fn=collate_fn)\n",
    "        data_loader_val = DataLoader(dataset_val, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "        data_loader_test = DataLoader(dataset_test, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "        model = get_model(num_keypoints = total_keypoints)\n",
    "        model.to(device)\n",
    "\n",
    "        params = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.3)\n",
    "        num_epochs = epochs\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            train_one_epoch(model, optimizer, data_loader_train, device, epoch, print_freq=1000)\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "#             if epoch == 25 or epoch == 30 :\n",
    "#                 PATH = f\"/home/jc-merlab/Pictures/Data/trained_models/keypointsrcnn_weights_ld_b{b_size}_e{epoch}_v{v}.pth\"        \n",
    "#                 torch.save(model, PATH)\n",
    "#                 v+=1 \n",
    "            \n",
    "        \n",
    "        PATH = f\"/home/jc-merlab/Pictures/Data/trained_models/kprcnn_plan_b{b_size}_e{epochs}_v{v}_sim.pth\"\n",
    "            \n",
    "            \n",
    "        torch.save(model, PATH)\n",
    "        \n",
    "           \n",
    "        \n",
    "\n",
    "\n",
    "#     evaluate(model, data_loader_val, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights after training\n",
    "# torch.save(model.state_dict(), 'keypointsrcnn_weights_120.pth')\n",
    "# torch.save(model, '/home/jc-merlab/Pictures/Data/trained_models/keypointsrcnn_weights_ld_b1_e30_v3.pth')\n",
    "            \n",
    "# torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e5f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYPOINTS_FOLDER_VAL = parent_path + \"split_folder_output-2023-07-14\" +\"/val\"\n",
    "dataset_val = ClassDataset(KEYPOINTS_FOLDER_VAL, transform=None, demo=False)\n",
    "data_loader_val = DataLoader(dataset_val, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "iterator = iter(data_loader_val)\n",
    "len(data_loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, data_loader_val, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fad317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_path = '/home/user/Workspace/WPI/Summer2023/ws/duc_repo/src/panda_test/data/trained_models/keypointsrcnn_weights_ld_b1_e25_v9.pth'\n",
    "weights_path = PATH\n",
    "model = torch.load(weights_path).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = iter(data_loader_val)\n",
    "i = 1\n",
    "while True:\n",
    "    try:\n",
    "        images, targets = next(data_iterator)\n",
    "        images = list(img.to(device) for img in images)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            images = (images[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "            scores = outputs[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "            high_scores_idxs = np.where(scores > 0.7)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "            post_nms_idxs = torchvision.ops.nms(outputs[0]['boxes'][high_scores_idxs], outputs[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "            keypoints = []\n",
    "            for kps in outputs[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "                keypoints.append([list(map(int, kp[:2])) for kp in kps])\n",
    "\n",
    "            bboxes = []\n",
    "            for bbox in outputs[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "                bboxes.append(list(map(int, bbox.tolist())))\n",
    "            img = visualize(images, bboxes, keypoints)\n",
    "#             cv2.imwrite(\"/home/jc-merlab/Pictures/Data/video_results_01/out_image_\" + str(i) + \".jpg\", img)\n",
    "            cv2.imshow(f'image{i}', img)\n",
    "\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyWindow(f'image{i}')\n",
    "\n",
    "            \n",
    "            i = i+1\n",
    "\n",
    "            # Calculate loss and metrics for evaluation here.\n",
    "    except StopIteration:\n",
    "        break         \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '/home/user/Workspace/WPI/Summer2023/ws/duc_repo/src/panda_test/data/trained_models/keypointsrcnn_weights_ld_b1_e25_v1.pth'\n",
    "model = torch.load(weights_path).to(device)\n",
    "\n",
    "images1, targets1 = next(iterator)\n",
    "images2, targets2 = next(iterator)\n",
    "images3, targets3 = next(iterator)\n",
    "images4, targets4 = next(iterator)\n",
    "# images, targets = next(iterator)\n",
    "\n",
    "print(type(images1))\n",
    "\n",
    "\n",
    "images1 = list(image1.to(device) for image1 in images1)\n",
    "images2 = list(image2.to(device) for image2 in images2)\n",
    "images3 = list(image3.to(device) for image3 in images3)\n",
    "images4 = list(image4.to(device) for image4 in images4)\n",
    "# images = list(image.to(device) for image in images)\n",
    "\n",
    "print(type(images1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    output1 = model(images1)\n",
    "    output2 = model(images2)\n",
    "    output3 = model(images3)\n",
    "    output4 = model(images4)\n",
    "#     output = model(image)\n",
    "\n",
    "# print(\"Predictions: \\n\", output1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2300e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions: \\n\", output1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca000731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, targets) in enumerate(data_loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e9a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "weights_path = '/home/jc-merlab/Pictures/Data/trained_models/keypointsrcnn_weights_ld_b1_e25_v2.pth'\n",
    "model = torch.load(weights_path).to(device)\n",
    "# model = get_model(num_keypoints=6, weights_path=weights_path)\n",
    "# model.load_state_dict(torch.load('keypointsrcnn_weights.pth'))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# print(type(model))\n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture('/home/jc-merlab/Pictures/Data/inference_data/test_video_3d.avi')\n",
    " \n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "i = 0\n",
    "print(type(i))\n",
    "while(cap.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "    print(i)\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:        \n",
    "#         img = cv2.imread(frame)\n",
    "        image = Image.fromarray(frame)\n",
    "\n",
    "        image = F.to_tensor(image).to(device)\n",
    "        image.unsqueeze_(0)\n",
    "        image = list(image)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            start = time.time(now)\n",
    "            output = model(image)\n",
    "            stop = time.time(now)\n",
    "            print(\"time\", (stop - start))\n",
    "\n",
    "        image = (image[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "        scores = output[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "        high_scores_idxs = np.where(scores > 0.7)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "        post_nms_idxs = torchvision.ops.nms(output[0]['boxes'][high_scores_idxs], output[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "\n",
    "        # Below, in output[0]['keypoints'][high_scores_idxs][post_nms_idxs] and output[0]['boxes'][high_scores_idxs][post_nms_idxs]\n",
    "        # Firstly, we choose only those objects, which have score above predefined threshold. This is done with choosing elements with [high_scores_idxs] indexes\n",
    "        # Secondly, we choose only those objects, which are left after NMS is applied. This is done with choosing elements with [post_nms_idxs] indexes\n",
    "\n",
    "        keypoints = []\n",
    "        for kps in output[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            keypoints.append([list(map(int, kp[:2])) for kp in kps])\n",
    "\n",
    "        bboxes = []\n",
    "        for bbox in output[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            bboxes.append(list(map(int, bbox.tolist())))\n",
    "        img = visualize(image, bboxes, keypoints)\n",
    "        \n",
    "        cv2.imwrite(\"/home/jc-merlab/Pictures/Data/video_results_01/out_image_\" + str(i) + \".jpg\", img)\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "    i = i+1\n",
    "    \n",
    "cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc57ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = (images1[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "scores1 = output1[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "high_scores_idxs = np.where(scores1 > 0.7)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "post_nms_idxs = torchvision.ops.nms(output1[0]['boxes'][high_scores_idxs], output1[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "\n",
    "# Below, in output[0]['keypoints'][high_scores_idxs][post_nms_idxs] and output[0]['boxes'][high_scores_idxs][post_nms_idxs]\n",
    "# Firstly, we choose only those objects, which have score above predefined threshold. This is done with choosing elements with [high_scores_idxs] indexes\n",
    "# Secondly, we choose only those objects, which are left after NMS is applied. This is done with choosing elements with [post_nms_idxs] indexes\n",
    "\n",
    "keypoints = []\n",
    "for kps in output1[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "    keypoints.append([list(map(int, kp[:2])) for kp in kps])\n",
    "    \n",
    "print(keypoints)\n",
    "\n",
    "bboxes = []\n",
    "for bbox in output1[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "    bboxes.append(list(map(int, bbox.tolist())))\n",
    "    \n",
    "image = visualize(image1, bboxes, keypoints)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b19363",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = (images2[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "scores = output2[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "high_scores_idxs = np.where(scores > 0.7)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "post_nms_idxs = torchvision.ops.nms(output2[0]['boxes'][high_scores_idxs], output2[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "\n",
    "# Below, in output[0]['keypoints'][high_scores_idxs][post_nms_idxs] and output[0]['boxes'][high_scores_idxs][post_nms_idxs]\n",
    "# Firstly, we choose only those objects, which have score above predefined threshold. This is done with choosing elements with [high_scores_idxs] indexes\n",
    "# Secondly, we choose only those objects, which are left after NMS is applied. This is done with choosing elements with [post_nms_idxs] indexes\n",
    "\n",
    "keypoints = []\n",
    "for kps in output2[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "    keypoints.append([list(map(int, kp[:2])) for kp in kps])\n",
    "\n",
    "bboxes = []\n",
    "for bbox in output2[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "    bboxes.append(list(map(int, bbox.tolist())))\n",
    "    \n",
    "visualize(image2, bboxes, keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e88f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image3 = (images3[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "scores3 = output3[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "high_scores_idxs = np.where(scores > 0.7)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "post_nms_idxs = torchvision.ops.nms(output3[0]['boxes'][high_scores_idxs], output3[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "\n",
    "# Below, in output[0]['keypoints'][high_scores_idxs][post_nms_idxs] and output[0]['boxes'][high_scores_idxs][post_nms_idxs]\n",
    "# Firstly, we choose only those objects, which have score above predefined threshold. This is done with choosing elements with [high_scores_idxs] indexes\n",
    "# Secondly, we choose only those objects, which are left after NMS is applied. This is done with choosing elements with [post_nms_idxs] indexes\n",
    "\n",
    "keypoints = []\n",
    "for kps in output3[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "    keypoints.append([list(map(int, kp[:2])) for kp in kps])\n",
    "\n",
    "bboxes = []\n",
    "for bbox in output3[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "    bboxes.append(list(map(int, bbox.tolist())))\n",
    "    \n",
    "visualize(image3, bboxes, keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52be56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image4 = (images4[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "scores4 = output4[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "high_scores_idxs = np.where(scores > 0.7)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "post_nms_idxs = torchvision.ops.nms(output4[0]['boxes'][high_scores_idxs], output4[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "\n",
    "# Below, in output[0]['keypoints'][high_scores_idxs][post_nms_idxs] and output[0]['boxes'][high_scores_idxs][post_nms_idxs]\n",
    "# Firstly, we choose only those objects, which have score above predefined threshold. This is done with choosing elements with [high_scores_idxs] indexes\n",
    "# Secondly, we choose only those objects, which are left after NMS is applied. This is done with choosing elements with [post_nms_idxs] indexes\n",
    "\n",
    "keypoints = []\n",
    "for kps in output4[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "    keypoints.append([list(map(int, kp[:2])) for kp in kps])\n",
    "\n",
    "bboxes = []\n",
    "for bbox in output4[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "    bboxes.append(list(map(int, bbox.tolist())))\n",
    "    \n",
    "visualize(image4, bboxes, keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"/home/jc-merlab/428.jpg\")\n",
    "print(type(image))\n",
    "\n",
    "image = F.to_tensor(image).to(device)\n",
    "image.unsqueeze_(0)\n",
    "print(image.shape)\n",
    "image = list(image)\n",
    "# print(type(images))\n",
    "# images = list(image.to(device) for image in images)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    output = model(image)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c0113",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = (image[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "scores = output[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "high_scores_idxs = np.where(scores > 0.7)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "post_nms_idxs = torchvision.ops.nms(output[0]['boxes'][high_scores_idxs], output[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "\n",
    "# Below, in output[0]['keypoints'][high_scores_idxs][post_nms_idxs] and output[0]['boxes'][high_scores_idxs][post_nms_idxs]\n",
    "# Firstly, we choose only those objects, which have score above predefined threshold. This is done with choosing elements with [high_scores_idxs] indexes\n",
    "# Secondly, we choose only those objects, which are left after NMS is applied. This is done with choosing elements with [post_nms_idxs] indexes\n",
    "\n",
    "keypoints = []\n",
    "for kps in output[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "    keypoints.append(list(map(int, kps[0,0:2])))\n",
    "#     keypoints.append([list(map(int, kp[:2])) for kp in kps])\n",
    "keypoints_ = [x for _,x in sorted(zip(labels,keypoints))]\n",
    "\n",
    "bboxes = []\n",
    "for bbox in output[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "    bboxes.append(list(map(int, bbox.tolist())))\n",
    "    \n",
    "visualize(image, bboxes, keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077377c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "weights_path = 'keypointsrcnn_weights.pth'\n",
    "model = get_model(num_keypoints=6, weights_path=weights_path)\n",
    "model.load_state_dict(torch.load('keypointsrcnn_weights.pth'))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# print(type(model))\n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture('/home/jc-merlab/nov1_v1.avi')\n",
    " \n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "i = 0\n",
    "print(type(i))\n",
    "while(cap.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "    print(i)\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:        \n",
    "#         img = cv2.imread(frame)\n",
    "        image = Image.fromarray(frame)\n",
    "\n",
    "        image = F.to_tensor(image).to(device)\n",
    "        image.unsqueeze_(0)\n",
    "        image = list(image)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            output = model(image)\n",
    "\n",
    "        image = (image[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "        scores = output[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "        high_scores_idxs = np.where(scores > 0.7)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "        post_nms_idxs = torchvision.ops.nms(output[0]['boxes'][high_scores_idxs], output[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "\n",
    "        # Below, in output[0]['keypoints'][high_scores_idxs][post_nms_idxs] and output[0]['boxes'][high_scores_idxs][post_nms_idxs]\n",
    "        # Firstly, we choose only those objects, which have score above predefined threshold. This is done with choosing elements with [high_scores_idxs] indexes\n",
    "        # Secondly, we choose only those objects, which are left after NMS is applied. This is done with choosing elements with [post_nms_idxs] indexes\n",
    "\n",
    "        keypoints = []\n",
    "        for kps in output[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            keypoints.append([list(map(int, kp[:2])) for kp in kps])\n",
    "\n",
    "        bboxes = []\n",
    "        for bbox in output[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            bboxes.append(list(map(int, bbox.tolist())))\n",
    "        img = visualize(image, bboxes, keypoints)\n",
    "        \n",
    "        cv2.imwrite(\"/home/jc-merlab/Pictures/Data/video_results/out_image_\" + str(i) + \".jpg\", img)\n",
    "        \n",
    "    i = i+1\n",
    "    \n",
    "cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99134e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import moviepy.video.io.ImageSequenceClip\n",
    "image_folder=\"/home/jc-merlab/Pictures/Data/video_results/\"\n",
    "\n",
    "fps=1\n",
    "\n",
    "image_files = [os.path.join(image_folder,img)\n",
    "               for img in os.listdir(image_folder)\n",
    "               if img.endswith(\".jpg\")]\n",
    "clip = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(image_files, fps=fps)\n",
    "clip.write_videofile('my_video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4af23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "2500//72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1070c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "weights_path = '/home/jc-merlab/Pictures/Data/trained_models/keypointsrcnn_weights_ld_b1_e25_v2.pth'\n",
    "model = torch.load(weights_path).to(device)\n",
    "# model = get_model(num_keypoints=6, weights_path=weights_path)\n",
    "# model.load_state_dict(torch.load('keypointsrcnn_weights.pth'))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# print(type(model))\n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture('/home/jc-merlab/Pictures/Data/inference_data/test_video_3d.avi')\n",
    " \n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "i = 0\n",
    "print(type(i))\n",
    "while(cap.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "    print(i)\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:        \n",
    "#         img = cv2.imread(frame)\n",
    "        image = Image.fromarray(frame)\n",
    "\n",
    "        image = F.to_tensor(image).to(device)\n",
    "        image.unsqueeze_(0)\n",
    "        image = list(image)\n",
    "        \n",
    "    \n",
    "        with torch.no_grad():\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            start = time.time(now)\n",
    "            output = model(image)\n",
    "            stop = time.time(now)\n",
    "            print(\"time\", (stop - start))\n",
    "\n",
    "        image = (image[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "        scores = output[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "        high_scores_idxs = np.where(scores > 0.7)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "        post_nms_idxs = torchvision.ops.nms(output[0]['boxes'][high_scores_idxs], output[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "\n",
    "        # Below, in output[0]['keypoints'][high_scores_idxs][post_nms_idxs] and output[0]['boxes'][high_scores_idxs][post_nms_idxs]\n",
    "        # Firstly, we choose only those objects, which have score above predefined threshold. This is done with choosing elements with [high_scores_idxs] indexes\n",
    "        # Secondly, we choose only those objects, which are left after NMS is applied. This is done with choosing elements with [post_nms_idxs] indexes\n",
    "\n",
    "        keypoints = []\n",
    "        for kps in output[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            keypoints.append([list(map(int, kp[:2])) for kp in kps])\n",
    "\n",
    "        bboxes = []\n",
    "        for bbox in output[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            bboxes.append(list(map(int, bbox.tolist())))\n",
    "        img = visualize(image, bboxes, keypoints)\n",
    "        \n",
    "        labels = []\n",
    "        for label in output[0]['labels'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            labels.append(label)\n",
    "        keypoints_ = [x for _,x in sorted(zip(labels,keypoints))]\n",
    "        \n",
    "        \n",
    "        cv2.imwrite(\"/home/jc-merlab/Pictures/Data/video_results_01/out_image_\" + str(i) + \".jpg\", img)\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "    i = i+1\n",
    "    \n",
    "cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dfffb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import torch, torchvision\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "import shutil\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "weights_path = '/home/jc-merlab/Pictures/Data/trained_models/keypointsrcnn_weights_sim_b1_e25_v0.pth'\n",
    "model = torch.load(weights_path).to(device)\n",
    "# model = get_model(num_keypoints=6, weights_path=weights_path)\n",
    "# model.load_state_dict(torch.load('keypointsrcnn_weights.pth'))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Specify input and output folders\n",
    "input_folder = '/home/jc-merlab/Pictures/Data/occ_sim_append/'\n",
    "output_frames_folder = '/home/jc-merlab/Pictures/Data/occ_sim_append_op/'\n",
    "# output_json_folder = '/home/jc-merlab/Pictures/Data/keypoint_jsons'\n",
    "\n",
    "# Check if output folders exist, create them if not\n",
    "os.makedirs(output_frames_folder, exist_ok=True)\n",
    "# os.makedirs(output_json_folder, exist_ok=True)\n",
    "\n",
    "# Process images in the folder\n",
    "i = 0\n",
    "for filename in sorted(os.listdir(input_folder)):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)  \n",
    "\n",
    "        image = F.to_tensor(image).to(device)\n",
    "        image.unsqueeze_(0)\n",
    "        image = list(image)\n",
    "        # print(type(images))\n",
    "        # images = list(image.to(device) for image in images)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            output = model(image)\n",
    "            image = (image[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "        scores = output[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "        high_scores_idxs = np.where(scores > 0.7)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "        post_nms_idxs = torchvision.ops.nms(output[0]['boxes'][high_scores_idxs], output[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "\n",
    "        keypoints = []\n",
    "        for kps in output[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            keypoints.append(list(map(int, kps[0,0:2])))\n",
    "            \n",
    "        bboxes = []\n",
    "        for bbox in output[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            bboxes.append(list(map(int, bbox.tolist())))\n",
    "       \n",
    "        labels = []\n",
    "        for label in output[0]['labels'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            labels.append(label)\n",
    "            \n",
    "        keypoints_ = [x for _,x in sorted(zip(labels,keypoints))]\n",
    "        print(keypoints_)\n",
    "        bbox_ = [x for _,x in sorted(zip(labels,bboxes))]\n",
    "        print(bbox_[3])\n",
    "        \n",
    "        # Modify the 4th keypoint as per the requirement\n",
    "#         if len(keypoints_) >= 4 and len(bbox_) >= 4:\n",
    "#             fourth_bbox = bbox_[3]\n",
    "#             # Replace 4th keypoint with the top-left corner of the 4th bounding box\n",
    "#             keypoints_[3] = [fourth_bbox[0], fourth_bbox[1]]\n",
    "#             # Append the bottom-right corner of the 4th bounding box as a new keypoint\n",
    "#             keypoints_.append([fourth_bbox[2], fourth_bbox[3]])\n",
    "            \n",
    "        print(keypoints_)\n",
    "\n",
    "        # Generate JSON data\n",
    "        image_filename_base = os.path.splitext(filename)[0]  # Remove '.jpg' extension\n",
    "        json_data = {\n",
    "            \"id\": i,\n",
    "            \"image_rgb\": filename,  \n",
    "            \"keypoints\": [[kp] for kp in keypoints_]\n",
    "        }\n",
    "\n",
    "        # Copy image to output folder\n",
    "        output_image_path = os.path.join(output_frames_folder, filename)\n",
    "        shutil.copyfile(image_path, output_image_path)\n",
    "\n",
    "        # Save JSON with matching filename\n",
    "        output_json_path = os.path.join(output_frames_folder, f\"{image_filename_base}.json\") \n",
    "        with open(output_json_path, 'w') as f:\n",
    "            json.dump(json_data, f)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d6385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76a113ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Accuracy for 012986.jpg: 0.0%\n",
      "Invisible Keypoint Accuracy for 012986.jpg: 0.0%\n",
      "Overall accuracy: 0.0%\n",
      "Overall invisible keypoint accuracy: 0.0%\n",
      "Total number of invisible keypoints: 3\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import json\n",
    "import shutil\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "weights_path = '/home/jc-merlab/Pictures/Data/trained_models/keypointsrcnn_planning_b1_e50_v8.pth'\n",
    "model = torch.load(weights_path).to(device)\n",
    "# model = get_model(num_keypoints=6, weights_path=weights_path)\n",
    "# model.load_state_dict(torch.load('keypointsrcnn_weights.pth'))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Assuming the necessary imports are done\n",
    "# Assuming the model is loaded and device is set as in your initial code\n",
    "\n",
    "# Specify input and output folders\n",
    "input_folder = '/home/jc-merlab/Pictures/ip_test_folder'\n",
    "output_frames_folder = '/home/jc-merlab/Pictures/Data/'\n",
    "\n",
    "# Check if output folders exist, create them if not\n",
    "os.makedirs(output_frames_folder, exist_ok=True)\n",
    "\n",
    "def load_ground_truth(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    # ground_truth_keypoints = [[int(kp[0][0]), int(kp[0][1])] for kp in data['keypoints']]\n",
    "    ground_truth_keypoints = [[int(kp[0][0]), int(kp[0][1]), kp[0][2]] for kp in data['keypoints']]\n",
    "    return ground_truth_keypoints\n",
    "\n",
    "def calculate_accuracy(predicted_keypoints, ground_truth_keypoints, margin=10):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of predicted keypoints within a margin of 10 pixels.\n",
    "    Also calculate accuracy for invisible keypoints within a margin of 5 pixels.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = len(ground_truth_keypoints)\n",
    "    \n",
    "    correct_invisible = 0\n",
    "    total_invisible = 0\n",
    "\n",
    "    for pred_kp, gt_kp in zip(predicted_keypoints, ground_truth_keypoints):\n",
    "        pred_kp = pred_kp.cpu().numpy()  # Move tensor to CPU and convert to NumPy array\n",
    "        dist = np.linalg.norm(np.array(pred_kp[:2]) - np.array(gt_kp[:2]))  # Use only x, y for distance calculation\n",
    "#         print(\"GT Keypoints\", gt_kp)\n",
    "        if gt_kp[2] == 0:  # Invisible keypoint\n",
    "            total_invisible += 1\n",
    "            if dist <= margin:  # Margin for invisible keypoints\n",
    "                correct_invisible += 1\n",
    "        else:  # Visible keypoint\n",
    "            if dist <= margin:\n",
    "                correct += 1\n",
    "    \n",
    "    correct_total = correct + correct_invisible\n",
    "    accuracy = (correct_total / total) * 100\n",
    "    invisible_accuracy = (correct_invisible / total_invisible) * 100 if total_invisible > 0 else 0\n",
    "    return accuracy, invisible_accuracy, total_invisible\n",
    "\n",
    "# Process images in the folder\n",
    "accuracies = []\n",
    "invisible_accuracies = []\n",
    "total_invisible_keypoints = 0\n",
    "total_inference_time = []\n",
    "i = 0\n",
    "for filename in sorted(os.listdir(input_folder)):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        tensor_image = F.to_tensor(image).to(device)\n",
    "        tensor_image.unsqueeze_(0)\n",
    "        tensor_image = list(tensor_image)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(tensor_image)\n",
    "            tensor_image = (tensor_image[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "        \n",
    "        scores = output[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "        high_scores_idxs = np.where(scores > 0.01)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "        post_nms_idxs = torchvision.ops.nms(output[0]['boxes'][high_scores_idxs], output[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "        confidence = output[0]['scores'][high_scores_idxs].detach().cpu().numpy()\n",
    "\n",
    "#         keypoints = []\n",
    "#         for kps in output[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "#             keypoints.append(list(map(int, kps[0,0:2])))\n",
    "            \n",
    "\n",
    "            \n",
    "#         bboxes = []\n",
    "#         for bbox in output[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "#             bboxes.append(list(map(int, bbox.tolist())))\n",
    "            \n",
    "        bboxes = []\n",
    "        for bbox in output[0]['boxes'][high_scores_idxs].detach().cpu().numpy():\n",
    "            bboxes.append(list(map(int, bbox.tolist())))\n",
    "       \n",
    "#         labels = []\n",
    "#         for label in output[0]['labels'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "#             labels.append(label)\n",
    "            \n",
    "        labels = []\n",
    "        for label in output[0]['labels'][high_scores_idxs].detach().cpu().numpy():\n",
    "            labels.append(label)\n",
    "            \n",
    "        keypoints = []\n",
    "        for idx, kps in enumerate(output[0]['keypoints'][high_scores_idxs].detach().cpu().numpy()):\n",
    "            keypoints.append(list(map(int, kps[0, 0:2])) + [confidence[idx]] + [labels[idx]])\n",
    "            \n",
    "        keypoints = [torch.tensor(kp, dtype=torch.float32).to(device) if not isinstance(kp, torch.Tensor) else kp for kp in keypoints]\n",
    "        keypoints = torch.stack(keypoints).to(device)\n",
    "        \n",
    "        unique_labels, best_keypoint_indices = torch.unique(keypoints[:, 3], return_inverse=True)\n",
    "        best_scores, best_indices = torch.max(keypoints[:, 2].unsqueeze(0) * (best_keypoint_indices == torch.arange(len(unique_labels)).unsqueeze(1).cuda()), dim=1)\n",
    "        keypoints = keypoints[best_indices]\n",
    "            \n",
    "#         keypoints_ = [x for _,x in sorted(zip(labels,keypoints))]\n",
    "        # Load ground truth keypoints\n",
    "        json_filename = filename.split('.')[0] + '.json'  # Construct JSON filename\n",
    "        json_path = os.path.join(input_folder, json_filename)\n",
    "        ground_truth_keypoints = load_ground_truth(json_path) \n",
    "        \n",
    "#         print(keypoints)\n",
    "\n",
    "        # Visualize keypoints on the image\n",
    "        for point in keypoints:\n",
    "            x,y, c, l = point\n",
    "            cv2.circle(image, (int(x), int(y)), 12, (255, 0, 0), -1)  # Draws a blue circle on each keypoint\n",
    "            \n",
    "        # Ground truth keypoints in red\n",
    "        for x, y, _ in ground_truth_keypoints:\n",
    "            cv2.circle(image, (x, y), radius=8, color=(0, 255, 255), thickness=-1)\n",
    "\n",
    "        # Save the modified image to the output folder\n",
    "        output_image_path = os.path.join(output_frames_folder, filename)\n",
    "        cv2.imwrite(output_image_path, image)\n",
    "        \n",
    "        # Calculate and store accuracy\n",
    "        accuracy, invisible_accuracy, num_invisible = calculate_accuracy(keypoints, ground_truth_keypoints, margin=10)\n",
    "        accuracies.append(accuracy)\n",
    "        invisible_accuracies.append(invisible_accuracy)\n",
    "#         total_inference_time.append(inference_time)\n",
    "        total_invisible_keypoints += num_invisible\n",
    "        print(f\"Accuracy for {filename}: {accuracy}%\")\n",
    "        print(f\"Invisible Keypoint Accuracy for {filename}: {invisible_accuracy}%\")\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "# Print overall accuracy\n",
    "overall_accuracy = np.mean(accuracies)\n",
    "overall_invisible_accuracy = np.mean(invisible_accuracies)\n",
    "avg_inference_time = np.mean(total_inference_time)\n",
    "print(f\"Overall accuracy: {overall_accuracy}%\")\n",
    "print(f\"Overall invisible keypoint accuracy: {overall_invisible_accuracy}%\")\n",
    "print(f\"Total number of invisible keypoints: {total_invisible_keypoints}\")\n",
    "# print(f\"Average inference time: {avg_inference_time}\")\n",
    "\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import json\n",
    "import shutil\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# weights_path = '/home/jc-merlab/Pictures/Data/lama_kp_trained_models/trained_models/keypointsrcnn_lama_b4_e25_v1.pth'\n",
    "weights_path = '/home/jc-merlab/Pictures/Data/trained_models/keypointsrcnn_planning_b1_e50_v8.pth'\n",
    "\n",
    "model = torch.load(weights_path).to(device)\n",
    "# model = get_model(num_keypoints=6, weights_path=weights_path)\n",
    "# model.load_state_dict(torch.load('keypointsrcnn_weights.pth'))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Assuming the necessary imports are done\n",
    "# Assuming the model is loaded and device is set as in your initial code\n",
    "\n",
    "# Specify input and output folders\n",
    "input_folder = '/home/jc-merlab/Pictures/Test_Data/occ_vids/exp_01/gt/'\n",
    "output_frames_folder = '/home/jc-merlab/Pictures/Data/occ_phys_test_data/prediction_with_line/'\n",
    "\n",
    "# Check if output folders exist, create them if not\n",
    "os.makedirs(output_frames_folder, exist_ok=True)\n",
    "\n",
    "def load_ground_truth(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    # ground_truth_keypoints = [[int(kp[0][0]), int(kp[0][1])] for kp in data['keypoints']]\n",
    "    ground_truth_keypoints = [[int(kp[0][0]), int(kp[0][1]), kp[0][2]] for kp in data['keypoints']]\n",
    "    return ground_truth_keypoints\n",
    "\n",
    "def calculate_accuracy(predicted_keypoints, ground_truth_keypoints, margin=10):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of predicted keypoints within a margin of 10 pixels.\n",
    "    Also calculate accuracy for invisible keypoints within a margin of 5 pixels.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = len(ground_truth_keypoints)\n",
    "    \n",
    "    correct_invisible = 0\n",
    "    total_invisible = 0\n",
    "\n",
    "    for pred_kp, gt_kp in zip(predicted_keypoints, ground_truth_keypoints):\n",
    "        pred_kp = pred_kp.cpu().numpy()  # Move tensor to CPU and convert to NumPy array\n",
    "        dist = np.linalg.norm(np.array(pred_kp[:2]) - np.array(gt_kp[:2]))  # Use only x, y for distance calculation\n",
    "#         print(\"GT Keypoints\", gt_kp)\n",
    "        if gt_kp[2] == 0:  # Invisible keypoint\n",
    "            total_invisible += 1\n",
    "            if dist <= margin:  # Margin for invisible keypoints\n",
    "                correct_invisible += 1\n",
    "        else:  # Visible keypoint\n",
    "            if dist <= margin:\n",
    "                correct += 1\n",
    "    \n",
    "    correct_total = correct + correct_invisible\n",
    "    accuracy = (correct_total / total) * 100\n",
    "    invisible_accuracy = (correct_invisible / total_invisible) * 100 if total_invisible > 0 else 0\n",
    "    return accuracy, invisible_accuracy, total_invisible\n",
    "\n",
    "# Process images in the folder\n",
    "accuracies = []\n",
    "invisible_accuracies = []\n",
    "total_invisible_keypoints = 0\n",
    "total_inference_time = []\n",
    "i = 0\n",
    "for filename in sorted(os.listdir(input_folder)):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        tensor_image = F.to_tensor(image).to(device)\n",
    "        tensor_image.unsqueeze_(0)\n",
    "        tensor_image = list(tensor_image)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(tensor_image)\n",
    "            tensor_image = (tensor_image[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "        \n",
    "        scores = output[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "        high_scores_idxs = np.where(scores > 0.01)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "        post_nms_idxs = torchvision.ops.nms(output[0]['boxes'][high_scores_idxs], output[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "        confidence = output[0]['scores'][high_scores_idxs].detach().cpu().numpy()\n",
    "\n",
    "#         keypoints = []\n",
    "#         for kps in output[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "#             keypoints.append(list(map(int, kps[0,0:2])))\n",
    "            \n",
    "\n",
    "            \n",
    "#         bboxes = []\n",
    "#         for bbox in output[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "#             bboxes.append(list(map(int, bbox.tolist())))\n",
    "            \n",
    "        bboxes = []\n",
    "        for bbox in output[0]['boxes'][high_scores_idxs].detach().cpu().numpy():\n",
    "            bboxes.append(list(map(int, bbox.tolist())))\n",
    "       \n",
    "#         labels = []\n",
    "#         for label in output[0]['labels'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "#             labels.append(label)\n",
    "            \n",
    "        labels = []\n",
    "        for label in output[0]['labels'][high_scores_idxs].detach().cpu().numpy():\n",
    "            labels.append(label)\n",
    "            \n",
    "        keypoints = []\n",
    "        for idx, kps in enumerate(output[0]['keypoints'][high_scores_idxs].detach().cpu().numpy()):\n",
    "            keypoints.append(list(map(int, kps[0, 0:2])) + [confidence[idx]] + [labels[idx]])\n",
    "            \n",
    "        keypoints = [torch.tensor(kp, dtype=torch.float32).to(device) if not isinstance(kp, torch.Tensor) else kp for kp in keypoints]\n",
    "        keypoints = torch.stack(keypoints).to(device)\n",
    "        \n",
    "        unique_labels, best_keypoint_indices = torch.unique(keypoints[:, 3], return_inverse=True)\n",
    "        best_scores, best_indices = torch.max(keypoints[:, 2].unsqueeze(0) * (best_keypoint_indices == torch.arange(len(unique_labels)).unsqueeze(1).cuda()), dim=1)\n",
    "        keypoints = keypoints[best_indices]\n",
    "            \n",
    "#         keypoints_ = [x for _,x in sorted(zip(labels,keypoints))]\n",
    "        # Load ground truth keypoints\n",
    "        json_filename = filename.split('.')[0] + '.json'  # Construct JSON filename\n",
    "        json_path = os.path.join(input_folder, json_filename)\n",
    "        ground_truth_keypoints = load_ground_truth(json_path) \n",
    "        \n",
    "#         print(keypoints)\n",
    "\n",
    "        # Visualize keypoints on the image\n",
    "#         for point in keypoints:\n",
    "#             x,y, c, l = point\n",
    "#             cv2.circle(image, (int(x), int(y)), 9, (255, 0, 0), -1)  # Draws a blue circle on each keypoint\n",
    "            \n",
    "        # Ground truth keypoints in red\n",
    "        for x, y, _ in ground_truth_keypoints:\n",
    "            cv2.circle(image, (x, y), radius=8, color=(0, 0, 255), thickness=-1)\n",
    "            \n",
    "        # Draw lines between consecutive ground truth keypoints\n",
    "        for j in range(len(ground_truth_keypoints) - 1):\n",
    "            start_point = tuple(ground_truth_keypoints[j][:2])\n",
    "            end_point = tuple(ground_truth_keypoints[j + 1][:2])\n",
    "            cv2.line(image, start_point, end_point, color=(255, 0, 0), thickness=3)\n",
    "            \n",
    "        # Visualize keypoints and bounding boxes on the image\n",
    "        for bbox in bboxes:\n",
    "            x_min, y_min, x_max, y_max = bbox\n",
    "            # Draw bounding box (Green color with thickness 2)\n",
    "            cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), thickness=2)\n",
    "\n",
    "        # Visualize detected keypoints on the image\n",
    "        for point in keypoints:\n",
    "            x, y, c, l = point\n",
    "            # Draw a circle for each detected keypoint (Blue color for keypoints)\n",
    "            cv2.circle(image, (int(x), int(y)), 9, (255, 0, 0), -1)\n",
    "\n",
    "        # Ground truth keypoints in red for comparison\n",
    "        for x, y, _ in ground_truth_keypoints:\n",
    "            cv2.circle(image, (x, y), radius=8, color=(0, 0, 255), thickness=-1)\n",
    "\n",
    "        # Draw lines between consecutive ground truth keypoints\n",
    "        for j in range(len(ground_truth_keypoints) - 1):\n",
    "            start_point = tuple(ground_truth_keypoints[j][:2])\n",
    "            end_point = tuple(ground_truth_keypoints[j + 1][:2])\n",
    "            cv2.line(image, start_point, end_point, color=(255, 0, 0), thickness=3)\n",
    "\n",
    "        # Save the modified image to the output folder\n",
    "        output_image_path = os.path.join(output_frames_folder, filename)\n",
    "        cv2.imwrite(output_image_path, image)\n",
    "        \n",
    "        # Calculate and store accuracy\n",
    "        accuracy, invisible_accuracy, num_invisible = calculate_accuracy(keypoints, ground_truth_keypoints, margin=10)\n",
    "        accuracies.append(accuracy)\n",
    "        invisible_accuracies.append(invisible_accuracy)\n",
    "#         total_inference_time.append(inference_time)\n",
    "        total_invisible_keypoints += num_invisible\n",
    "        print(f\"Accuracy for {filename}: {accuracy}%\")\n",
    "        print(f\"Invisible Keypoint Accuracy for {filename}: {invisible_accuracy}%\")\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "# Print overall accuracy\n",
    "overall_accuracy = np.mean(accuracies)\n",
    "overall_invisible_accuracy = np.mean(invisible_accuracies)\n",
    "avg_inference_time = np.mean(total_inference_time)\n",
    "print(f\"Overall accuracy: {overall_accuracy}%\")\n",
    "print(f\"Overall invisible keypoint accuracy: {overall_invisible_accuracy}%\")\n",
    "print(f\"Total number of invisible keypoints: {total_invisible_keypoints}\")\n",
    "# print(f\"Average inference time: {avg_inference_time}\")\n",
    "\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2cca35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998915195465088, 1.0], [255.0, 312.0, 0.9999997615814209, 2.0], [207.0, 283.0, 0.9999959468841553, 3.0], [157.0, 254.0, 0.999987006187439, 4.0], [172.0, 229.0, 0.9999657869338989, 5.0], [198.0, 164.0, 0.9999083280563354, 6.0], [225.0, 97.0, 0.9996922016143799, 7.0], [205.0, 73.0, 0.9864763021469116, 8.0], [230.0, 44.0, 0.9905106425285339, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[254.0, 441.0, 0.9996466636657715, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [207.0, 283.0, 0.9999953508377075, 3.0], [158.0, 254.0, 0.999982476234436, 4.0], [173.0, 228.0, 0.9999561309814453, 5.0], [198.0, 164.0, 0.9999051094055176, 6.0], [226.0, 97.0, 0.999650239944458, 7.0], [205.0, 72.0, 0.990409255027771, 8.0], [230.0, 45.0, 0.9917991161346436, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999935507774353, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [207.0, 283.0, 0.9999967813491821, 3.0], [158.0, 254.0, 0.9999803304672241, 4.0], [173.0, 228.0, 0.9999545812606812, 5.0], [199.0, 164.0, 0.9998348951339722, 6.0], [227.0, 96.0, 0.9992879033088684, 7.0], [206.0, 74.0, 0.984025776386261, 8.0], [233.0, 45.0, 0.9938619136810303, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 441.0, 0.999859094619751, 1.0], [255.0, 312.0, 0.9999997615814209, 2.0], [207.0, 282.0, 0.9999954700469971, 3.0], [158.0, 253.0, 0.9999850988388062, 4.0], [174.0, 227.0, 0.9999383687973022, 5.0], [200.0, 163.0, 0.9998507499694824, 6.0], [229.0, 97.0, 0.9994421601295471, 7.0], [209.0, 74.0, 0.9829141497612, 8.0], [234.0, 45.0, 0.9859515428543091, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999841570854187, 1.0], [255.0, 312.0, 0.9999997615814209, 2.0], [207.0, 282.0, 0.9999902248382568, 3.0], [158.0, 252.0, 0.9999871253967285, 4.0], [175.0, 227.0, 0.9999603033065796, 5.0], [202.0, 162.0, 0.9999655485153198, 6.0], [230.0, 97.0, 0.9995608925819397, 7.0], [213.0, 74.0, 0.9933528900146484, 8.0], [236.0, 46.0, 0.9881183505058289, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.999913215637207, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [207.0, 282.0, 0.9999884366989136, 3.0], [159.0, 251.0, 0.9999687671661377, 4.0], [175.0, 225.0, 0.9999606609344482, 5.0], [203.0, 162.0, 0.999969482421875, 6.0], [232.0, 96.0, 0.9996347427368164, 7.0], [215.0, 74.0, 0.9955185651779175, 8.0], [239.0, 46.0, 0.996085524559021, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 441.0, 0.9998670816421509, 1.0], [255.0, 312.0, 0.9999997615814209, 2.0], [208.0, 281.0, 0.9999914169311523, 3.0], [160.0, 250.0, 0.9998724460601807, 4.0], [176.0, 224.0, 0.9999655485153198, 5.0], [205.0, 161.0, 0.9999815225601196, 6.0], [235.0, 96.0, 0.9996440410614014, 7.0], [219.0, 74.0, 0.9953606724739075, 8.0], [243.0, 45.0, 0.9942246079444885, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998008608818054, 1.0], [255.0, 312.0, 0.9999997615814209, 2.0], [208.0, 280.0, 0.9999879598617554, 3.0], [161.0, 249.0, 0.9999785423278809, 4.0], [177.0, 224.0, 0.9999616146087646, 5.0], [207.0, 161.0, 0.9999595880508423, 6.0], [237.0, 95.0, 0.999674916267395, 7.0], [221.0, 72.0, 0.9956028461456299, 8.0], [246.0, 45.0, 0.9918071627616882, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 441.0, 0.9998373985290527, 1.0], [255.0, 312.0, 0.9999998807907104, 2.0], [208.0, 280.0, 0.9999821186065674, 3.0], [162.0, 248.0, 0.9999217987060547, 4.0], [178.0, 223.0, 0.9999727010726929, 5.0], [208.0, 160.0, 0.9999333620071411, 6.0], [240.0, 97.0, 0.9994375109672546, 7.0], [224.0, 72.0, 0.9870346188545227, 8.0], [250.0, 44.0, 0.9934287667274475, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[253.0, 442.0, 0.9998477697372437, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [208.0, 279.0, 0.9999423027038574, 3.0], [162.0, 247.0, 0.9999550580978394, 4.0], [179.0, 222.0, 0.9999470710754395, 5.0], [210.0, 160.0, 0.9996238946914673, 6.0], [243.0, 96.0, 0.9995918869972229, 7.0], [226.0, 71.0, 0.9968776702880859, 8.0], [253.0, 44.0, 0.9934180974960327, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 442.0, 0.9998283386230469, 1.0], [255.0, 312.0, 0.9999997615814209, 2.0], [209.0, 278.0, 0.9999101161956787, 3.0], [163.0, 246.0, 0.9999735355377197, 4.0], [180.0, 221.0, 0.9999170303344727, 5.0], [212.0, 159.0, 0.9998518228530884, 6.0], [245.0, 95.0, 0.9997442364692688, 7.0], [229.0, 70.0, 0.9972673654556274, 8.0], [257.0, 46.0, 0.9951635599136353, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998668432235718, 1.0], [255.0, 312.0, 0.9999997615814209, 2.0], [209.0, 278.0, 0.9998759031295776, 3.0], [163.0, 245.0, 0.9999792575836182, 4.0], [181.0, 220.0, 0.9999431371688843, 5.0], [213.0, 158.0, 0.9998999834060669, 6.0], [247.0, 95.0, 0.9995177984237671, 7.0], [232.0, 70.0, 0.9950019717216492, 8.0], [259.0, 45.0, 0.9967622756958008, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9997814297676086, 1.0], [255.0, 312.0, 0.9999998807907104, 2.0], [210.0, 278.0, 0.9999878406524658, 3.0], [164.0, 244.0, 0.9999686479568481, 4.0], [182.0, 219.0, 0.9999271631240845, 5.0], [216.0, 158.0, 0.9999191761016846, 6.0], [250.0, 95.0, 0.9995700716972351, 7.0], [235.0, 69.0, 0.9954537153244019, 8.0], [263.0, 45.0, 0.9880058169364929, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 442.0, 0.9998928308486938, 1.0], [255.0, 312.0, 0.9999998807907104, 2.0], [210.0, 277.0, 0.9999849796295166, 3.0], [165.0, 243.0, 0.9999868869781494, 4.0], [183.0, 219.0, 0.9998979568481445, 5.0], [218.0, 157.0, 0.9996358156204224, 6.0], [252.0, 95.0, 0.9997205138206482, 7.0], [239.0, 70.0, 0.9962314963340759, 8.0], [266.0, 44.0, 0.9933086633682251, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 442.0, 0.9998319149017334, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [210.0, 277.0, 0.9999827146530151, 3.0], [165.0, 242.0, 0.9999905824661255, 4.0], [184.0, 218.0, 0.9999383687973022, 5.0], [219.0, 157.0, 0.9997668862342834, 6.0], [254.0, 95.0, 0.9996902942657471, 7.0], [241.0, 69.0, 0.9939820170402527, 8.0], [269.0, 44.0, 0.991473913192749, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999426603317261, 1.0], [255.0, 312.0, 0.9999997615814209, 2.0], [211.0, 276.0, 0.9999672174453735, 3.0], [166.0, 241.0, 0.9999912977218628, 4.0], [185.0, 217.0, 0.9999401569366455, 5.0], [221.0, 156.0, 0.9997500777244568, 6.0], [256.0, 95.0, 0.9997149109840393, 7.0], [244.0, 69.0, 0.9956700801849365, 8.0], [272.0, 46.0, 0.9892922639846802, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998075366020203, 1.0], [255.0, 312.0, 0.9999997615814209, 2.0], [211.0, 275.0, 0.9999127388000488, 3.0], [167.0, 240.0, 0.9999830722808838, 4.0], [185.0, 216.0, 0.9999676942825317, 5.0], [223.0, 156.0, 0.9998237490653992, 6.0], [259.0, 95.0, 0.9996059536933899, 7.0], [246.0, 68.0, 0.9939436316490173, 8.0], [276.0, 45.0, 0.9971869587898254, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998948574066162, 1.0], [255.0, 312.0, 0.9999997615814209, 2.0], [212.0, 275.0, 0.9999955892562866, 3.0], [167.0, 239.0, 0.9999603033065796, 4.0], [187.0, 215.0, 0.9999809265136719, 5.0], [225.0, 156.0, 0.9998698234558105, 6.0], [262.0, 94.0, 0.9996893405914307, 7.0], [249.0, 68.0, 0.9957375526428223, 8.0], [279.0, 44.0, 0.9976435303688049, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.999887228012085, 1.0], [255.0, 312.0, 0.9999997615814209, 2.0], [212.0, 275.0, 0.9999959468841553, 3.0], [168.0, 238.0, 0.9999842643737793, 4.0], [188.0, 215.0, 0.9999796152114868, 5.0], [226.0, 156.0, 0.999848484992981, 6.0], [264.0, 95.0, 0.9998125433921814, 7.0], [251.0, 68.0, 0.9919742941856384, 8.0], [282.0, 45.0, 0.9965318441390991, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[255.0, 443.0, 0.9997418522834778, 1.0], [255.0, 312.0, 0.9999997615814209, 2.0], [213.0, 274.0, 0.9999948740005493, 3.0], [169.0, 237.0, 0.9999866485595703, 4.0], [189.0, 214.0, 0.9999666213989258, 5.0], [228.0, 155.0, 0.9998136162757874, 6.0], [266.0, 95.0, 0.9997252821922302, 7.0], [254.0, 69.0, 0.9934813976287842, 8.0], [286.0, 44.0, 0.9956660270690918, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999743640422821, 1.0], [255.0, 312.0, 0.9999997615814209, 2.0], [213.0, 274.0, 0.9999954700469971, 3.0], [170.0, 236.0, 0.9999895095825195, 4.0], [190.0, 213.0, 0.9999734163284302, 5.0], [229.0, 155.0, 0.9997209906578064, 6.0], [269.0, 95.0, 0.9996254444122314, 7.0], [257.0, 68.0, 0.996276319026947, 8.0], [290.0, 45.0, 0.994249701499939, 9.0]]\n",
      "(9, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints after label index [[251.0, 441.0, 0.9998308420181274, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [214.0, 273.0, 0.9999963045120239, 3.0], [171.0, 234.0, 0.9999827146530151, 4.0], [191.0, 212.0, 0.9999685287475586, 5.0], [231.0, 155.0, 0.9997351765632629, 6.0], [271.0, 95.0, 0.9997947812080383, 7.0], [260.0, 68.0, 0.9950980544090271, 8.0], [294.0, 46.0, 0.9961163997650146, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999338388442993, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [214.0, 273.0, 0.9999960660934448, 3.0], [172.0, 234.0, 0.99997878074646, 4.0], [192.0, 212.0, 0.9999760389328003, 5.0], [232.0, 154.0, 0.999760091304779, 6.0], [273.0, 94.0, 0.9997716546058655, 7.0], [261.0, 67.0, 0.9907596111297607, 8.0], [296.0, 47.0, 0.9961928129196167, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999923825263977, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [214.0, 272.0, 0.9999960660934448, 3.0], [172.0, 233.0, 0.9999843835830688, 4.0], [193.0, 211.0, 0.9999657869338989, 5.0], [234.0, 154.0, 0.9995765089988708, 6.0], [275.0, 95.0, 0.9997417330741882, 7.0], [264.0, 67.0, 0.9975154399871826, 8.0], [299.0, 47.0, 0.9978677034378052, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[253.0, 442.0, 0.9998623132705688, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [215.0, 271.0, 0.9999955892562866, 3.0], [173.0, 233.0, 0.999985933303833, 4.0], [194.0, 211.0, 0.9999759197235107, 5.0], [236.0, 154.0, 0.9997642636299133, 6.0], [278.0, 96.0, 0.9997673630714417, 7.0], [267.0, 67.0, 0.994107723236084, 8.0], [302.0, 48.0, 0.9914473295211792, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 442.0, 0.9998563528060913, 1.0], [255.0, 311.0, 0.9999991655349731, 2.0], [215.0, 271.0, 0.9999959468841553, 3.0], [174.0, 231.0, 0.9999665021896362, 4.0], [195.0, 210.0, 0.9999568462371826, 5.0], [238.0, 154.0, 0.9997294545173645, 6.0], [281.0, 95.0, 0.9997904896736145, 7.0], [271.0, 68.0, 0.996371865272522, 8.0], [306.0, 48.0, 0.9954050779342651, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998518228530884, 1.0], [255.0, 311.0, 0.9999985694885254, 2.0], [215.0, 270.0, 0.9999966621398926, 3.0], [175.0, 230.0, 0.9999104738235474, 4.0], [196.0, 209.0, 0.9999260902404785, 5.0], [240.0, 154.0, 0.9998807907104492, 6.0], [283.0, 95.0, 0.9998180270195007, 7.0], [273.0, 67.0, 0.9954417943954468, 8.0], [309.0, 49.0, 0.9958752989768982, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999128580093384, 1.0], [255.0, 311.0, 0.9999984502792358, 2.0], [216.0, 270.0, 0.9999960660934448, 3.0], [176.0, 230.0, 0.9999068975448608, 4.0], [197.0, 208.0, 0.999925971031189, 5.0], [242.0, 153.0, 0.9998828172683716, 6.0], [285.0, 96.0, 0.9997853636741638, 7.0], [275.0, 67.0, 0.9934325218200684, 8.0], [312.0, 50.0, 0.9961220622062683, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998314380645752, 1.0], [255.0, 311.0, 0.999998927116394, 2.0], [217.0, 270.0, 0.999994158744812, 3.0], [177.0, 229.0, 0.9999364614486694, 4.0], [198.0, 207.0, 0.9999250173568726, 5.0], [243.0, 153.0, 0.9998379945755005, 6.0], [288.0, 97.0, 0.9998443126678467, 7.0], [280.0, 68.0, 0.9964630007743835, 8.0], [315.0, 50.0, 0.9975161552429199, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999380111694336, 1.0], [255.0, 311.0, 0.999998927116394, 2.0], [217.0, 269.0, 0.999996542930603, 3.0], [178.0, 228.0, 0.9999397993087769, 4.0], [200.0, 207.0, 0.9999401569366455, 5.0], [245.0, 153.0, 0.9998176693916321, 6.0], [290.0, 97.0, 0.999861478805542, 7.0], [282.0, 67.0, 0.998516857624054, 8.0], [318.0, 51.0, 0.9983578324317932, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998935461044312, 1.0], [255.0, 312.0, 0.9999984502792358, 2.0], [217.0, 269.0, 0.9999909400939941, 3.0], [179.0, 227.0, 0.9999680519104004, 4.0], [201.0, 206.0, 0.9999591112136841, 5.0], [246.0, 153.0, 0.999842643737793, 6.0], [293.0, 96.0, 0.9998156428337097, 7.0], [285.0, 68.0, 0.9977213740348816, 8.0], [320.0, 52.0, 0.9972425699234009, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9997463822364807, 1.0], [255.0, 311.0, 0.999998927116394, 2.0], [218.0, 268.0, 0.9999901056289673, 3.0], [180.0, 227.0, 0.9997833371162415, 4.0], [202.0, 206.0, 0.9999620914459229, 5.0], [248.0, 152.0, 0.9996598958969116, 6.0], [294.0, 98.0, 0.9998564720153809, 7.0], [287.0, 68.0, 0.9974579215049744, 8.0], [323.0, 53.0, 0.9944267272949219, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998182654380798, 1.0], [255.0, 311.0, 0.999998927116394, 2.0], [218.0, 268.0, 0.9999927282333374, 3.0], [181.0, 226.0, 0.9999604225158691, 4.0], [203.0, 205.0, 0.9999632835388184, 5.0], [249.0, 153.0, 0.9996317625045776, 6.0], [298.0, 98.0, 0.9998742341995239, 7.0], [290.0, 68.0, 0.9964728951454163, 8.0], [328.0, 54.0, 0.9951316118240356, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9998206496238708, 1.0], [255.0, 311.0, 0.9999985694885254, 2.0], [219.0, 267.0, 0.9999929666519165, 3.0], [182.0, 225.0, 0.9998793601989746, 4.0], [204.0, 205.0, 0.9999717473983765, 5.0], [252.0, 152.0, 0.9997941851615906, 6.0], [300.0, 98.0, 0.9999008178710938, 7.0], [292.0, 68.0, 0.9959048628807068, 8.0], [331.0, 56.0, 0.9885234236717224, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9998194575309753, 1.0], [255.0, 312.0, 0.9999979734420776, 2.0], [219.0, 267.0, 0.9999945163726807, 3.0], [183.0, 224.0, 0.9999414682388306, 4.0], [205.0, 204.0, 0.9999759197235107, 5.0], [254.0, 152.0, 0.9997933506965637, 6.0], [302.0, 98.0, 0.9999275207519531, 7.0], [295.0, 68.0, 0.9978525638580322, 8.0], [333.0, 56.0, 0.9931653141975403, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9997914433479309, 1.0], [255.0, 311.0, 0.9999984502792358, 2.0], [220.0, 267.0, 0.9999958276748657, 3.0], [183.0, 223.0, 0.9999790191650391, 4.0], [206.0, 204.0, 0.9999735355377197, 5.0], [256.0, 152.0, 0.999825656414032, 6.0], [305.0, 99.0, 0.9998838901519775, 7.0], [298.0, 68.0, 0.9985670447349548, 8.0], [336.0, 56.0, 0.991302490234375, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 441.0, 0.9998120665550232, 1.0], [255.0, 311.0, 0.9999985694885254, 2.0], [220.0, 266.0, 0.9999978542327881, 3.0], [184.0, 222.0, 0.9999868869781494, 4.0], [207.0, 203.0, 0.999977707862854, 5.0], [258.0, 152.0, 0.9997155070304871, 6.0], [307.0, 98.0, 0.9998832941055298, 7.0], [300.0, 69.0, 0.9979842901229858, 8.0], [339.0, 57.0, 0.997374415397644, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.999900221824646, 1.0], [255.0, 312.0, 0.9999985694885254, 2.0], [221.0, 266.0, 0.9999940395355225, 3.0], [185.0, 221.0, 0.9999874830245972, 4.0], [208.0, 202.0, 0.9999605417251587, 5.0], [259.0, 152.0, 0.9998849630355835, 6.0], [309.0, 100.0, 0.9998787641525269, 7.0], [304.0, 69.0, 0.9976245760917664, 8.0], [341.0, 57.0, 0.9944045543670654, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998595714569092, 1.0], [255.0, 311.0, 0.999997615814209, 2.0], [221.0, 265.0, 0.9999949932098389, 3.0], [186.0, 221.0, 0.9999921321868896, 4.0], [210.0, 202.0, 0.9999796152114868, 5.0], [260.0, 152.0, 0.999900221824646, 6.0], [312.0, 100.0, 0.9997865557670593, 7.0], [307.0, 69.0, 0.997366726398468, 8.0], [346.0, 58.0, 0.9939104318618774, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998698234558105, 1.0], [255.0, 311.0, 0.9999977350234985, 2.0], [222.0, 265.0, 0.9999895095825195, 3.0], [187.0, 220.0, 0.9999914169311523, 4.0], [211.0, 201.0, 0.9999750852584839, 5.0], [262.0, 152.0, 0.9998321533203125, 6.0], [314.0, 102.0, 0.9999150037765503, 7.0], [310.0, 71.0, 0.9977685213088989, 8.0], [348.0, 60.0, 0.9934712648391724, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999798595905304, 1.0], [255.0, 311.0, 0.9999974966049194, 2.0], [222.0, 265.0, 0.9999891519546509, 3.0], [188.0, 219.0, 0.9999500513076782, 4.0], [212.0, 201.0, 0.9999706745147705, 5.0], [264.0, 152.0, 0.9998639822006226, 6.0], [317.0, 101.0, 0.9998779296875, 7.0], [311.0, 71.0, 0.9980358481407166, 8.0], [351.0, 61.0, 0.9939218759536743, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9997493624687195, 1.0], [255.0, 311.0, 0.9999983310699463, 2.0], [223.0, 265.0, 0.9999905824661255, 3.0], [189.0, 219.0, 0.9999680519104004, 4.0], [213.0, 201.0, 0.9999648332595825, 5.0], [265.0, 152.0, 0.9999102354049683, 6.0], [319.0, 103.0, 0.9999232292175293, 7.0], [314.0, 72.0, 0.9969695210456848, 8.0], [354.0, 63.0, 0.997779905796051, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999240636825562, 1.0], [255.0, 311.0, 0.9999986886978149, 2.0], [223.0, 264.0, 0.999990701675415, 3.0], [190.0, 218.0, 0.9999774694442749, 4.0], [214.0, 200.0, 0.9999516010284424, 5.0], [267.0, 152.0, 0.9998650550842285, 6.0], [321.0, 103.0, 0.999659538269043, 7.0], [317.0, 72.0, 0.9984862804412842, 8.0], [357.0, 63.0, 0.996624231338501, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999817430973053, 1.0], [255.0, 311.0, 0.9999984502792358, 2.0], [224.0, 264.0, 0.999991774559021, 3.0], [191.0, 217.0, 0.9999587535858154, 4.0], [216.0, 199.0, 0.9999017715454102, 5.0], [269.0, 153.0, 0.9997918009757996, 6.0], [324.0, 104.0, 0.9997288584709167, 7.0], [321.0, 73.0, 0.9971190690994263, 8.0], [360.0, 65.0, 0.9952468276023865, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998828172683716, 1.0], [255.0, 311.0, 0.9999984502792358, 2.0], [225.0, 264.0, 0.9999935626983643, 3.0], [193.0, 216.0, 0.9999628067016602, 4.0], [218.0, 199.0, 0.9998311996459961, 5.0], [272.0, 152.0, 0.9998677968978882, 6.0], [327.0, 105.0, 0.9999252557754517, 7.0], [326.0, 74.0, 0.9955436587333679, 8.0], [364.0, 66.0, 0.994472324848175, 9.0]]\n",
      "(9, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints after label index [[252.0, 442.0, 0.9999604225158691, 1.0], [255.0, 311.0, 0.9999986886978149, 2.0], [225.0, 263.0, 0.9999905824661255, 3.0], [194.0, 216.0, 0.9999579191207886, 4.0], [219.0, 199.0, 0.9998288154602051, 5.0], [273.0, 153.0, 0.9997923970222473, 6.0], [329.0, 105.0, 0.999832272529602, 7.0], [329.0, 75.0, 0.9919801950454712, 8.0], [367.0, 68.0, 0.9955319166183472, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998249411582947, 1.0], [255.0, 312.0, 0.999998927116394, 2.0], [226.0, 263.0, 0.9999923706054688, 3.0], [195.0, 215.0, 0.9999754428863525, 4.0], [220.0, 199.0, 0.9998650550842285, 5.0], [275.0, 152.0, 0.9993796348571777, 6.0], [331.0, 106.0, 0.9998262524604797, 7.0], [329.0, 74.0, 0.9966117739677429, 8.0], [370.0, 69.0, 0.9961179494857788, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9998313188552856, 1.0], [255.0, 311.0, 0.9999988079071045, 2.0], [226.0, 263.0, 0.9999887943267822, 3.0], [196.0, 214.0, 0.9999699592590332, 4.0], [221.0, 198.0, 0.9999287128448486, 5.0], [277.0, 153.0, 0.9998145699501038, 6.0], [334.0, 107.0, 0.9999067783355713, 7.0], [332.0, 75.0, 0.9966186285018921, 8.0], [371.0, 71.0, 0.9981473684310913, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998162388801575, 1.0], [255.0, 311.0, 0.9999990463256836, 2.0], [226.0, 262.0, 0.9999939203262329, 3.0], [197.0, 213.0, 0.9999357461929321, 4.0], [222.0, 197.0, 0.9999594688415527, 5.0], [279.0, 153.0, 0.9998737573623657, 6.0], [336.0, 109.0, 0.9998519420623779, 7.0], [334.0, 77.0, 0.9968016147613525, 8.0], [374.0, 72.0, 0.9974902868270874, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998573064804077, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [227.0, 262.0, 0.9999912977218628, 3.0], [198.0, 212.0, 0.9998701810836792, 4.0], [224.0, 197.0, 0.999963641166687, 5.0], [280.0, 153.0, 0.9998863935470581, 6.0], [338.0, 109.0, 0.9996495246887207, 7.0], [338.0, 77.0, 0.9979198575019836, 8.0], [378.0, 73.0, 0.9951747059822083, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[253.0, 442.0, 0.9998301267623901, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [227.0, 262.0, 0.9999904632568359, 3.0], [200.0, 212.0, 0.9999809265136719, 4.0], [225.0, 196.0, 0.9999603033065796, 5.0], [282.0, 153.0, 0.9998917579650879, 6.0], [341.0, 110.0, 0.9996065497398376, 7.0], [339.0, 78.0, 0.9989714622497559, 8.0], [380.0, 75.0, 0.9944726824760437, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999350309371948, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [228.0, 262.0, 0.9999933242797852, 3.0], [201.0, 212.0, 0.9999606609344482, 4.0], [226.0, 196.0, 0.9999558925628662, 5.0], [283.0, 154.0, 0.9999086856842041, 6.0], [343.0, 111.0, 0.9996323585510254, 7.0], [342.0, 79.0, 0.9986521601676941, 8.0], [382.0, 77.0, 0.9942547678947449, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998457431793213, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [229.0, 261.0, 0.999991774559021, 3.0], [202.0, 211.0, 0.9999366998672485, 4.0], [227.0, 196.0, 0.9999690055847168, 5.0], [285.0, 154.0, 0.9999140501022339, 6.0], [345.0, 112.0, 0.9995871186256409, 7.0], [345.0, 80.0, 0.9979633092880249, 8.0], [386.0, 77.0, 0.995901882648468, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9997650980949402, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [230.0, 261.0, 0.9999911785125732, 3.0], [202.0, 211.0, 0.9999879598617554, 4.0], [228.0, 195.0, 0.9999761581420898, 5.0], [287.0, 154.0, 0.999886155128479, 6.0], [347.0, 112.0, 0.9996371269226074, 7.0], [348.0, 81.0, 0.9980292916297913, 8.0], [389.0, 78.0, 0.9970462918281555, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999243021011353, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [230.0, 261.0, 0.9999912977218628, 3.0], [203.0, 210.0, 0.9999780654907227, 4.0], [230.0, 196.0, 0.9999758005142212, 5.0], [289.0, 154.0, 0.9999090433120728, 6.0], [349.0, 113.0, 0.9995695948600769, 7.0], [350.0, 82.0, 0.9978358149528503, 8.0], [392.0, 80.0, 0.9966318011283875, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998481273651123, 1.0], [255.0, 312.0, 0.9999996423721313, 2.0], [230.0, 261.0, 0.9999902248382568, 3.0], [205.0, 210.0, 0.9999464750289917, 4.0], [231.0, 195.0, 0.9999767541885376, 5.0], [290.0, 155.0, 0.9999256134033203, 6.0], [351.0, 114.0, 0.9995835423469543, 7.0], [352.0, 82.0, 0.9981179237365723, 8.0], [394.0, 81.0, 0.9981826543807983, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 442.0, 0.9998531341552734, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [231.0, 260.0, 0.9999790191650391, 3.0], [206.0, 209.0, 0.9998925924301147, 4.0], [232.0, 195.0, 0.9999723434448242, 5.0], [293.0, 156.0, 0.9998658895492554, 6.0], [354.0, 115.0, 0.9998273253440857, 7.0], [355.0, 83.0, 0.9986949563026428, 8.0], [397.0, 83.0, 0.9958055019378662, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999324083328247, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [232.0, 260.0, 0.9999804496765137, 3.0], [207.0, 208.0, 0.9999061822891235, 4.0], [233.0, 195.0, 0.9999749660491943, 5.0], [294.0, 156.0, 0.9998922348022461, 6.0], [356.0, 117.0, 0.9998677968978882, 7.0], [358.0, 84.0, 0.9989569187164307, 8.0], [398.0, 84.0, 0.9927504062652588, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998546838760376, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [232.0, 259.0, 0.9999933242797852, 3.0], [208.0, 207.0, 0.9998977184295654, 4.0], [234.0, 194.0, 0.9999711513519287, 5.0], [296.0, 156.0, 0.999847412109375, 6.0], [358.0, 117.0, 0.9999054670333862, 7.0], [360.0, 86.0, 0.9992757439613342, 8.0], [402.0, 86.0, 0.9963473677635193, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998422861099243, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [232.0, 259.0, 0.9999678134918213, 3.0], [209.0, 206.0, 0.9998793601989746, 4.0], [235.0, 194.0, 0.9999558925628662, 5.0], [298.0, 156.0, 0.9999337196350098, 6.0], [360.0, 119.0, 0.9999305009841919, 7.0], [363.0, 87.0, 0.9990682005882263, 8.0], [404.0, 89.0, 0.9925093650817871, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998366832733154, 1.0], [255.0, 311.0, 0.999998927116394, 2.0], [233.0, 259.0, 0.9999949932098389, 3.0], [210.0, 206.0, 0.9999206066131592, 4.0], [237.0, 194.0, 0.9999178647994995, 5.0], [299.0, 156.0, 0.9999146461486816, 6.0], [362.0, 120.0, 0.999830961227417, 7.0], [366.0, 87.0, 0.9987735152244568, 8.0], [407.0, 90.0, 0.9940540194511414, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 441.0, 0.9998610019683838, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [234.0, 259.0, 0.9999984502792358, 3.0], [211.0, 206.0, 0.9999490976333618, 4.0], [238.0, 194.0, 0.9999479055404663, 5.0], [300.0, 157.0, 0.999922513961792, 6.0], [365.0, 121.0, 0.9998350143432617, 7.0], [368.0, 88.0, 0.9982907176017761, 8.0], [410.0, 91.0, 0.9974260926246643, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[253.0, 442.0, 0.9998840093612671, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [234.0, 259.0, 0.9999951124191284, 3.0], [212.0, 205.0, 0.9999402761459351, 4.0], [240.0, 193.0, 0.9999717473983765, 5.0], [302.0, 158.0, 0.9999244213104248, 6.0], [367.0, 121.0, 0.9998615980148315, 7.0], [371.0, 89.0, 0.9988486766815186, 8.0], [413.0, 92.0, 0.9945966005325317, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999135732650757, 1.0], [255.0, 311.0, 0.9999991655349731, 2.0], [235.0, 258.0, 0.9999966621398926, 3.0], [213.0, 205.0, 0.999933123588562, 4.0], [241.0, 193.0, 0.9999685287475586, 5.0], [304.0, 158.0, 0.9999017715454102, 6.0], [368.0, 123.0, 0.9998354911804199, 7.0], [375.0, 91.0, 0.9980428218841553, 8.0], [415.0, 95.0, 0.9951553344726562, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998531341552734, 1.0], [255.0, 311.0, 0.9999990463256836, 2.0], [235.0, 258.0, 0.9999983310699463, 3.0], [214.0, 205.0, 0.9999556541442871, 4.0], [242.0, 193.0, 0.9999792575836182, 5.0], [306.0, 159.0, 0.9998884201049805, 6.0], [370.0, 124.0, 0.9993834495544434, 7.0], [377.0, 92.0, 0.9978759288787842, 8.0], [418.0, 96.0, 0.99427729845047, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998730421066284, 1.0], [256.0, 311.0, 0.9999988079071045, 2.0], [236.0, 257.0, 0.9999986886978149, 3.0], [216.0, 204.0, 0.9999666213989258, 4.0], [243.0, 193.0, 0.9999778270721436, 5.0], [307.0, 159.0, 0.9998875856399536, 6.0], [373.0, 126.0, 0.9998538494110107, 7.0], [380.0, 94.0, 0.9984342455863953, 8.0], [420.0, 98.0, 0.995893120765686, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998667240142822, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [237.0, 257.0, 0.9999988079071045, 3.0], [217.0, 204.0, 0.9999814033508301, 4.0], [244.0, 192.0, 0.9999755620956421, 5.0], [309.0, 160.0, 0.9999185800552368, 6.0], [375.0, 127.0, 0.9995174407958984, 7.0], [382.0, 94.0, 0.9971489310264587, 8.0], [424.0, 100.0, 0.994351863861084, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999245405197144, 1.0], [256.0, 311.0, 0.9999990463256836, 2.0], [237.0, 257.0, 0.9999980926513672, 3.0], [218.0, 203.0, 0.9999903440475464, 4.0], [246.0, 192.0, 0.9999661445617676, 5.0], [311.0, 160.0, 0.9996703863143921, 6.0], [377.0, 128.0, 0.9996471405029297, 7.0], [384.0, 96.0, 0.9975656270980835, 8.0], [426.0, 102.0, 0.992141604423523, 9.0]]\n",
      "(9, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints after label index [[250.0, 441.0, 0.9998865127563477, 1.0], [255.0, 311.0, 0.9999991655349731, 2.0], [238.0, 257.0, 0.9999988079071045, 3.0], [219.0, 203.0, 0.9999847412109375, 4.0], [247.0, 192.0, 0.9999579191207886, 5.0], [313.0, 160.0, 0.9999364614486694, 6.0], [379.0, 129.0, 0.9996788501739502, 7.0], [387.0, 97.0, 0.9987529516220093, 8.0], [429.0, 104.0, 0.9964649677276611, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999842643737793, 1.0], [255.0, 311.0, 0.9999991655349731, 2.0], [238.0, 256.0, 0.9999984502792358, 3.0], [220.0, 202.0, 0.9999465942382812, 4.0], [248.0, 192.0, 0.9999549388885498, 5.0], [314.0, 161.0, 0.9999710321426392, 6.0], [381.0, 131.0, 0.9997472167015076, 7.0], [390.0, 99.0, 0.9992740750312805, 8.0], [431.0, 106.0, 0.9968286156654358, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999476671218872, 1.0], [255.0, 311.0, 0.9999990463256836, 2.0], [239.0, 256.0, 0.999997615814209, 3.0], [222.0, 202.0, 0.9999922513961792, 4.0], [249.0, 192.0, 0.9999502897262573, 5.0], [316.0, 162.0, 0.9999572038650513, 6.0], [383.0, 132.0, 0.9997718930244446, 7.0], [393.0, 100.0, 0.9993622899055481, 8.0], [434.0, 108.0, 0.9958364963531494, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999815046787262, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [239.0, 256.0, 0.9999967813491821, 3.0], [223.0, 202.0, 0.9999873638153076, 4.0], [251.0, 192.0, 0.9999518394470215, 5.0], [317.0, 163.0, 0.9999686479568481, 6.0], [385.0, 134.0, 0.9997877478599548, 7.0], [395.0, 101.0, 0.9994483590126038, 8.0], [436.0, 110.0, 0.9971596002578735, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998787641525269, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [240.0, 256.0, 0.999996542930603, 3.0], [223.0, 201.0, 0.9999644756317139, 4.0], [252.0, 192.0, 0.9999430179595947, 5.0], [319.0, 164.0, 0.9999558925628662, 6.0], [387.0, 135.0, 0.9998109936714172, 7.0], [398.0, 102.0, 0.9983592629432678, 8.0], [439.0, 112.0, 0.9948773980140686, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998250603675842, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [241.0, 255.0, 0.9999984502792358, 3.0], [225.0, 201.0, 0.9999496936798096, 4.0], [253.0, 191.0, 0.9999176263809204, 5.0], [321.0, 164.0, 0.9999656677246094, 6.0], [389.0, 136.0, 0.9998149275779724, 7.0], [400.0, 104.0, 0.9990026354789734, 8.0], [440.0, 114.0, 0.9943265318870544, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998908042907715, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [241.0, 255.0, 0.9999984502792358, 3.0], [226.0, 200.0, 0.999932050704956, 4.0], [254.0, 191.0, 0.9998794794082642, 5.0], [322.0, 164.0, 0.9999572038650513, 6.0], [390.0, 137.0, 0.9997155070304871, 7.0], [401.0, 106.0, 0.9990604519844055, 8.0], [443.0, 117.0, 0.9953247308731079, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 441.0, 0.9998540878295898, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [242.0, 255.0, 0.9999988079071045, 3.0], [227.0, 200.0, 0.999936580657959, 4.0], [256.0, 192.0, 0.9998519420623779, 5.0], [324.0, 165.0, 0.9999089241027832, 6.0], [393.0, 139.0, 0.9997425675392151, 7.0], [404.0, 108.0, 0.9985530972480774, 8.0], [445.0, 119.0, 0.9951578974723816, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9998489618301392, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [242.0, 255.0, 0.9999948740005493, 3.0], [228.0, 200.0, 0.9999382495880127, 4.0], [257.0, 191.0, 0.9998985528945923, 5.0], [326.0, 166.0, 0.999795138835907, 6.0], [395.0, 141.0, 0.9995686411857605, 7.0], [407.0, 110.0, 0.9977295994758606, 8.0], [448.0, 122.0, 0.9968311190605164, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.999953031539917, 1.0], [255.0, 311.0, 0.9999991655349731, 2.0], [243.0, 255.0, 0.9999910593032837, 3.0], [229.0, 200.0, 0.9999603033065796, 4.0], [258.0, 191.0, 0.9999567270278931, 5.0], [327.0, 167.0, 0.9998958110809326, 6.0], [397.0, 142.0, 0.9994276165962219, 7.0], [409.0, 111.0, 0.9983593821525574, 8.0], [451.0, 123.0, 0.9978475570678711, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 442.0, 0.9999432563781738, 1.0], [255.0, 311.0, 0.9999991655349731, 2.0], [243.0, 255.0, 0.9999946355819702, 3.0], [231.0, 200.0, 0.9999411106109619, 4.0], [260.0, 191.0, 0.999954342842102, 5.0], [329.0, 168.0, 0.9998632669448853, 6.0], [399.0, 143.0, 0.9997311234474182, 7.0], [412.0, 113.0, 0.9980408549308777, 8.0], [452.0, 126.0, 0.9978867173194885, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9997904896736145, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [244.0, 255.0, 0.999994158744812, 3.0], [232.0, 199.0, 0.9999157190322876, 4.0], [261.0, 191.0, 0.9999547004699707, 5.0], [330.0, 169.0, 0.9998047947883606, 6.0], [401.0, 145.0, 0.9998119473457336, 7.0], [414.0, 114.0, 0.9989909529685974, 8.0], [455.0, 128.0, 0.9956921935081482, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9997802376747131, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [245.0, 254.0, 0.9999963045120239, 3.0], [233.0, 199.0, 0.9999473094940186, 4.0], [262.0, 191.0, 0.9999595880508423, 5.0], [332.0, 170.0, 0.9996167421340942, 6.0], [403.0, 147.0, 0.9998602867126465, 7.0], [417.0, 117.0, 0.9993484616279602, 8.0], [456.0, 131.0, 0.9942242503166199, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9998173117637634, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [246.0, 254.0, 0.9999963045120239, 3.0], [235.0, 199.0, 0.9998912811279297, 4.0], [263.0, 192.0, 0.9999316930770874, 5.0], [334.0, 171.0, 0.9992864727973938, 6.0], [405.0, 148.0, 0.999792754650116, 7.0], [419.0, 119.0, 0.998794436454773, 8.0], [458.0, 133.0, 0.9952192902565002, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999854326248169, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [246.0, 254.0, 0.9999967813491821, 3.0], [236.0, 198.0, 0.9999620914459229, 4.0], [265.0, 192.0, 0.9999322891235352, 5.0], [335.0, 172.0, 0.9997826218605042, 6.0], [407.0, 150.0, 0.9997712969779968, 7.0], [422.0, 120.0, 0.9991036057472229, 8.0], [461.0, 136.0, 0.9961305856704712, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999128580093384, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [247.0, 254.0, 0.9999966621398926, 3.0], [237.0, 198.0, 0.9999575614929199, 4.0], [266.0, 192.0, 0.9998959302902222, 5.0], [336.0, 173.0, 0.9998868703842163, 6.0], [407.0, 152.0, 0.9997970461845398, 7.0], [423.0, 123.0, 0.9985042810440063, 8.0], [463.0, 138.0, 0.9969394207000732, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9998438358306885, 1.0], [256.0, 311.0, 0.9999992847442627, 2.0], [247.0, 254.0, 0.9999961853027344, 3.0], [238.0, 198.0, 0.9999452829360962, 4.0], [267.0, 192.0, 0.9999071359634399, 5.0], [338.0, 173.0, 0.999809205532074, 6.0], [409.0, 154.0, 0.9997580647468567, 7.0], [425.0, 124.0, 0.9986853003501892, 8.0], [465.0, 141.0, 0.996552586555481, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.999919056892395, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [248.0, 253.0, 0.9999967813491821, 3.0], [239.0, 198.0, 0.9999052286148071, 4.0], [268.0, 192.0, 0.9998898506164551, 5.0], [339.0, 174.0, 0.9997650980949402, 6.0], [411.0, 155.0, 0.9997425675392151, 7.0], [428.0, 126.0, 0.9976307153701782, 8.0], [468.0, 143.0, 0.9956437349319458, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998432397842407, 1.0], [255.0, 311.0, 0.9999990463256836, 2.0], [249.0, 254.0, 0.9999959468841553, 3.0], [240.0, 198.0, 0.999923825263977, 4.0], [270.0, 192.0, 0.9999234676361084, 5.0], [341.0, 175.0, 0.9998370409011841, 6.0], [413.0, 157.0, 0.9997805953025818, 7.0], [430.0, 128.0, 0.9986735582351685, 8.0], [468.0, 147.0, 0.996566653251648, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9997673630714417, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [249.0, 254.0, 0.9999958276748657, 3.0], [241.0, 197.0, 0.9999781847000122, 4.0], [271.0, 192.0, 0.999953031539917, 5.0], [343.0, 176.0, 0.9998717308044434, 6.0], [415.0, 159.0, 0.9998108744621277, 7.0], [433.0, 130.0, 0.9973458647727966, 8.0], [470.0, 149.0, 0.9968056678771973, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998546838760376, 1.0], [256.0, 311.0, 0.9999991655349731, 2.0], [250.0, 254.0, 0.9999964237213135, 3.0], [243.0, 197.0, 0.9999663829803467, 4.0], [272.0, 192.0, 0.9999475479125977, 5.0], [344.0, 177.0, 0.9997531771659851, 6.0], [416.0, 161.0, 0.9996790885925293, 7.0], [435.0, 132.0, 0.996039867401123, 8.0], [472.0, 151.0, 0.9972021579742432, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999004602432251, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [250.0, 253.0, 0.9999967813491821, 3.0], [244.0, 197.0, 0.9999589920043945, 4.0], [273.0, 192.0, 0.9998801946640015, 5.0], [346.0, 178.0, 0.9998038411140442, 6.0], [418.0, 162.0, 0.9997782111167908, 7.0], [437.0, 134.0, 0.996802568435669, 8.0], [475.0, 154.0, 0.9975177049636841, 9.0]]\n",
      "(9, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints after label index [[250.0, 442.0, 0.9998635053634644, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [251.0, 253.0, 0.9999979734420776, 3.0], [245.0, 197.0, 0.9998792409896851, 4.0], [275.0, 193.0, 0.9999178647994995, 5.0], [348.0, 179.0, 0.9998975992202759, 6.0], [421.0, 164.0, 0.9998501539230347, 7.0], [440.0, 137.0, 0.9972777962684631, 8.0], [476.0, 157.0, 0.9962764382362366, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998527765274048, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [252.0, 254.0, 0.9999979734420776, 3.0], [247.0, 197.0, 0.999941349029541, 4.0], [276.0, 193.0, 0.9999260902404785, 5.0], [348.0, 180.0, 0.9997377991676331, 6.0], [421.0, 166.0, 0.999811589717865, 7.0], [441.0, 138.0, 0.9976656436920166, 8.0], [478.0, 160.0, 0.9959408044815063, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998433589935303, 1.0], [256.0, 311.0, 0.9999991655349731, 2.0], [252.0, 254.0, 0.9999979734420776, 3.0], [248.0, 197.0, 0.9998986721038818, 4.0], [278.0, 193.0, 0.9999473094940186, 5.0], [350.0, 180.0, 0.9997809529304504, 6.0], [423.0, 167.0, 0.9998000264167786, 7.0], [443.0, 140.0, 0.9982107877731323, 8.0], [480.0, 162.0, 0.9958218336105347, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 443.0, 0.9997991919517517, 1.0], [256.0, 311.0, 0.9999986886978149, 2.0], [253.0, 253.0, 0.9999982118606567, 3.0], [249.0, 197.0, 0.9999197721481323, 4.0], [279.0, 193.0, 0.9999366998672485, 5.0], [352.0, 182.0, 0.9998822212219238, 6.0], [425.0, 170.0, 0.9997356534004211, 7.0], [445.0, 143.0, 0.9980525970458984, 8.0], [482.0, 165.0, 0.9942224621772766, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998076558113098, 1.0], [255.0, 311.0, 0.9999991655349731, 2.0], [253.0, 254.0, 0.9999978542327881, 3.0], [250.0, 196.0, 0.9999276399612427, 4.0], [280.0, 193.0, 0.9999638795852661, 5.0], [353.0, 182.0, 0.9997296929359436, 6.0], [426.0, 171.0, 0.9998831748962402, 7.0], [447.0, 144.0, 0.997983455657959, 8.0], [483.0, 168.0, 0.9961134195327759, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998496770858765, 1.0], [256.0, 311.0, 0.9999986886978149, 2.0], [255.0, 253.0, 0.9999986886978149, 3.0], [251.0, 196.0, 0.9999679327011108, 4.0], [281.0, 194.0, 0.9999805688858032, 5.0], [354.0, 183.0, 0.9998162388801575, 6.0], [428.0, 173.0, 0.9997770190238953, 7.0], [449.0, 147.0, 0.9977474808692932, 8.0], [485.0, 171.0, 0.9945557117462158, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998664855957031, 1.0], [256.0, 311.0, 0.999998927116394, 2.0], [255.0, 253.0, 0.9999977350234985, 3.0], [253.0, 197.0, 0.9999690055847168, 4.0], [283.0, 194.0, 0.9999819993972778, 5.0], [356.0, 185.0, 0.9997891783714294, 6.0], [429.0, 175.0, 0.9998726844787598, 7.0], [451.0, 148.0, 0.9969218373298645, 8.0], [487.0, 173.0, 0.9958603978157043, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999136924743652, 1.0], [256.0, 312.0, 0.9999991655349731, 2.0], [256.0, 253.0, 0.9999991655349731, 3.0], [254.0, 196.0, 0.99996018409729, 4.0], [284.0, 194.0, 0.9999819993972778, 5.0], [357.0, 186.0, 0.9997041821479797, 6.0], [431.0, 177.0, 0.9998070597648621, 7.0], [453.0, 151.0, 0.9972043633460999, 8.0], [488.0, 175.0, 0.9967411160469055, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998151659965515, 1.0], [256.0, 312.0, 0.9999992847442627, 2.0], [256.0, 253.0, 0.9999985694885254, 3.0], [255.0, 196.0, 0.9998738765716553, 4.0], [285.0, 194.0, 0.9999661445617676, 5.0], [359.0, 187.0, 0.9997050166130066, 6.0], [433.0, 180.0, 0.9998321533203125, 7.0], [455.0, 153.0, 0.9967505931854248, 8.0], [490.0, 178.0, 0.9981583952903748, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999826967716217, 1.0], [256.0, 311.0, 0.9999990463256836, 2.0], [257.0, 254.0, 0.9999988079071045, 3.0], [256.0, 196.0, 0.9999418258666992, 4.0], [287.0, 195.0, 0.9999390840530396, 5.0], [360.0, 188.0, 0.999648928642273, 6.0], [434.0, 181.0, 0.9996838569641113, 7.0], [457.0, 156.0, 0.998273491859436, 8.0], [491.0, 181.0, 0.9980297684669495, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998904466629028, 1.0], [256.0, 312.0, 0.9999984502792358, 2.0], [257.0, 253.0, 0.999998927116394, 3.0], [258.0, 196.0, 0.999975323677063, 4.0], [288.0, 195.0, 0.9999675750732422, 5.0], [361.0, 189.0, 0.999515175819397, 6.0], [435.0, 183.0, 0.9998206496238708, 7.0], [459.0, 159.0, 0.9974742531776428, 8.0], [493.0, 185.0, 0.9964892864227295, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998883008956909, 1.0], [256.0, 311.0, 0.9999991655349731, 2.0], [258.0, 253.0, 0.9999988079071045, 3.0], [258.0, 196.0, 0.9999480247497559, 4.0], [289.0, 195.0, 0.9999700784683228, 5.0], [363.0, 190.0, 0.9993368983268738, 6.0], [437.0, 186.0, 0.9996538162231445, 7.0], [460.0, 161.0, 0.998177170753479, 8.0], [494.0, 186.0, 0.9964795708656311, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9998892545700073, 1.0], [256.0, 312.0, 0.9999994039535522, 2.0], [259.0, 254.0, 0.9999969005584717, 3.0], [260.0, 196.0, 0.9999574422836304, 4.0], [290.0, 196.0, 0.999948263168335, 5.0], [365.0, 191.0, 0.9993563294410706, 6.0], [439.0, 188.0, 0.9997639060020447, 7.0], [462.0, 163.0, 0.9982245564460754, 8.0], [495.0, 189.0, 0.9937957525253296, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999065399169922, 1.0], [256.0, 312.0, 0.9999994039535522, 2.0], [259.0, 253.0, 0.999996542930603, 3.0], [261.0, 196.0, 0.9999319314956665, 4.0], [291.0, 196.0, 0.9999393224716187, 5.0], [366.0, 192.0, 0.9997861981391907, 6.0], [440.0, 190.0, 0.999777615070343, 7.0], [464.0, 165.0, 0.9971585273742676, 8.0], [498.0, 192.0, 0.9943361878395081, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9998156428337097, 1.0], [255.0, 312.0, 0.9999992847442627, 2.0], [260.0, 254.0, 0.9999964237213135, 3.0], [263.0, 196.0, 0.9998531341552734, 4.0], [292.0, 196.0, 0.9998853206634521, 5.0], [367.0, 194.0, 0.999860405921936, 6.0], [441.0, 192.0, 0.9998188614845276, 7.0], [466.0, 168.0, 0.9983407258987427, 8.0], [499.0, 195.0, 0.9964655637741089, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.999748170375824, 1.0], [256.0, 312.0, 0.9999991655349731, 2.0], [260.0, 253.0, 0.999997615814209, 3.0], [264.0, 196.0, 0.999896764755249, 4.0], [294.0, 196.0, 0.9998782873153687, 5.0], [368.0, 195.0, 0.9998231530189514, 6.0], [442.0, 193.0, 0.9999055862426758, 7.0], [468.0, 170.0, 0.9967349171638489, 8.0], [499.0, 198.0, 0.9962149262428284, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998891353607178, 1.0], [256.0, 311.0, 0.9999991655349731, 2.0], [261.0, 253.0, 0.999996542930603, 3.0], [265.0, 196.0, 0.9998750686645508, 4.0], [295.0, 197.0, 0.9998756647109985, 5.0], [370.0, 196.0, 0.9996956586837769, 6.0], [443.0, 195.0, 0.9998927116394043, 7.0], [470.0, 172.0, 0.9952139854431152, 8.0], [501.0, 201.0, 0.9960749745368958, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999629259109497, 1.0], [256.0, 312.0, 0.9999988079071045, 2.0], [261.0, 253.0, 0.9999958276748657, 3.0], [266.0, 196.0, 0.9999250173568726, 4.0], [297.0, 197.0, 0.9998630285263062, 5.0], [371.0, 198.0, 0.9998921155929565, 6.0], [445.0, 197.0, 0.9995818734169006, 7.0], [471.0, 174.0, 0.9972227811813354, 8.0], [502.0, 204.0, 0.9959160685539246, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999349117279053, 1.0], [255.0, 312.0, 0.9999994039535522, 2.0], [262.0, 253.0, 0.9999966621398926, 3.0], [268.0, 196.0, 0.9999523162841797, 4.0], [297.0, 197.0, 0.9999243021011353, 5.0], [371.0, 198.0, 0.999945878982544, 6.0], [446.0, 200.0, 0.9997790455818176, 7.0], [473.0, 178.0, 0.9978011250495911, 8.0], [504.0, 207.0, 0.9961985945701599, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 442.0, 0.999933123588562, 1.0], [255.0, 312.0, 0.9999991655349731, 2.0], [263.0, 253.0, 0.9999960660934448, 3.0], [268.0, 197.0, 0.9999617338180542, 4.0], [298.0, 198.0, 0.999901533126831, 5.0], [372.0, 200.0, 0.9999409914016724, 6.0], [448.0, 202.0, 0.9998558759689331, 7.0], [474.0, 180.0, 0.9976071119308472, 8.0], [505.0, 210.0, 0.9933829307556152, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998908042907715, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [264.0, 253.0, 0.9999963045120239, 3.0], [270.0, 197.0, 0.9999586343765259, 4.0], [300.0, 199.0, 0.9999258518218994, 5.0], [374.0, 202.0, 0.9999444484710693, 6.0], [449.0, 204.0, 0.9998712539672852, 7.0], [475.0, 182.0, 0.9937692284584045, 8.0], [506.0, 213.0, 0.9954994320869446, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 441.0, 0.9998134970664978, 1.0], [256.0, 311.0, 0.9999991655349731, 2.0], [264.0, 254.0, 0.9999958276748657, 3.0], [271.0, 197.0, 0.9999566078186035, 4.0], [301.0, 199.0, 0.9999412298202515, 5.0], [375.0, 203.0, 0.9998682737350464, 6.0], [450.0, 207.0, 0.9998621940612793, 7.0], [476.0, 184.0, 0.997750461101532, 8.0], [506.0, 216.0, 0.9940398931503296, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 442.0, 0.9998133778572083, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [265.0, 254.0, 0.999996542930603, 3.0], [272.0, 197.0, 0.9999351501464844, 4.0], [302.0, 200.0, 0.9998936653137207, 5.0], [377.0, 204.0, 0.9998182654380798, 6.0], [450.0, 209.0, 0.9997404217720032, 7.0], [478.0, 187.0, 0.9973300695419312, 8.0], [508.0, 218.0, 0.998190701007843, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 442.0, 0.9999686479568481, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [266.0, 254.0, 0.9999960660934448, 3.0], [274.0, 197.0, 0.9999415874481201, 4.0], [304.0, 200.0, 0.9998981952667236, 5.0], [378.0, 205.0, 0.9998375177383423, 6.0], [452.0, 211.0, 0.9996230602264404, 7.0], [480.0, 189.0, 0.9974685907363892, 8.0], [509.0, 222.0, 0.9981322884559631, 9.0]]\n",
      "(9, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints after label index [[252.0, 442.0, 0.9999147653579712, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [266.0, 253.0, 0.9999949932098389, 3.0], [276.0, 197.0, 0.9999556541442871, 4.0], [305.0, 200.0, 0.9998435974121094, 5.0], [379.0, 206.0, 0.9997004270553589, 6.0], [453.0, 213.0, 0.9997860789299011, 7.0], [482.0, 192.0, 0.9983035326004028, 8.0], [510.0, 225.0, 0.9953402280807495, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.999833345413208, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [266.0, 254.0, 0.9999954700469971, 3.0], [276.0, 198.0, 0.9999746084213257, 4.0], [307.0, 201.0, 0.9999101161956787, 5.0], [380.0, 208.0, 0.9995797276496887, 6.0], [454.0, 215.0, 0.9998494386672974, 7.0], [483.0, 195.0, 0.9983261227607727, 8.0], [511.0, 228.0, 0.9952347874641418, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.99988853931427, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [268.0, 254.0, 0.9999929666519165, 3.0], [278.0, 198.0, 0.9999377727508545, 4.0], [307.0, 202.0, 0.9998688697814941, 5.0], [381.0, 210.0, 0.9996175765991211, 6.0], [455.0, 217.0, 0.9998082518577576, 7.0], [485.0, 197.0, 0.9988343119621277, 8.0], [512.0, 231.0, 0.9958511590957642, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998966455459595, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [268.0, 254.0, 0.9999951124191284, 3.0], [279.0, 198.0, 0.999908447265625, 4.0], [308.0, 202.0, 0.9997383952140808, 5.0], [382.0, 211.0, 0.9996293783187866, 6.0], [456.0, 219.0, 0.9998630285263062, 7.0], [486.0, 200.0, 0.9950476884841919, 8.0], [513.0, 233.0, 0.9937410950660706, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9998137354850769, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [268.0, 254.0, 0.9999947547912598, 3.0], [280.0, 198.0, 0.999549925327301, 4.0], [310.0, 203.0, 0.9998952150344849, 5.0], [384.0, 212.0, 0.9998270869255066, 6.0], [458.0, 222.0, 0.9998584985733032, 7.0], [486.0, 202.0, 0.9975243210792542, 8.0], [514.0, 237.0, 0.9975354671478271, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9998904466629028, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [269.0, 254.0, 0.9999949932098389, 3.0], [281.0, 199.0, 0.9999547004699707, 4.0], [311.0, 203.0, 0.9997878670692444, 5.0], [384.0, 213.0, 0.999889612197876, 6.0], [458.0, 224.0, 0.999920129776001, 7.0], [489.0, 205.0, 0.9977284073829651, 8.0], [514.0, 240.0, 0.9969046711921692, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999022483825684, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [270.0, 254.0, 0.9999954700469971, 3.0], [282.0, 199.0, 0.9998101592063904, 4.0], [312.0, 203.0, 0.9996988773345947, 5.0], [386.0, 215.0, 0.9999395608901978, 6.0], [459.0, 226.0, 0.9998651742935181, 7.0], [491.0, 208.0, 0.9972597360610962, 8.0], [516.0, 244.0, 0.9935484528541565, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999474287033081, 1.0], [255.0, 311.0, 0.9999998807907104, 2.0], [270.0, 254.0, 0.9999970197677612, 3.0], [284.0, 199.0, 0.9997931122779846, 4.0], [313.0, 204.0, 0.9998689889907837, 5.0], [387.0, 216.0, 0.9999136924743652, 6.0], [460.0, 228.0, 0.9997918009757996, 7.0], [492.0, 210.0, 0.995796799659729, 8.0], [516.0, 247.0, 0.9884394407272339, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.999864935874939, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [270.0, 255.0, 0.9999974966049194, 3.0], [284.0, 199.0, 0.9983452558517456, 4.0], [314.0, 205.0, 0.9998779296875, 5.0], [388.0, 218.0, 0.9999589920043945, 6.0], [461.0, 231.0, 0.9998952150344849, 7.0], [493.0, 213.0, 0.9987719655036926, 8.0], [516.0, 250.0, 0.991706371307373, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999610185623169, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [271.0, 255.0, 0.9999972581863403, 3.0], [286.0, 199.0, 0.9994767308235168, 4.0], [316.0, 205.0, 0.9999265670776367, 5.0], [389.0, 219.0, 0.9998626708984375, 6.0], [462.0, 233.0, 0.9998874664306641, 7.0], [494.0, 217.0, 0.9979833364486694, 8.0], [517.0, 253.0, 0.9949600696563721, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 441.0, 0.9997914433479309, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [272.0, 255.0, 0.999996542930603, 3.0], [288.0, 199.0, 0.999036431312561, 4.0], [316.0, 206.0, 0.9999116659164429, 5.0], [389.0, 221.0, 0.9999399185180664, 6.0], [462.0, 235.0, 0.9998539686203003, 7.0], [495.0, 219.0, 0.9971656203269958, 8.0], [518.0, 255.0, 0.9928174018859863, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9998162388801575, 1.0], [256.0, 311.0, 0.9999996423721313, 2.0], [273.0, 255.0, 0.9999977350234985, 3.0], [288.0, 199.0, 0.9999151229858398, 4.0], [317.0, 207.0, 0.9999186992645264, 5.0], [391.0, 222.0, 0.999591052532196, 6.0], [464.0, 237.0, 0.9997183680534363, 7.0], [497.0, 221.0, 0.9974243640899658, 8.0], [519.0, 259.0, 0.9958399534225464, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999889612197876, 1.0], [256.0, 311.0, 0.9999996423721313, 2.0], [273.0, 255.0, 0.9999966621398926, 3.0], [290.0, 200.0, 0.9998291730880737, 4.0], [318.0, 208.0, 0.9999620914459229, 5.0], [391.0, 224.0, 0.9998739957809448, 6.0], [465.0, 240.0, 0.9998414516448975, 7.0], [497.0, 224.0, 0.9965431094169617, 8.0], [519.0, 262.0, 0.9932863116264343, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[253.0, 442.0, 0.9998812675476074, 1.0], [256.0, 311.0, 0.9999996423721313, 2.0], [274.0, 255.0, 0.9999971389770508, 3.0], [291.0, 200.0, 0.9995518326759338, 4.0], [320.0, 208.0, 0.9999483823776245, 5.0], [392.0, 225.0, 0.9998844861984253, 6.0], [466.0, 242.0, 0.9999181032180786, 7.0], [499.0, 226.0, 0.9963766932487488, 8.0], [520.0, 266.0, 0.9929519295692444, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9997938275337219, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [274.0, 255.0, 0.9999980926513672, 3.0], [293.0, 201.0, 0.9998173117637634, 4.0], [321.0, 209.0, 0.9999539852142334, 5.0], [393.0, 227.0, 0.9993582367897034, 6.0], [466.0, 245.0, 0.9999194145202637, 7.0], [500.0, 230.0, 0.99570232629776, 8.0], [520.0, 269.0, 0.9904515743255615, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999011754989624, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [275.0, 256.0, 0.9999984502792358, 3.0], [294.0, 202.0, 0.9998478889465332, 4.0], [322.0, 209.0, 0.9999618530273438, 5.0], [394.0, 228.0, 0.9996659755706787, 6.0], [467.0, 247.0, 0.9998546838760376, 7.0], [501.0, 234.0, 0.9966208934783936, 8.0], [521.0, 273.0, 0.994434654712677, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998461008071899, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [276.0, 256.0, 0.9999943971633911, 3.0], [295.0, 202.0, 0.9997319579124451, 4.0], [323.0, 210.0, 0.9999245405197144, 5.0], [395.0, 230.0, 0.9997001886367798, 6.0], [468.0, 250.0, 0.999896764755249, 7.0], [502.0, 236.0, 0.9958111047744751, 8.0], [520.0, 275.0, 0.9959905743598938, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999125003814697, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [276.0, 256.0, 0.9999973773956299, 3.0], [296.0, 202.0, 0.9998995065689087, 4.0], [324.0, 211.0, 0.9999134540557861, 5.0], [396.0, 231.0, 0.9995232820510864, 6.0], [468.0, 252.0, 0.9999130964279175, 7.0], [503.0, 239.0, 0.9967709183692932, 8.0], [520.0, 278.0, 0.9960337281227112, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998641014099121, 1.0], [256.0, 311.0, 0.9999995231628418, 2.0], [277.0, 257.0, 0.9999986886978149, 3.0], [297.0, 202.0, 0.9998241066932678, 4.0], [325.0, 211.0, 0.9999034404754639, 5.0], [397.0, 233.0, 0.9998002648353577, 6.0], [469.0, 254.0, 0.9998600482940674, 7.0], [503.0, 243.0, 0.9953696131706238, 8.0], [521.0, 282.0, 0.9949017763137817, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998568296432495, 1.0], [256.0, 311.0, 0.9999995231628418, 2.0], [277.0, 256.0, 0.9999721050262451, 3.0], [298.0, 203.0, 0.9999399185180664, 4.0], [327.0, 212.0, 0.9999269247055054, 5.0], [398.0, 234.0, 0.9998364448547363, 6.0], [470.0, 257.0, 0.9999200105667114, 7.0], [504.0, 244.0, 0.9970808625221252, 8.0], [521.0, 285.0, 0.993941068649292, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999297857284546, 1.0], [256.0, 311.0, 0.9999996423721313, 2.0], [278.0, 257.0, 0.999998927116394, 3.0], [299.0, 203.0, 0.9998718500137329, 4.0], [327.0, 212.0, 0.9999532699584961, 5.0], [399.0, 236.0, 0.9997739195823669, 6.0], [470.0, 259.0, 0.999947190284729, 7.0], [505.0, 248.0, 0.9967645406723022, 8.0], [521.0, 288.0, 0.9931069016456604, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998558759689331, 1.0], [256.0, 311.0, 0.9999995231628418, 2.0], [278.0, 257.0, 0.999998927116394, 3.0], [300.0, 204.0, 0.9994316697120667, 4.0], [329.0, 213.0, 0.9999114274978638, 5.0], [399.0, 237.0, 0.9997321963310242, 6.0], [471.0, 261.0, 0.9999027252197266, 7.0], [505.0, 251.0, 0.9903205037117004, 8.0], [521.0, 291.0, 0.9939661622047424, 9.0]]\n",
      "(9, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints after label index [[250.0, 442.0, 0.9998753070831299, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [279.0, 258.0, 0.9999973773956299, 3.0], [302.0, 204.0, 0.9987466335296631, 4.0], [330.0, 214.0, 0.9997922778129578, 5.0], [400.0, 239.0, 0.9999178647994995, 6.0], [471.0, 263.0, 0.9998791217803955, 7.0], [506.0, 254.0, 0.9969280362129211, 8.0], [522.0, 294.0, 0.9960975646972656, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998539686203003, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [280.0, 258.0, 0.9999984502792358, 3.0], [303.0, 204.0, 0.9983341097831726, 4.0], [331.0, 215.0, 0.9997965693473816, 5.0], [401.0, 241.0, 0.9999164342880249, 6.0], [472.0, 266.0, 0.9993956089019775, 7.0], [507.0, 257.0, 0.9965211153030396, 8.0], [522.0, 297.0, 0.9929667711257935, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999915361404419, 1.0], [256.0, 311.0, 0.9999994039535522, 2.0], [281.0, 258.0, 0.9999982118606567, 3.0], [304.0, 205.0, 0.9974937438964844, 4.0], [331.0, 216.0, 0.9997081160545349, 5.0], [402.0, 243.0, 0.9998034834861755, 6.0], [473.0, 269.0, 0.9996932744979858, 7.0], [507.0, 260.0, 0.9966607093811035, 8.0], [522.0, 301.0, 0.9943060278892517, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998332262039185, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [281.0, 258.0, 0.9999986886978149, 3.0], [306.0, 205.0, 0.9972556233406067, 4.0], [332.0, 217.0, 0.9998024106025696, 5.0], [402.0, 244.0, 0.9998260140419006, 6.0], [474.0, 272.0, 0.9998883008956909, 7.0], [508.0, 262.0, 0.996783971786499, 8.0], [522.0, 304.0, 0.9935716390609741, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998548030853271, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [281.0, 259.0, 0.9999985694885254, 3.0], [306.0, 205.0, 0.9971174001693726, 4.0], [333.0, 217.0, 0.9997889399528503, 5.0], [403.0, 246.0, 0.9998873472213745, 6.0], [473.0, 274.0, 0.9999377727508545, 7.0], [508.0, 266.0, 0.9927095174789429, 8.0], [521.0, 307.0, 0.9925050735473633, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998681545257568, 1.0], [256.0, 311.0, 0.9999994039535522, 2.0], [282.0, 259.0, 0.9999948740005493, 3.0], [307.0, 206.0, 0.9978036284446716, 4.0], [334.0, 218.0, 0.9998214840888977, 5.0], [404.0, 247.0, 0.9998160004615784, 6.0], [474.0, 276.0, 0.9999310970306396, 7.0], [509.0, 268.0, 0.990583062171936, 8.0], [522.0, 310.0, 0.994788408279419, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9997764229774475, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [283.0, 260.0, 0.9999929666519165, 3.0], [308.0, 207.0, 0.9987999200820923, 4.0], [335.0, 219.0, 0.9998220801353455, 5.0], [405.0, 249.0, 0.9998725652694702, 6.0], [475.0, 279.0, 0.9999439716339111, 7.0], [511.0, 272.0, 0.9942828416824341, 8.0], [522.0, 314.0, 0.9958928823471069, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998852014541626, 1.0], [256.0, 311.0, 0.9999995231628418, 2.0], [283.0, 260.0, 0.9999903440475464, 3.0], [310.0, 207.0, 0.9988077878952026, 4.0], [336.0, 220.0, 0.9999524354934692, 5.0], [405.0, 250.0, 0.9998675584793091, 6.0], [474.0, 282.0, 0.9999477863311768, 7.0], [511.0, 274.0, 0.9931633472442627, 8.0], [522.0, 317.0, 0.9918306469917297, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.99988853931427, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [283.0, 260.0, 0.9999911785125732, 3.0], [311.0, 208.0, 0.9987727999687195, 4.0], [338.0, 221.0, 0.9999496936798096, 5.0], [406.0, 252.0, 0.9998928308486938, 6.0], [475.0, 285.0, 0.9999014139175415, 7.0], [512.0, 277.0, 0.9927247166633606, 8.0], [521.0, 320.0, 0.9938588738441467, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998494386672974, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [284.0, 260.0, 0.9999896287918091, 3.0], [312.0, 209.0, 0.9991275668144226, 4.0], [339.0, 222.0, 0.9999716281890869, 5.0], [406.0, 253.0, 0.9999282360076904, 6.0], [475.0, 287.0, 0.9998784065246582, 7.0], [513.0, 280.0, 0.9911661744117737, 8.0], [522.0, 324.0, 0.9904218912124634, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998748302459717, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [285.0, 261.0, 0.9999927282333374, 3.0], [313.0, 210.0, 0.9995693564414978, 4.0], [340.0, 223.0, 0.9999697208404541, 5.0], [407.0, 255.0, 0.9998167157173157, 6.0], [476.0, 289.0, 0.9998970031738281, 7.0], [513.0, 283.0, 0.993300199508667, 8.0], [521.0, 326.0, 0.9930009841918945, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999297857284546, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [285.0, 261.0, 0.9999890327453613, 3.0], [315.0, 211.0, 0.9997608065605164, 4.0], [341.0, 224.0, 0.9999595880508423, 5.0], [408.0, 257.0, 0.9998992681503296, 6.0], [476.0, 292.0, 0.9999325275421143, 7.0], [513.0, 286.0, 0.9851271510124207, 8.0], [519.0, 330.0, 0.9926797151565552, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998123049736023, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [285.0, 261.0, 0.9999861717224121, 3.0], [316.0, 211.0, 0.9993314743041992, 4.0], [341.0, 225.0, 0.99994957447052, 5.0], [409.0, 259.0, 0.9997933506965637, 6.0], [476.0, 294.0, 0.9997702240943909, 7.0], [514.0, 289.0, 0.9867092370986938, 8.0], [521.0, 333.0, 0.9962630867958069, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999775230884552, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [286.0, 261.0, 0.9999855756759644, 3.0], [317.0, 212.0, 0.9994877576828003, 4.0], [342.0, 226.0, 0.9999183416366577, 5.0], [409.0, 261.0, 0.999868631362915, 6.0], [476.0, 297.0, 0.9999434947967529, 7.0], [514.0, 292.0, 0.9937641620635986, 8.0], [519.0, 335.0, 0.993750274181366, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999194145202637, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [287.0, 261.0, 0.9999812841415405, 3.0], [318.0, 212.0, 0.9998713731765747, 4.0], [343.0, 226.0, 0.9998189806938171, 5.0], [409.0, 262.0, 0.9999123811721802, 6.0], [477.0, 299.0, 0.9999545812606812, 7.0], [514.0, 295.0, 0.9968796968460083, 8.0], [519.0, 339.0, 0.9887022972106934, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998458623886108, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [288.0, 262.0, 0.9999916553497314, 3.0], [317.0, 212.0, 0.9996715784072876, 4.0], [344.0, 227.0, 0.9997162222862244, 5.0], [410.0, 264.0, 0.9995480179786682, 6.0], [477.0, 302.0, 0.9999414682388306, 7.0], [515.0, 298.0, 0.9842482209205627, 8.0], [519.0, 342.0, 0.9929366707801819, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999068975448608, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [288.0, 262.0, 0.9999903440475464, 3.0], [320.0, 213.0, 0.9996768236160278, 4.0], [344.0, 228.0, 0.9996304512023926, 5.0], [411.0, 266.0, 0.9998549222946167, 6.0], [477.0, 304.0, 0.9999135732650757, 7.0], [514.0, 301.0, 0.9922080636024475, 8.0], [519.0, 345.0, 0.9906249642372131, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999208450317383, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [289.0, 262.0, 0.9999918937683105, 3.0], [320.0, 214.0, 0.9994588494300842, 4.0], [345.0, 229.0, 0.9997983574867249, 5.0], [411.0, 267.0, 0.999782145023346, 6.0], [477.0, 305.0, 0.9997976422309875, 7.0], [514.0, 303.0, 0.9925022125244141, 8.0], [519.0, 346.0, 0.9937547445297241, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998824596405029, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [289.0, 262.0, 0.9999922513961792, 3.0], [321.0, 214.0, 0.9993185997009277, 4.0], [346.0, 229.0, 0.9997461438179016, 5.0], [411.0, 267.0, 0.9998682737350464, 6.0], [476.0, 307.0, 0.9998534917831421, 7.0], [515.0, 304.0, 0.9881039261817932, 8.0], [519.0, 348.0, 0.9946727156639099, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 443.0, 0.9999839067459106, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [289.0, 262.0, 0.9999927282333374, 3.0], [321.0, 215.0, 0.9996079802513123, 4.0], [346.0, 229.0, 0.9997276663780212, 5.0], [411.0, 268.0, 0.9998462200164795, 6.0], [477.0, 308.0, 0.9999021291732788, 7.0], [515.0, 305.0, 0.9863346815109253, 8.0], [519.0, 348.0, 0.9943397641181946, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998119473457336, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [289.0, 262.0, 0.9999934434890747, 3.0], [321.0, 214.0, 0.9994096755981445, 4.0], [346.0, 230.0, 0.9997962117195129, 5.0], [411.0, 268.0, 0.9998272061347961, 6.0], [476.0, 307.0, 0.9998818635940552, 7.0], [515.0, 305.0, 0.9845534563064575, 8.0], [518.0, 348.0, 0.993654727935791, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 441.0, 0.9998769760131836, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [289.0, 263.0, 0.999993085861206, 3.0], [321.0, 214.0, 0.9994140863418579, 4.0], [346.0, 230.0, 0.9997764229774475, 5.0], [411.0, 268.0, 0.9998737573623657, 6.0], [477.0, 308.0, 0.9998908042907715, 7.0], [515.0, 305.0, 0.9851818680763245, 8.0], [518.0, 349.0, 0.9938439130783081, 9.0]]\n",
      "(9, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints after label index [[252.0, 442.0, 0.9998457431793213, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [289.0, 262.0, 0.9999924898147583, 3.0], [321.0, 214.0, 0.999447762966156, 4.0], [347.0, 230.0, 0.9998154044151306, 5.0], [411.0, 268.0, 0.9998323917388916, 6.0], [477.0, 308.0, 0.9998999834060669, 7.0], [514.0, 305.0, 0.9858681559562683, 8.0], [518.0, 349.0, 0.9939180612564087, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998575448989868, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [289.0, 262.0, 0.999992847442627, 3.0], [321.0, 214.0, 0.9992977380752563, 4.0], [346.0, 229.0, 0.9997777342796326, 5.0], [411.0, 268.0, 0.9998270869255066, 6.0], [477.0, 308.0, 0.9998966455459595, 7.0], [515.0, 305.0, 0.9859316349029541, 8.0], [518.0, 349.0, 0.9940631985664368, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998327493667603, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [289.0, 262.0, 0.9999927282333374, 3.0], [321.0, 214.0, 0.9993122816085815, 4.0], [346.0, 230.0, 0.9997941851615906, 5.0], [411.0, 268.0, 0.9998624324798584, 6.0], [477.0, 308.0, 0.9998960494995117, 7.0], [515.0, 305.0, 0.9882444143295288, 8.0], [518.0, 348.0, 0.9941431879997253, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9997792840003967, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [289.0, 262.0, 0.9999926090240479, 3.0], [321.0, 215.0, 0.9994186162948608, 4.0], [346.0, 230.0, 0.9998121857643127, 5.0], [411.0, 268.0, 0.9998681545257568, 6.0], [477.0, 308.0, 0.9998986721038818, 7.0], [515.0, 305.0, 0.9853830337524414, 8.0], [518.0, 348.0, 0.9940310120582581, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9997621178627014, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [289.0, 262.0, 0.9999938011169434, 3.0], [321.0, 214.0, 0.9994754195213318, 4.0], [346.0, 230.0, 0.9998308420181274, 5.0], [411.0, 268.0, 0.9998220801353455, 6.0], [476.0, 307.0, 0.9998373985290527, 7.0], [515.0, 305.0, 0.9811244606971741, 8.0], [519.0, 348.0, 0.9949960708618164, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999265670776367, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [289.0, 262.0, 0.999991774559021, 3.0], [321.0, 214.0, 0.99932861328125, 4.0], [346.0, 229.0, 0.9997932314872742, 5.0], [411.0, 268.0, 0.9997939467430115, 6.0], [477.0, 306.0, 0.9998863935470581, 7.0], [515.0, 304.0, 0.992280125617981, 8.0], [519.0, 347.0, 0.9940592050552368, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998040795326233, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [289.0, 262.0, 0.9999922513961792, 3.0], [321.0, 214.0, 0.9994396567344666, 4.0], [346.0, 229.0, 0.999795138835907, 5.0], [412.0, 267.0, 0.9997028708457947, 6.0], [478.0, 304.0, 0.9998171925544739, 7.0], [516.0, 302.0, 0.991489827632904, 8.0], [520.0, 346.0, 0.989406406879425, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9997991919517517, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [288.0, 262.0, 0.9999914169311523, 3.0], [320.0, 214.0, 0.9995094537734985, 4.0], [345.0, 229.0, 0.999777615070343, 5.0], [411.0, 265.0, 0.9997392296791077, 6.0], [479.0, 302.0, 0.9999160766601562, 7.0], [517.0, 299.0, 0.9896126389503479, 8.0], [521.0, 343.0, 0.9920337796211243, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9998602867126465, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [288.0, 262.0, 0.9999890327453613, 3.0], [320.0, 213.0, 0.9998062252998352, 4.0], [345.0, 229.0, 0.9997813105583191, 5.0], [411.0, 264.0, 0.9998835325241089, 6.0], [479.0, 300.0, 0.9999039173126221, 7.0], [518.0, 296.0, 0.9930959343910217, 8.0], [521.0, 340.0, 0.992363691329956, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998170733451843, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [288.0, 262.0, 0.9999916553497314, 3.0], [319.0, 213.0, 0.9997915625572205, 4.0], [344.0, 228.0, 0.9997158646583557, 5.0], [412.0, 262.0, 0.9997678399085999, 6.0], [480.0, 297.0, 0.9997716546058655, 7.0], [518.0, 294.0, 0.9952450394630432, 8.0], [520.0, 338.0, 0.992676854133606, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 442.0, 0.9999139308929443, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [287.0, 262.0, 0.9999903440475464, 3.0], [318.0, 213.0, 0.999804675579071, 4.0], [344.0, 228.0, 0.9997537732124329, 5.0], [412.0, 261.0, 0.9999344348907471, 6.0], [481.0, 294.0, 0.9996353387832642, 7.0], [518.0, 291.0, 0.9874070882797241, 8.0], [522.0, 335.0, 0.9909294247627258, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999293088912964, 1.0], [255.0, 311.0, 0.9999997615814209, 2.0], [287.0, 262.0, 0.999991774559021, 3.0], [318.0, 213.0, 0.9996970891952515, 4.0], [344.0, 227.0, 0.9997873902320862, 5.0], [412.0, 260.0, 0.9999642372131348, 6.0], [481.0, 292.0, 0.999923825263977, 7.0], [517.0, 290.0, 0.9690294861793518, 8.0], [522.0, 333.0, 0.9937440752983093, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.999842643737793, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [287.0, 262.0, 0.9999901056289673, 3.0], [317.0, 212.0, 0.9995309114456177, 4.0], [343.0, 227.0, 0.9997683167457581, 5.0], [413.0, 258.0, 0.9996423721313477, 6.0], [481.0, 289.0, 0.9998626708984375, 7.0], [519.0, 285.0, 0.9783872365951538, 8.0], [524.0, 328.0, 0.993719220161438, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998359680175781, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [287.0, 262.0, 0.9999884366989136, 3.0], [318.0, 212.0, 0.9996516704559326, 4.0], [343.0, 227.0, 0.9997696280479431, 5.0], [413.0, 258.0, 0.9996936321258545, 6.0], [481.0, 287.0, 0.9997747540473938, 7.0], [519.0, 283.0, 0.9847479462623596, 8.0], [525.0, 327.0, 0.9914831519126892, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999544620513916, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [286.0, 261.0, 0.9999862909317017, 3.0], [318.0, 212.0, 0.9998958110809326, 4.0], [343.0, 226.0, 0.999864935874939, 5.0], [413.0, 256.0, 0.9994346499443054, 6.0], [482.0, 284.0, 0.999930739402771, 7.0], [520.0, 280.0, 0.9922019243240356, 8.0], [525.0, 323.0, 0.993895947933197, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999198913574219, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [286.0, 261.0, 0.9999847412109375, 3.0], [317.0, 212.0, 0.99959796667099, 4.0], [342.0, 226.0, 0.9998868703842163, 5.0], [412.0, 254.0, 0.9998743534088135, 6.0], [483.0, 282.0, 0.99993896484375, 7.0], [520.0, 277.0, 0.9915018081665039, 8.0], [525.0, 320.0, 0.9952303767204285, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[253.0, 442.0, 0.9999611377716064, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [286.0, 261.0, 0.999985933303833, 3.0], [317.0, 212.0, 0.9995337724685669, 4.0], [342.0, 226.0, 0.9998962879180908, 5.0], [412.0, 252.0, 0.9998489618301392, 6.0], [483.0, 279.0, 0.9999582767486572, 7.0], [520.0, 275.0, 0.9935507774353027, 8.0], [527.0, 318.0, 0.9953069090843201, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998824596405029, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [286.0, 261.0, 0.9999879598617554, 3.0], [316.0, 211.0, 0.9996492862701416, 4.0], [342.0, 225.0, 0.999915599822998, 5.0], [412.0, 251.0, 0.9995717406272888, 6.0], [485.0, 276.0, 0.9998371601104736, 7.0], [521.0, 272.0, 0.9933913946151733, 8.0], [527.0, 315.0, 0.9974446296691895, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998005032539368, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [285.0, 261.0, 0.9999829530715942, 3.0], [316.0, 211.0, 0.9995602965354919, 4.0], [341.0, 225.0, 0.9999552965164185, 5.0], [412.0, 249.0, 0.9996520280838013, 6.0], [485.0, 273.0, 0.999626636505127, 7.0], [521.0, 268.0, 0.9858111143112183, 8.0], [526.0, 312.0, 0.9968985319137573, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999129772186279, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [285.0, 261.0, 0.9999831914901733, 3.0], [316.0, 211.0, 0.9996480941772461, 4.0], [341.0, 225.0, 0.999962329864502, 5.0], [412.0, 248.0, 0.999797523021698, 6.0], [485.0, 271.0, 0.9998555183410645, 7.0], [520.0, 266.0, 0.9797778129577637, 8.0], [527.0, 309.0, 0.9945014715194702, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998950958251953, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [285.0, 261.0, 0.9999898672103882, 3.0], [315.0, 210.0, 0.9996939897537231, 4.0], [340.0, 224.0, 0.9999618530273438, 5.0], [412.0, 247.0, 0.999675989151001, 6.0], [485.0, 268.0, 0.9998021721839905, 7.0], [521.0, 263.0, 0.9847516417503357, 8.0], [527.0, 307.0, 0.9926921725273132, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[251.0, 442.0, 0.9998795986175537, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [285.0, 261.0, 0.999990701675415, 3.0], [315.0, 210.0, 0.9997435212135315, 4.0], [340.0, 224.0, 0.9999747276306152, 5.0], [411.0, 245.0, 0.9997032284736633, 6.0], [485.0, 266.0, 0.9998717308044434, 7.0], [521.0, 260.0, 0.995128870010376, 8.0], [529.0, 302.0, 0.9934154748916626, 9.0]]\n",
      "(9, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints after label index [[250.0, 442.0, 0.9998694658279419, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [284.0, 261.0, 0.9999927282333374, 3.0], [314.0, 210.0, 0.9996733665466309, 4.0], [340.0, 224.0, 0.9999780654907227, 5.0], [412.0, 243.0, 0.9998109936714172, 6.0], [485.0, 264.0, 0.9998791217803955, 7.0], [522.0, 257.0, 0.9953539371490479, 8.0], [530.0, 299.0, 0.992976188659668, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998199343681335, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [284.0, 260.0, 0.9999911785125732, 3.0], [313.0, 210.0, 0.9998107552528381, 4.0], [339.0, 223.0, 0.9999775886535645, 5.0], [412.0, 242.0, 0.9999089241027832, 6.0], [485.0, 260.0, 0.9999263286590576, 7.0], [521.0, 255.0, 0.9938099980354309, 8.0], [529.0, 298.0, 0.9973949193954468, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[255.0, 443.0, 0.999754011631012, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [284.0, 260.0, 0.9999868869781494, 3.0], [313.0, 209.0, 0.9997208714485168, 4.0], [339.0, 223.0, 0.9999767541885376, 5.0], [412.0, 241.0, 0.9998693466186523, 6.0], [485.0, 259.0, 0.9998979568481445, 7.0], [521.0, 253.0, 0.9963440299034119, 8.0], [529.0, 294.0, 0.9970135688781738, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998403787612915, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [284.0, 260.0, 0.9999904632568359, 3.0], [312.0, 209.0, 0.9996565580368042, 4.0], [338.0, 222.0, 0.9999675750732422, 5.0], [412.0, 239.0, 0.9999192953109741, 6.0], [486.0, 256.0, 0.999806821346283, 7.0], [521.0, 249.0, 0.9850332140922546, 8.0], [529.0, 292.0, 0.9971586465835571, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9998412132263184, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [283.0, 260.0, 0.9999904632568359, 3.0], [312.0, 208.0, 0.9994899034500122, 4.0], [338.0, 222.0, 0.9999736547470093, 5.0], [411.0, 237.0, 0.9999523162841797, 6.0], [486.0, 253.0, 0.9997251629829407, 7.0], [520.0, 247.0, 0.9828503131866455, 8.0], [528.0, 289.0, 0.994255006313324, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998730421066284, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [283.0, 260.0, 0.9999922513961792, 3.0], [311.0, 208.0, 0.9993531107902527, 4.0], [338.0, 221.0, 0.9999598264694214, 5.0], [411.0, 236.0, 0.9999487400054932, 6.0], [486.0, 250.0, 0.9996989965438843, 7.0], [521.0, 243.0, 0.9925380349159241, 8.0], [531.0, 285.0, 0.9927332401275635, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999001026153564, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [283.0, 260.0, 0.9999935626983643, 3.0], [311.0, 208.0, 0.9990376234054565, 4.0], [337.0, 221.0, 0.999942421913147, 5.0], [410.0, 235.0, 0.9998617172241211, 6.0], [485.0, 248.0, 0.999749481678009, 7.0], [521.0, 240.0, 0.9959371089935303, 8.0], [529.0, 283.0, 0.9936479926109314, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999090433120728, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [283.0, 260.0, 0.9999926090240479, 3.0], [310.0, 207.0, 0.9990485310554504, 4.0], [336.0, 221.0, 0.999954342842102, 5.0], [410.0, 233.0, 0.9996681213378906, 6.0], [485.0, 245.0, 0.9999037981033325, 7.0], [520.0, 238.0, 0.9968818426132202, 8.0], [532.0, 279.0, 0.9932795166969299, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998952150344849, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [283.0, 259.0, 0.999991774559021, 3.0], [309.0, 207.0, 0.999030351638794, 4.0], [336.0, 220.0, 0.9999418258666992, 5.0], [410.0, 231.0, 0.9997686743736267, 6.0], [485.0, 242.0, 0.9999024868011475, 7.0], [520.0, 235.0, 0.9935914874076843, 8.0], [529.0, 277.0, 0.9971535205841064, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999325275421143, 1.0], [256.0, 311.0, 0.9999992847442627, 2.0], [282.0, 259.0, 0.9999929666519165, 3.0], [309.0, 207.0, 0.9990035891532898, 4.0], [336.0, 220.0, 0.9999288320541382, 5.0], [410.0, 230.0, 0.9998432397842407, 6.0], [485.0, 239.0, 0.9997772574424744, 7.0], [520.0, 233.0, 0.992508590221405, 8.0], [528.0, 274.0, 0.9967010617256165, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998849630355835, 1.0], [255.0, 311.0, 0.9999991655349731, 2.0], [282.0, 259.0, 0.9999940395355225, 3.0], [308.0, 206.0, 0.9987616539001465, 4.0], [335.0, 220.0, 0.9999252557754517, 5.0], [409.0, 229.0, 0.9994617104530334, 6.0], [485.0, 237.0, 0.9996664524078369, 7.0], [520.0, 230.0, 0.9902994632720947, 8.0], [529.0, 271.0, 0.9941998720169067, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998651742935181, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [282.0, 259.0, 0.9999940395355225, 3.0], [308.0, 206.0, 0.9987125396728516, 4.0], [335.0, 220.0, 0.9998582601547241, 5.0], [409.0, 227.0, 0.9998118281364441, 6.0], [484.0, 235.0, 0.999816358089447, 7.0], [519.0, 227.0, 0.9807291626930237, 8.0], [528.0, 269.0, 0.9888211488723755, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[254.0, 443.0, 0.9997944235801697, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [282.0, 259.0, 0.9999924898147583, 3.0], [307.0, 206.0, 0.9985122084617615, 4.0], [334.0, 219.0, 0.999873161315918, 5.0], [409.0, 225.0, 0.9998799562454224, 6.0], [483.0, 232.0, 0.9998241066932678, 7.0], [519.0, 224.0, 0.994633674621582, 8.0], [527.0, 266.0, 0.9917156100273132, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 441.0, 0.9998231530189514, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [281.0, 259.0, 0.9999985694885254, 3.0], [307.0, 206.0, 0.9979377388954163, 4.0], [334.0, 219.0, 0.9998489618301392, 5.0], [408.0, 223.0, 0.9998632669448853, 6.0], [483.0, 229.0, 0.9998216032981873, 7.0], [518.0, 221.0, 0.9933464527130127, 8.0], [527.0, 263.0, 0.994171679019928, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999962329864502, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [281.0, 259.0, 0.9999985694885254, 3.0], [306.0, 205.0, 0.9980276226997375, 4.0], [333.0, 218.0, 0.9997624754905701, 5.0], [408.0, 223.0, 0.99982088804245, 6.0], [482.0, 226.0, 0.9998860359191895, 7.0], [518.0, 218.0, 0.9973040819168091, 8.0], [528.0, 258.0, 0.9969333410263062, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9998468160629272, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [281.0, 258.0, 0.9999986886978149, 3.0], [306.0, 205.0, 0.9980782270431519, 4.0], [333.0, 218.0, 0.9998655319213867, 5.0], [408.0, 221.0, 0.9999561309814453, 6.0], [482.0, 224.0, 0.9998762607574463, 7.0], [516.0, 216.0, 0.9964094758033752, 8.0], [526.0, 257.0, 0.9970180988311768, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998693466186523, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [281.0, 258.0, 0.9999986886978149, 3.0], [305.0, 205.0, 0.9977297186851501, 4.0], [332.0, 218.0, 0.9997797608375549, 5.0], [407.0, 220.0, 0.9998990297317505, 6.0], [482.0, 221.0, 0.9999183416366577, 7.0], [517.0, 213.0, 0.9932239055633545, 8.0], [527.0, 254.0, 0.9940673112869263, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998698234558105, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [281.0, 258.0, 0.9999927282333374, 3.0], [305.0, 205.0, 0.997400164604187, 4.0], [332.0, 218.0, 0.9998106360435486, 5.0], [406.0, 218.0, 0.9998884201049805, 6.0], [481.0, 219.0, 0.9998338222503662, 7.0], [515.0, 210.0, 0.9848086833953857, 8.0], [524.0, 252.0, 0.9910723567008972, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 443.0, 0.9997959733009338, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [280.0, 258.0, 0.9999983310699463, 3.0], [305.0, 204.0, 0.9978176355361938, 4.0], [331.0, 217.0, 0.9998458623886108, 5.0], [406.0, 217.0, 0.9999388456344604, 6.0], [480.0, 217.0, 0.9995643496513367, 7.0], [515.0, 208.0, 0.9921525120735168, 8.0], [525.0, 248.0, 0.989834725856781, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999310970306396, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [280.0, 258.0, 0.9999979734420776, 3.0], [304.0, 204.0, 0.9988522529602051, 4.0], [331.0, 217.0, 0.9997943043708801, 5.0], [406.0, 215.0, 0.9999239444732666, 6.0], [480.0, 213.0, 0.9997937083244324, 7.0], [514.0, 204.0, 0.9943583607673645, 8.0], [525.0, 245.0, 0.9948596954345703, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 441.0, 0.9999097585678101, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [280.0, 258.0, 0.9999980926513672, 3.0], [304.0, 204.0, 0.9980157613754272, 4.0], [331.0, 217.0, 0.9998080134391785, 5.0], [406.0, 214.0, 0.9999362230300903, 6.0], [479.0, 212.0, 0.9996324777603149, 7.0], [514.0, 202.0, 0.9954519867897034, 8.0], [524.0, 242.0, 0.9938921928405762, 9.0]]\n",
      "(9, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints after label index [[250.0, 442.0, 0.9999346733093262, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [280.0, 258.0, 0.999996542930603, 3.0], [303.0, 204.0, 0.9993190765380859, 4.0], [330.0, 216.0, 0.9998654127120972, 5.0], [405.0, 212.0, 0.9998815059661865, 6.0], [479.0, 210.0, 0.9994195699691772, 7.0], [513.0, 200.0, 0.9968094229698181, 8.0], [525.0, 240.0, 0.9956795573234558, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.999953031539917, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [279.0, 257.0, 0.9999980926513672, 3.0], [303.0, 204.0, 0.9995323419570923, 4.0], [330.0, 216.0, 0.9998133778572083, 5.0], [404.0, 211.0, 0.9996777772903442, 6.0], [478.0, 207.0, 0.9994078874588013, 7.0], [512.0, 197.0, 0.9954190254211426, 8.0], [522.0, 237.0, 0.9949377775192261, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9999083280563354, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [279.0, 257.0, 0.9999977350234985, 3.0], [302.0, 204.0, 0.9996416568756104, 4.0], [330.0, 216.0, 0.9998257756233215, 5.0], [404.0, 209.0, 0.9997568726539612, 6.0], [478.0, 204.0, 0.999683141708374, 7.0], [512.0, 194.0, 0.9965728521347046, 8.0], [521.0, 236.0, 0.9883497953414917, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998995065689087, 1.0], [255.0, 311.0, 0.9999996423721313, 2.0], [279.0, 257.0, 0.9999986886978149, 3.0], [302.0, 203.0, 0.9997127652168274, 4.0], [329.0, 216.0, 0.9997788071632385, 5.0], [403.0, 208.0, 0.9997435212135315, 6.0], [478.0, 201.0, 0.9998109936714172, 7.0], [510.0, 191.0, 0.9969252943992615, 8.0], [520.0, 233.0, 0.9916933178901672, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998420476913452, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [278.0, 257.0, 0.9999988079071045, 3.0], [301.0, 203.0, 0.9995470643043518, 4.0], [329.0, 215.0, 0.9997972846031189, 5.0], [403.0, 207.0, 0.9997822642326355, 6.0], [477.0, 199.0, 0.9998477697372437, 7.0], [509.0, 189.0, 0.9939006567001343, 8.0], [518.0, 230.0, 0.9858787655830383, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999760389328003, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [278.0, 257.0, 0.9999991655349731, 3.0], [301.0, 203.0, 0.9995273351669312, 4.0], [329.0, 215.0, 0.9998132586479187, 5.0], [402.0, 205.0, 0.9997326731681824, 6.0], [476.0, 196.0, 0.9999006986618042, 7.0], [508.0, 186.0, 0.9953371286392212, 8.0], [520.0, 226.0, 0.991911768913269, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998700618743896, 1.0], [255.0, 311.0, 0.9999994039535522, 2.0], [278.0, 257.0, 0.9999990463256836, 3.0], [301.0, 203.0, 0.999583899974823, 4.0], [328.0, 215.0, 0.9998410940170288, 5.0], [402.0, 203.0, 0.9998818635940552, 6.0], [475.0, 194.0, 0.9998443126678467, 7.0], [507.0, 185.0, 0.9953523874282837, 8.0], [519.0, 224.0, 0.9920645356178284, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[250.0, 442.0, 0.9998258948326111, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [278.0, 257.0, 0.9999634027481079, 3.0], [301.0, 203.0, 0.9996688365936279, 4.0], [328.0, 215.0, 0.9998770952224731, 5.0], [402.0, 203.0, 0.9999475479125977, 6.0], [474.0, 193.0, 0.9998020529747009, 7.0], [506.0, 183.0, 0.9959141612052917, 8.0], [520.0, 222.0, 0.9944429993629456, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999628067016602, 1.0], [255.0, 311.0, 0.9999992847442627, 2.0], [278.0, 257.0, 0.9999990463256836, 3.0], [301.0, 203.0, 0.9997394680976868, 4.0], [328.0, 214.0, 0.9998606443405151, 5.0], [400.0, 202.0, 0.9999347925186157, 6.0], [474.0, 192.0, 0.9998014569282532, 7.0], [506.0, 181.0, 0.9949159622192383, 8.0], [519.0, 221.0, 0.9934471249580383, 9.0]]\n",
      "(9, 2)\n",
      "Keypoints after label index [[252.0, 442.0, 0.9999195337295532, 1.0], [255.0, 311.0, 0.9999995231628418, 2.0], [278.0, 257.0, 0.9999990463256836, 3.0], [300.0, 203.0, 0.999819815158844, 4.0], [327.0, 214.0, 0.9998780488967896, 5.0], [401.0, 202.0, 0.9999340772628784, 6.0], [473.0, 192.0, 0.9997194409370422, 7.0], [505.0, 182.0, 0.9919275045394897, 8.0], [519.0, 221.0, 0.9908876419067383, 9.0]]\n",
      "(9, 2)\n",
      "Processing complete! Keypoints saved in /home/jc-merlab/Pictures/Test_Data/occ_vids/exp_01/gt/save_keypoints/keypoints.txt and images saved with drawn keypoints.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import json\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Check for CUDA availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Running on: {device}\")\n",
    "\n",
    "# Load pre-trained model\n",
    "weights_path = '/home/jc-merlab/Pictures/Data/trained_models/keypointsrcnn_planning_b1_e50_v8.pth'\n",
    "model = torch.load(weights_path).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Input and output paths\n",
    "input_folder = '/home/jc-merlab/Pictures/Test_Data/occ_vids/exp_01/gt/'\n",
    "output_path = '/home/jc-merlab/Pictures/Test_Data/occ_vids/exp_01/gt/save_keypoints/'\n",
    "os.makedirs(output_path, exist_ok=True)  # Ensure output directory exists\n",
    "\n",
    "# Dictionary to store all keypoints\n",
    "all_keypoints = {}\n",
    "\n",
    "# Process images in the folder\n",
    "for filename in sorted(os.listdir(input_folder)):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Convert image to tensor\n",
    "        tensor_image = F.to_tensor(image).to(device).unsqueeze(0)\n",
    "\n",
    "        # Run model inference\n",
    "        with torch.no_grad():\n",
    "            output = model(tensor_image)\n",
    "\n",
    "        # Extract keypoints and confidence scores\n",
    "        scores = output[0]['scores'].detach().cpu().numpy()\n",
    "        high_scores_idxs = np.where(scores > 0.7)[0].tolist()\n",
    "        post_nms_idxs = torchvision.ops.nms(\n",
    "            output[0]['boxes'][high_scores_idxs], \n",
    "            output[0]['scores'][high_scores_idxs], \n",
    "            0.3\n",
    "        ).cpu().numpy()\n",
    "        \n",
    "        confidence = output[0]['scores'][high_scores_idxs].detach().cpu().numpy()\n",
    "        labels = output[0]['labels'][high_scores_idxs].detach().cpu().numpy()\n",
    "        \n",
    "        keypoints = []\n",
    "        for idx, kps in enumerate(output[0]['keypoints'][high_scores_idxs].detach().cpu().numpy()):\n",
    "            keypoints.append(list(map(int, kps[0, 0:2])) + [confidence[idx]] + [labels[idx]])\n",
    "            \n",
    "#         print(\"keypoints before label index\", keypoints)\n",
    "\n",
    "        keypoints = [torch.tensor(kp, dtype=torch.float32).to(device) if not isinstance(kp, torch.Tensor) else kp for kp in keypoints]\n",
    "        keypoints = torch.stack(keypoints).to(device)\n",
    "        \n",
    "        unique_labels, best_keypoint_indices = torch.unique(keypoints[:, 3], return_inverse=True)\n",
    "        best_scores, best_indices = torch.max(keypoints[:, 2].unsqueeze(0) * (best_keypoint_indices == torch.arange(len(unique_labels)).unsqueeze(1).cuda()), dim=1)\n",
    "        keypoints = keypoints[best_indices]\n",
    "        keypoints_list = keypoints.tolist()\n",
    "        print(\"Keypoints after label index\", keypoints_list)\n",
    "\n",
    "        # keypoints_list is the list of keypoints\n",
    "        keypoints_all = np.array([[int(kp[0]), int(kp[1])] for kp in keypoints_list])\n",
    "        \n",
    "        print(keypoints_all.shape)\n",
    "        \n",
    "        for idx, kps in enumerate(keypoints_all):\n",
    "            x, y = int(kps[0]), int(kps[1])\n",
    "            cv2.circle(image, (x, y), 5, (0, 0, 255), -1)\n",
    "        \n",
    "        # Store in dictionary with frame name\n",
    "        frame_key = filename.replace('.jpg', '')\n",
    "        all_keypoints[frame_key] = keypoints_all.tolist()\n",
    "\n",
    "        # Save the image with drawn keypoints\n",
    "        output_image_path = os.path.join(output_path, filename)\n",
    "        cv2.imwrite(output_image_path, image)\n",
    "\n",
    "# Save all keypoints in one JSON file\n",
    "txt_output_path = os.path.join(output_path, \"keypoints.txt\")\n",
    "with open(txt_output_path, 'w') as f:\n",
    "    for frame, keypoints in all_keypoints.items():\n",
    "        f.write(f\"{frame}: {keypoints}\\n\")\n",
    "\n",
    "\n",
    "print(f\"Processing complete! Keypoints saved in {txt_output_path} and images saved with drawn keypoints.\")\n",
    "            \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import json\n",
    "import shutil\n",
    "from torchvision.transforms import functional as F\n",
    "import time\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "weights_path = '/home/jc-merlab/Pictures/Data/trained_models/keypointsrcnn_planning_b1_e50_v8.pth'\n",
    "model = torch.load(weights_path).to(device)\n",
    "# model = get_model(num_keypoints=6, weights_path=weights_path)\n",
    "# model.load_state_dict(torch.load('keypointsrcnn_weights.pth'))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Assuming the necessary imports are done\n",
    "# Assuming the model is loaded and device is set as in your initial code\n",
    "\n",
    "# Specify input and output folders\n",
    "input_folder = '/home/jc-merlab/Pictures/Data/occ_panda_phys_test_data/'\n",
    "output_frames_folder = '/home/jc-merlab/Pictures/Data/occ_phys_test_data/panda_kprcnn_op/'\n",
    "\n",
    "# Check if output folders exist, create them if not\n",
    "os.makedirs(output_frames_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# print(type(model))\n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture('/home/jc-merlab/Pictures/Test_Data/ycb_test_01.avi')\n",
    " \n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "i = 0\n",
    "print(type(i))\n",
    "while(cap.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "    print(i)\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:        \n",
    "#         img = cv2.imread(frame)\n",
    "        image = Image.fromarray(frame)\n",
    "\n",
    "        image = F.to_tensor(image).to(device)\n",
    "        image.unsqueeze_(0)\n",
    "        image = list(image)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            start = time.time()\n",
    "            output = model(image)\n",
    "            stop = time.time()\n",
    "            print(\"time\", (stop - start))\n",
    "\n",
    "        image = (image[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "        scores = output[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "        high_scores_idxs = np.where(scores > 0.7)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "        post_nms_idxs = torchvision.ops.nms(output[0]['boxes'][high_scores_idxs], output[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "\n",
    "        # Below, in output[0]['keypoints'][high_scores_idxs][post_nms_idxs] and output[0]['boxes'][high_scores_idxs][post_nms_idxs]\n",
    "        # Firstly, we choose only those objects, which have score above predefined threshold. This is done with choosing elements with [high_scores_idxs] indexes\n",
    "        # Secondly, we choose only those objects, which are left after NMS is applied. This is done with choosing elements with [post_nms_idxs] indexes\n",
    "\n",
    "        keypoints = []\n",
    "        for kps in output[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            keypoints.append([list(map(int, kp[:2])) for kp in kps])\n",
    "\n",
    "        bboxes = []\n",
    "        for bbox in output[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            bboxes.append(list(map(int, bbox.tolist())))\n",
    "        img = visualize(image, bboxes, keypoints)\n",
    "        \n",
    "        cv2.imwrite(\"/home/jc-merlab/Pictures/Test_Data/vid_occ_kp/out_image_\" + str(i) + \".jpg\", img)\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "    i = i+1\n",
    "    \n",
    "cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db362b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3078534d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
